### YamlMime:ManagedReference
items:
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  id: _computer_vision_a_p_i_impl
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation
  children:
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.acceptLanguage()
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImage(String)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImage(String,List<VisualFeatureTypes>,List<Details>,Language1)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageAsync(String)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageAsync(String,final ServiceCallback<ImageAnalysisInner>)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageAsync(String,List<VisualFeatureTypes>,List<Details>,Language1)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageAsync(String,List<VisualFeatureTypes>,List<Details>,Language1,final ServiceCallback<ImageAnalysisInner>)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageByDomain(DomainModels,String)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageByDomainAsync(DomainModels,String)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageByDomainAsync(DomainModels,String,final ServiceCallback<DomainModelResultsInner>)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageByDomainInStream(String,byte [])
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageByDomainInStreamAsync(String,byte [])
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageByDomainInStreamAsync(String,byte [],final ServiceCallback<DomainModelResultsInner>)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageByDomainInStreamWithServiceResponseAsync(String,byte [])
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageByDomainWithServiceResponseAsync(DomainModels,String)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageInStream(byte [])
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageInStream(byte [],List<VisualFeatureTypes>,String,String)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageInStreamAsync(byte [])
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageInStreamAsync(byte [],final ServiceCallback<ImageAnalysisInner>)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageInStreamAsync(byte [],List<VisualFeatureTypes>,String,String)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageInStreamAsync(byte [],List<VisualFeatureTypes>,String,String,final ServiceCallback<ImageAnalysisInner>)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageInStreamWithServiceResponseAsync(byte [])
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageInStreamWithServiceResponseAsync(byte [],List<VisualFeatureTypes>,String,String)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageWithServiceResponseAsync(String)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageWithServiceResponseAsync(String,List<VisualFeatureTypes>,List<Details>,Language1)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.azureRegion()
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.ComputerVisionAPIImpl(RestClient)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.ComputerVisionAPIImpl(ServiceClientCredentials)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.ComputerVisionAPIImpl(String,ServiceClientCredentials)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.describeImage(String)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.describeImage(String,String)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.describeImageAsync(String)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.describeImageAsync(String,final ServiceCallback<ImageDescriptionInner>)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.describeImageAsync(String,String)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.describeImageAsync(String,String,final ServiceCallback<ImageDescriptionInner>)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.describeImageInStream(byte [])
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.describeImageInStream(byte [],String)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.describeImageInStreamAsync(byte [])
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.describeImageInStreamAsync(byte [],final ServiceCallback<ImageDescriptionInner>)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.describeImageInStreamAsync(byte [],String)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.describeImageInStreamAsync(byte [],String,final ServiceCallback<ImageDescriptionInner>)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.describeImageInStreamWithServiceResponseAsync(byte [])
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.describeImageInStreamWithServiceResponseAsync(byte [],String)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.describeImageWithServiceResponseAsync(String)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.describeImageWithServiceResponseAsync(String,String)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.generateClientRequestId()
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.generateThumbnail(int,int,String)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.generateThumbnail(int,int,String,Boolean)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.generateThumbnailAsync(int,int,String)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.generateThumbnailAsync(int,int,String,Boolean)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.generateThumbnailAsync(int,int,String,Boolean,final ServiceCallback<InputStream>)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.generateThumbnailAsync(int,int,String,final ServiceCallback<InputStream>)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.generateThumbnailInStream(int,int,byte [])
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.generateThumbnailInStream(int,int,byte [],Boolean)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.generateThumbnailInStreamAsync(int,int,byte [])
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.generateThumbnailInStreamAsync(int,int,byte [],Boolean)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.generateThumbnailInStreamAsync(int,int,byte [],Boolean,final ServiceCallback<InputStream>)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.generateThumbnailInStreamAsync(int,int,byte [],final ServiceCallback<InputStream>)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.generateThumbnailInStreamWithServiceResponseAsync(int,int,byte [])
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.generateThumbnailInStreamWithServiceResponseAsync(int,int,byte [],Boolean)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.generateThumbnailWithServiceResponseAsync(int,int,String)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.generateThumbnailWithServiceResponseAsync(int,int,String,Boolean)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.getAzureClient()
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.getTextOperationResult(String)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.getTextOperationResultAsync(String)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.getTextOperationResultAsync(String,final ServiceCallback<TextOperationResultInner>)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.getTextOperationResultWithServiceResponseAsync(String)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.initialize()
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.listModels()
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.listModelsAsync()
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.listModelsAsync(final ServiceCallback<ListModelsResultInner>)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.listModelsWithServiceResponseAsync()
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.longRunningOperationRetryTimeout()
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizePrintedText(boolean,String)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizePrintedText(boolean,String,OcrLanguages)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizePrintedTextAsync(boolean,String)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizePrintedTextAsync(boolean,String,final ServiceCallback<OcrResultInner>)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizePrintedTextAsync(boolean,String,OcrLanguages)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizePrintedTextAsync(boolean,String,OcrLanguages,final ServiceCallback<OcrResultInner>)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizePrintedTextInStream(boolean,byte [])
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizePrintedTextInStream(boolean,byte [],OcrLanguages)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizePrintedTextInStreamAsync(boolean,byte [])
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizePrintedTextInStreamAsync(boolean,byte [],final ServiceCallback<OcrResultInner>)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizePrintedTextInStreamAsync(boolean,byte [],OcrLanguages)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizePrintedTextInStreamAsync(boolean,byte [],OcrLanguages,final ServiceCallback<OcrResultInner>)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizePrintedTextInStreamWithServiceResponseAsync(boolean,byte [])
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizePrintedTextInStreamWithServiceResponseAsync(boolean,byte [],OcrLanguages)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizePrintedTextWithServiceResponseAsync(boolean,String)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizePrintedTextWithServiceResponseAsync(boolean,String,OcrLanguages)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizeText(String)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizeText(String,Boolean)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizeTextAsync(String)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizeTextAsync(String,Boolean)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizeTextAsync(String,Boolean,final ServiceCallback<Void>)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizeTextAsync(String,final ServiceCallback<Void>)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizeTextInStream(byte [])
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizeTextInStream(byte [],Boolean)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizeTextInStreamAsync(byte [])
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizeTextInStreamAsync(byte [],Boolean)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizeTextInStreamAsync(byte [],Boolean,final ServiceCallback<Void>)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizeTextInStreamAsync(byte [],final ServiceCallback<Void>)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizeTextInStreamWithServiceResponseAsync(byte [])
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizeTextInStreamWithServiceResponseAsync(byte [],Boolean)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizeTextWithServiceResponseAsync(String)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizeTextWithServiceResponseAsync(String,Boolean)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.tagImage(String)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.tagImageAsync(String)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.tagImageAsync(String,final ServiceCallback<TagResultInner>)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.tagImageInStream(byte [])
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.tagImageInStreamAsync(byte [])
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.tagImageInStreamAsync(byte [],final ServiceCallback<TagResultInner>)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.tagImageInStreamWithServiceResponseAsync(byte [])
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.tagImageWithServiceResponseAsync(String)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.userAgent()
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.withAcceptLanguage(String)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.withAzureRegion(AzureRegions)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.withGenerateClientRequestId(boolean)
  - com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.withLongRunningOperationRetryTimeout(int)
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: ComputerVisionAPIImpl
  nameWithType: ComputerVisionAPIImpl
  fullName: com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl
  type: Class
  source:
    remote: &o0
      path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
      branch: master
      repo: https://github.com/Azure/azure-sdk-for-java
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 50
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: <p>Initializes a new instance of the <xref uid="com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl" data-throw-if-not-resolved="false">ComputerVisionAPIImpl</xref> class. </p>
  syntax: &o1
    content: public class ComputerVisionAPIImpl
  inheritance:
  - java.lang.Object
  - AzureServiceClient
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.acceptLanguage()
  id: acceptLanguage()
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: acceptLanguage()
  nameWithType: ComputerVisionAPIImpl.acceptLanguage()
  fullName: String com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.acceptLanguage()
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.acceptLanguage*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 95
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>Gets Gets or sets the preferred language for the response.</p>

    <p></p>
  syntax:
    content: public String acceptLanguage()
    return:
      type: "26831127"
      description: <p>the acceptLanguage value. </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImage(String)
  id: analyzeImage(String)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: analyzeImage(String url)
  nameWithType: ComputerVisionAPIImpl.analyzeImage(String url)
  fullName: ImageAnalysisInner com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.analyzeImage(String url)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImage*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 360
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>This operation extracts a rich set of visual features based on the image content. Two input methods are supported <ndash></ndash> (1) Uploading an image or (2) specifying an image URL. Within your request, there is an optional parameter to allow you to choose which features to return. By default, image categories are returned in the response.</p>

    <p></p>
  syntax:
    content: public ImageAnalysisInner analyzeImage(String url)
    parameters:
    - id: url
      type: "26831127"
      description: <p>the String value </p>
    return:
      type: com.microsoft.azure.cognitiveservices.computervision.implementation._image_analysis_inner
      description: <p>the <xref uid="com.microsoft.azure.cognitiveservices.computervision.implementation._image_analysis_inner" data-throw-if-not-resolved="false">ImageAnalysisInner</xref> object if successful. </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
  - type: com.microsoft.azure.cognitiveservices.computervision._computer_vision_error_exception
    description: <p>thrown if the request is rejected by server </p>
  - type: 9b2a4515
    description: <p>all other wrapped checked exceptions if the request fails to be sent </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImage(String,List<VisualFeatureTypes>,List<Details>,Language1)
  id: analyzeImage(String,List<VisualFeatureTypes>,List<Details>,Language1)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: analyzeImage(String url, List<VisualFeatureTypes> visualFeatures, List<Details> details, Language1 language)
  nameWithType: ComputerVisionAPIImpl.analyzeImage(String url, List<VisualFeatureTypes> visualFeatures, List<Details> details, Language1 language)
  fullName: ImageAnalysisInner com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.analyzeImage(String url, List<VisualFeatureTypes> visualFeatures, List<Details> details, Language1 language)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImage*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 440
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>This operation extracts a rich set of visual features based on the image content. Two input methods are supported <ndash></ndash> (1) Uploading an image or (2) specifying an image URL. Within your request, there is an optional parameter to allow you to choose which features to return. By default, image categories are returned in the response.</p>

    <p></p>
  syntax:
    content: public ImageAnalysisInner analyzeImage(String url, List<VisualFeatureTypes> visualFeatures, List<Details> details, Language1 language)
    parameters:
    - id: url
      type: "26831127"
      description: <p>the String value </p>
    - id: visualFeatures
      type: 5618da2dcom.microsoft.azure.cognitiveservices.computervision._visual_feature_typesa08ddfce
      description: <p>A string indicating what visual feature types to return. Multiple values should be comma-separated. Valid visual feature types include:Categories - categorizes image content according to a taxonomy defined in documentation. Tags - tags the image with a detailed list of words related to the image content. Description - describes the image content with a complete English sentence. Faces - detects if faces are present. If present, generate coordinates, gender and age. <xref uid="com.microsoft.azure.cognitiveservices.computervision._image_type" data-throw-if-not-resolved="false">ImageType</xref> - detects if image is clipart or a line drawing. Color - determines the accent color, dominant color, and whether an image is black&amp;white.Adult - detects if the image is pornographic in nature (depicts nudity or a sex act). Sexually suggestive content is also detected. </p>
    - id: details
      type: 5618da2dcom.microsoft.azure.cognitiveservices.computervision._detailsa08ddfce
      description: <p>A string indicating which domain-specific details to return. Multiple values should be comma-separated. Valid visual feature types include:Celebrities - identifies celebrities if detected in the image. </p>
    - id: language
      type: com.microsoft.azure.cognitiveservices.computervision._language1
      description: "<p>A string indicating which language to return. The service will return recognition results in specified language. If this parameter is not specified, the default value is &amp;quot;en&amp;quot;.Supported languages:en - English, Default.zh - Simplified Chinese. Possible values include: 'en', 'zh' </p>"
    return:
      type: com.microsoft.azure.cognitiveservices.computervision.implementation._image_analysis_inner
      description: <p>the <xref uid="com.microsoft.azure.cognitiveservices.computervision.implementation._image_analysis_inner" data-throw-if-not-resolved="false">ImageAnalysisInner</xref> object if successful. </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
  - type: com.microsoft.azure.cognitiveservices.computervision._computer_vision_error_exception
    description: <p>thrown if the request is rejected by server </p>
  - type: 9b2a4515
    description: <p>all other wrapped checked exceptions if the request fails to be sent </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageAsync(String)
  id: analyzeImageAsync(String)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: analyzeImageAsync(String url)
  nameWithType: ComputerVisionAPIImpl.analyzeImageAsync(String url)
  fullName: Observable<ImageAnalysisInner> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.analyzeImageAsync(String url)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 383
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>This operation extracts a rich set of visual features based on the image content. Two input methods are supported <ndash></ndash> (1) Uploading an image or (2) specifying an image URL. Within your request, there is an optional parameter to allow you to choose which features to return. By default, image categories are returned in the response.</p>

    <p></p>
  syntax:
    content: public Observable<ImageAnalysisInner> analyzeImageAsync(String url)
    parameters:
    - id: url
      type: "26831127"
      description: <p>the String value </p>
    return:
      type: c2d0e8c6com.microsoft.azure.cognitiveservices.computervision.implementation._image_analysis_innera08ddfce
      description: <p>the observable to the <xref uid="com.microsoft.azure.cognitiveservices.computervision.implementation._image_analysis_inner" data-throw-if-not-resolved="false">ImageAnalysisInner</xref> object </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageAsync(String,final ServiceCallback<ImageAnalysisInner>)
  id: analyzeImageAsync(String,final ServiceCallback<ImageAnalysisInner>)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: analyzeImageAsync(String url, final ServiceCallback<ImageAnalysisInner> serviceCallback)
  nameWithType: ComputerVisionAPIImpl.analyzeImageAsync(String url, final ServiceCallback<ImageAnalysisInner> serviceCallback)
  fullName: ServiceFuture<ImageAnalysisInner> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.analyzeImageAsync(String url, final ServiceCallback<ImageAnalysisInner> serviceCallback)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 372
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>This operation extracts a rich set of visual features based on the image content. Two input methods are supported <ndash></ndash> (1) Uploading an image or (2) specifying an image URL. Within your request, there is an optional parameter to allow you to choose which features to return. By default, image categories are returned in the response.</p>

    <p></p>
  syntax:
    content: public ServiceFuture<ImageAnalysisInner> analyzeImageAsync(String url, final ServiceCallback<ImageAnalysisInner> serviceCallback)
    parameters:
    - id: url
      type: "26831127"
      description: <p>the String value </p>
    - id: serviceCallback
      type: 897eb10acom.microsoft.azure.cognitiveservices.computervision.implementation._image_analysis_innera08ddfce
      description: <p>the async ServiceCallback to handle successful and failed responses. </p>
    return:
      type: c522ce07com.microsoft.azure.cognitiveservices.computervision.implementation._image_analysis_innera08ddfce
      description: <p>the <xref uid="" data-throw-if-not-resolved="false">ServiceFuture</xref> object </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageAsync(String,List<VisualFeatureTypes>,List<Details>,Language1)
  id: analyzeImageAsync(String,List<VisualFeatureTypes>,List<Details>,Language1)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: analyzeImageAsync(String url, List<VisualFeatureTypes> visualFeatures, List<Details> details, Language1 language)
  nameWithType: ComputerVisionAPIImpl.analyzeImageAsync(String url, List<VisualFeatureTypes> visualFeatures, List<Details> details, Language1 language)
  fullName: Observable<ImageAnalysisInner> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.analyzeImageAsync(String url, List<VisualFeatureTypes> visualFeatures, List<Details> details, Language1 language)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 469
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>This operation extracts a rich set of visual features based on the image content. Two input methods are supported <ndash></ndash> (1) Uploading an image or (2) specifying an image URL. Within your request, there is an optional parameter to allow you to choose which features to return. By default, image categories are returned in the response.</p>

    <p></p>
  syntax:
    content: public Observable<ImageAnalysisInner> analyzeImageAsync(String url, List<VisualFeatureTypes> visualFeatures, List<Details> details, Language1 language)
    parameters:
    - id: url
      type: "26831127"
      description: <p>the String value </p>
    - id: visualFeatures
      type: 5618da2dcom.microsoft.azure.cognitiveservices.computervision._visual_feature_typesa08ddfce
      description: <p>A string indicating what visual feature types to return. Multiple values should be comma-separated. Valid visual feature types include:Categories - categorizes image content according to a taxonomy defined in documentation. Tags - tags the image with a detailed list of words related to the image content. Description - describes the image content with a complete English sentence. Faces - detects if faces are present. If present, generate coordinates, gender and age. <xref uid="com.microsoft.azure.cognitiveservices.computervision._image_type" data-throw-if-not-resolved="false">ImageType</xref> - detects if image is clipart or a line drawing. Color - determines the accent color, dominant color, and whether an image is black&amp;white.Adult - detects if the image is pornographic in nature (depicts nudity or a sex act). Sexually suggestive content is also detected. </p>
    - id: details
      type: 5618da2dcom.microsoft.azure.cognitiveservices.computervision._detailsa08ddfce
      description: <p>A string indicating which domain-specific details to return. Multiple values should be comma-separated. Valid visual feature types include:Celebrities - identifies celebrities if detected in the image. </p>
    - id: language
      type: com.microsoft.azure.cognitiveservices.computervision._language1
      description: "<p>A string indicating which language to return. The service will return recognition results in specified language. If this parameter is not specified, the default value is &amp;quot;en&amp;quot;.Supported languages:en - English, Default.zh - Simplified Chinese. Possible values include: 'en', 'zh' </p>"
    return:
      type: c2d0e8c6com.microsoft.azure.cognitiveservices.computervision.implementation._image_analysis_innera08ddfce
      description: <p>the observable to the <xref uid="com.microsoft.azure.cognitiveservices.computervision.implementation._image_analysis_inner" data-throw-if-not-resolved="false">ImageAnalysisInner</xref> object </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageAsync(String,List<VisualFeatureTypes>,List<Details>,Language1,final ServiceCallback<ImageAnalysisInner>)
  id: analyzeImageAsync(String,List<VisualFeatureTypes>,List<Details>,Language1,final ServiceCallback<ImageAnalysisInner>)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: analyzeImageAsync(String url, List<VisualFeatureTypes> visualFeatures, List<Details> details, Language1 language, final ServiceCallback<ImageAnalysisInner> serviceCallback)
  nameWithType: ComputerVisionAPIImpl.analyzeImageAsync(String url, List<VisualFeatureTypes> visualFeatures, List<Details> details, Language1 language, final ServiceCallback<ImageAnalysisInner> serviceCallback)
  fullName: ServiceFuture<ImageAnalysisInner> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.analyzeImageAsync(String url, List<VisualFeatureTypes> visualFeatures, List<Details> details, Language1 language, final ServiceCallback<ImageAnalysisInner> serviceCallback)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 455
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>This operation extracts a rich set of visual features based on the image content. Two input methods are supported <ndash></ndash> (1) Uploading an image or (2) specifying an image URL. Within your request, there is an optional parameter to allow you to choose which features to return. By default, image categories are returned in the response.</p>

    <p></p>
  syntax:
    content: public ServiceFuture<ImageAnalysisInner> analyzeImageAsync(String url, List<VisualFeatureTypes> visualFeatures, List<Details> details, Language1 language, final ServiceCallback<ImageAnalysisInner> serviceCallback)
    parameters:
    - id: url
      type: "26831127"
      description: <p>the String value </p>
    - id: visualFeatures
      type: 5618da2dcom.microsoft.azure.cognitiveservices.computervision._visual_feature_typesa08ddfce
      description: <p>A string indicating what visual feature types to return. Multiple values should be comma-separated. Valid visual feature types include:Categories - categorizes image content according to a taxonomy defined in documentation. Tags - tags the image with a detailed list of words related to the image content. Description - describes the image content with a complete English sentence. Faces - detects if faces are present. If present, generate coordinates, gender and age. <xref uid="com.microsoft.azure.cognitiveservices.computervision._image_type" data-throw-if-not-resolved="false">ImageType</xref> - detects if image is clipart or a line drawing. Color - determines the accent color, dominant color, and whether an image is black&amp;white.Adult - detects if the image is pornographic in nature (depicts nudity or a sex act). Sexually suggestive content is also detected. </p>
    - id: details
      type: 5618da2dcom.microsoft.azure.cognitiveservices.computervision._detailsa08ddfce
      description: <p>A string indicating which domain-specific details to return. Multiple values should be comma-separated. Valid visual feature types include:Celebrities - identifies celebrities if detected in the image. </p>
    - id: language
      type: com.microsoft.azure.cognitiveservices.computervision._language1
      description: "<p>A string indicating which language to return. The service will return recognition results in specified language. If this parameter is not specified, the default value is &amp;quot;en&amp;quot;.Supported languages:en - English, Default.zh - Simplified Chinese. Possible values include: 'en', 'zh' </p>"
    - id: serviceCallback
      type: 897eb10acom.microsoft.azure.cognitiveservices.computervision.implementation._image_analysis_innera08ddfce
      description: <p>the async ServiceCallback to handle successful and failed responses. </p>
    return:
      type: c522ce07com.microsoft.azure.cognitiveservices.computervision.implementation._image_analysis_innera08ddfce
      description: <p>the <xref uid="" data-throw-if-not-resolved="false">ServiceFuture</xref> object </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageByDomain(DomainModels,String)
  id: analyzeImageByDomain(DomainModels,String)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: analyzeImageByDomain(DomainModels model, String url)
  nameWithType: ComputerVisionAPIImpl.analyzeImageByDomain(DomainModels model, String url)
  fullName: DomainModelResultsInner com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.analyzeImageByDomain(DomainModels model, String url)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageByDomain*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 1104
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>This operation recognizes content within an image by applying a domain-specific model. The list of domain-specific models that are supported by the Computer Vision API can be retrieved using the /models GET request. Currently, the API only provides a single domain-specific model: celebrities. Two input methods are supported <ndash></ndash> (1) Uploading an image or (2) specifying an image URL. A successful response will be returned in JSON. If the request failed, the response will contain an error code and a message to help understand what went wrong.</p>

    <p></p>
  syntax:
    content: public DomainModelResultsInner analyzeImageByDomain(DomainModels model, String url)
    parameters:
    - id: model
      type: com.microsoft.azure.cognitiveservices.computervision._domain_models
      description: "<p>The domain-specific content to recognize. Possible values include: 'Celebrities', 'Landmarks' </p>"
    - id: url
      type: "26831127"
      description: <p>the String value </p>
    return:
      type: com.microsoft.azure.cognitiveservices.computervision.implementation._domain_model_results_inner
      description: <p>the <xref uid="com.microsoft.azure.cognitiveservices.computervision.implementation._domain_model_results_inner" data-throw-if-not-resolved="false">DomainModelResultsInner</xref> object if successful. </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
  - type: com.microsoft.azure.cognitiveservices.computervision._computer_vision_error_exception
    description: <p>thrown if the request is rejected by server </p>
  - type: 9b2a4515
    description: <p>all other wrapped checked exceptions if the request fails to be sent </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageByDomainAsync(DomainModels,String)
  id: analyzeImageByDomainAsync(DomainModels,String)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: analyzeImageByDomainAsync(DomainModels model, String url)
  nameWithType: ComputerVisionAPIImpl.analyzeImageByDomainAsync(DomainModels model, String url)
  fullName: Observable<DomainModelResultsInner> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.analyzeImageByDomainAsync(DomainModels model, String url)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageByDomainAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 1129
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>This operation recognizes content within an image by applying a domain-specific model. The list of domain-specific models that are supported by the Computer Vision API can be retrieved using the /models GET request. Currently, the API only provides a single domain-specific model: celebrities. Two input methods are supported <ndash></ndash> (1) Uploading an image or (2) specifying an image URL. A successful response will be returned in JSON. If the request failed, the response will contain an error code and a message to help understand what went wrong.</p>

    <p></p>
  syntax:
    content: public Observable<DomainModelResultsInner> analyzeImageByDomainAsync(DomainModels model, String url)
    parameters:
    - id: model
      type: com.microsoft.azure.cognitiveservices.computervision._domain_models
      description: "<p>The domain-specific content to recognize. Possible values include: 'Celebrities', 'Landmarks' </p>"
    - id: url
      type: "26831127"
      description: <p>the String value </p>
    return:
      type: c2d0e8c6com.microsoft.azure.cognitiveservices.computervision.implementation._domain_model_results_innera08ddfce
      description: <p>the observable to the <xref uid="com.microsoft.azure.cognitiveservices.computervision.implementation._domain_model_results_inner" data-throw-if-not-resolved="false">DomainModelResultsInner</xref> object </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageByDomainAsync(DomainModels,String,final ServiceCallback<DomainModelResultsInner>)
  id: analyzeImageByDomainAsync(DomainModels,String,final ServiceCallback<DomainModelResultsInner>)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: analyzeImageByDomainAsync(DomainModels model, String url, final ServiceCallback<DomainModelResultsInner> serviceCallback)
  nameWithType: ComputerVisionAPIImpl.analyzeImageByDomainAsync(DomainModels model, String url, final ServiceCallback<DomainModelResultsInner> serviceCallback)
  fullName: ServiceFuture<DomainModelResultsInner> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.analyzeImageByDomainAsync(DomainModels model, String url, final ServiceCallback<DomainModelResultsInner> serviceCallback)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageByDomainAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 1117
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>This operation recognizes content within an image by applying a domain-specific model. The list of domain-specific models that are supported by the Computer Vision API can be retrieved using the /models GET request. Currently, the API only provides a single domain-specific model: celebrities. Two input methods are supported <ndash></ndash> (1) Uploading an image or (2) specifying an image URL. A successful response will be returned in JSON. If the request failed, the response will contain an error code and a message to help understand what went wrong.</p>

    <p></p>
  syntax:
    content: public ServiceFuture<DomainModelResultsInner> analyzeImageByDomainAsync(DomainModels model, String url, final ServiceCallback<DomainModelResultsInner> serviceCallback)
    parameters:
    - id: model
      type: com.microsoft.azure.cognitiveservices.computervision._domain_models
      description: "<p>The domain-specific content to recognize. Possible values include: 'Celebrities', 'Landmarks' </p>"
    - id: url
      type: "26831127"
      description: <p>the String value </p>
    - id: serviceCallback
      type: 897eb10acom.microsoft.azure.cognitiveservices.computervision.implementation._domain_model_results_innera08ddfce
      description: <p>the async ServiceCallback to handle successful and failed responses. </p>
    return:
      type: c522ce07com.microsoft.azure.cognitiveservices.computervision.implementation._domain_model_results_innera08ddfce
      description: <p>the <xref uid="" data-throw-if-not-resolved="false">ServiceFuture</xref> object </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageByDomainInStream(String,byte [])
  id: analyzeImageByDomainInStream(String,byte [])
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: analyzeImageByDomainInStream(String model, byte[] image)
  nameWithType: ComputerVisionAPIImpl.analyzeImageByDomainInStream(String model, byte[] image)
  fullName: DomainModelResultsInner com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.analyzeImageByDomainInStream(String model, byte[] image)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageByDomainInStream*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 2152
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>This operation recognizes content within an image by applying a domain-specific model. The list of domain-specific models that are supported by the Computer Vision API can be retrieved using the /models GET request. Currently, the API only provides a single domain-specific model: celebrities. Two input methods are supported <ndash></ndash> (1) Uploading an image or (2) specifying an image URL. A successful response will be returned in JSON. If the request failed, the response will contain an error code and a message to help understand what went wrong.</p>

    <p></p>
  syntax:
    content: public DomainModelResultsInner analyzeImageByDomainInStream(String model, byte[] image)
    parameters:
    - id: model
      type: "26831127"
      description: <p>The domain-specific content to recognize. </p>
    - id: image
      type: ccd9418d
      description: <p>An image stream. </p>
    return:
      type: com.microsoft.azure.cognitiveservices.computervision.implementation._domain_model_results_inner
      description: <p>the <xref uid="com.microsoft.azure.cognitiveservices.computervision.implementation._domain_model_results_inner" data-throw-if-not-resolved="false">DomainModelResultsInner</xref> object if successful. </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
  - type: com.microsoft.azure.cognitiveservices.computervision._computer_vision_error_exception
    description: <p>thrown if the request is rejected by server </p>
  - type: 9b2a4515
    description: <p>all other wrapped checked exceptions if the request fails to be sent </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageByDomainInStreamAsync(String,byte [])
  id: analyzeImageByDomainInStreamAsync(String,byte [])
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: analyzeImageByDomainInStreamAsync(String model, byte[] image)
  nameWithType: ComputerVisionAPIImpl.analyzeImageByDomainInStreamAsync(String model, byte[] image)
  fullName: Observable<DomainModelResultsInner> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.analyzeImageByDomainInStreamAsync(String model, byte[] image)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageByDomainInStreamAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 2177
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>This operation recognizes content within an image by applying a domain-specific model. The list of domain-specific models that are supported by the Computer Vision API can be retrieved using the /models GET request. Currently, the API only provides a single domain-specific model: celebrities. Two input methods are supported <ndash></ndash> (1) Uploading an image or (2) specifying an image URL. A successful response will be returned in JSON. If the request failed, the response will contain an error code and a message to help understand what went wrong.</p>

    <p></p>
  syntax:
    content: public Observable<DomainModelResultsInner> analyzeImageByDomainInStreamAsync(String model, byte[] image)
    parameters:
    - id: model
      type: "26831127"
      description: <p>The domain-specific content to recognize. </p>
    - id: image
      type: ccd9418d
      description: <p>An image stream. </p>
    return:
      type: c2d0e8c6com.microsoft.azure.cognitiveservices.computervision.implementation._domain_model_results_innera08ddfce
      description: <p>the observable to the <xref uid="com.microsoft.azure.cognitiveservices.computervision.implementation._domain_model_results_inner" data-throw-if-not-resolved="false">DomainModelResultsInner</xref> object </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageByDomainInStreamAsync(String,byte [],final ServiceCallback<DomainModelResultsInner>)
  id: analyzeImageByDomainInStreamAsync(String,byte [],final ServiceCallback<DomainModelResultsInner>)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: analyzeImageByDomainInStreamAsync(String model, byte[] image, final ServiceCallback<DomainModelResultsInner> serviceCallback)
  nameWithType: ComputerVisionAPIImpl.analyzeImageByDomainInStreamAsync(String model, byte[] image, final ServiceCallback<DomainModelResultsInner> serviceCallback)
  fullName: ServiceFuture<DomainModelResultsInner> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.analyzeImageByDomainInStreamAsync(String model, byte[] image, final ServiceCallback<DomainModelResultsInner> serviceCallback)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageByDomainInStreamAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 2165
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>This operation recognizes content within an image by applying a domain-specific model. The list of domain-specific models that are supported by the Computer Vision API can be retrieved using the /models GET request. Currently, the API only provides a single domain-specific model: celebrities. Two input methods are supported <ndash></ndash> (1) Uploading an image or (2) specifying an image URL. A successful response will be returned in JSON. If the request failed, the response will contain an error code and a message to help understand what went wrong.</p>

    <p></p>
  syntax:
    content: public ServiceFuture<DomainModelResultsInner> analyzeImageByDomainInStreamAsync(String model, byte[] image, final ServiceCallback<DomainModelResultsInner> serviceCallback)
    parameters:
    - id: model
      type: "26831127"
      description: <p>The domain-specific content to recognize. </p>
    - id: image
      type: ccd9418d
      description: <p>An image stream. </p>
    - id: serviceCallback
      type: 897eb10acom.microsoft.azure.cognitiveservices.computervision.implementation._domain_model_results_innera08ddfce
      description: <p>the async ServiceCallback to handle successful and failed responses. </p>
    return:
      type: c522ce07com.microsoft.azure.cognitiveservices.computervision.implementation._domain_model_results_innera08ddfce
      description: <p>the <xref uid="" data-throw-if-not-resolved="false">ServiceFuture</xref> object </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageByDomainInStreamWithServiceResponseAsync(String,byte [])
  id: analyzeImageByDomainInStreamWithServiceResponseAsync(String,byte [])
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: analyzeImageByDomainInStreamWithServiceResponseAsync(String model, byte[] image)
  nameWithType: ComputerVisionAPIImpl.analyzeImageByDomainInStreamWithServiceResponseAsync(String model, byte[] image)
  fullName: Observable<ServiceResponse<DomainModelResultsInner>> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.analyzeImageByDomainInStreamWithServiceResponseAsync(String model, byte[] image)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageByDomainInStreamWithServiceResponseAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 2194
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>This operation recognizes content within an image by applying a domain-specific model. The list of domain-specific models that are supported by the Computer Vision API can be retrieved using the /models GET request. Currently, the API only provides a single domain-specific model: celebrities. Two input methods are supported <ndash></ndash> (1) Uploading an image or (2) specifying an image URL. A successful response will be returned in JSON. If the request failed, the response will contain an error code and a message to help understand what went wrong.</p>

    <p></p>
  syntax:
    content: public Observable<ServiceResponse<DomainModelResultsInner>> analyzeImageByDomainInStreamWithServiceResponseAsync(String model, byte[] image)
    parameters:
    - id: model
      type: "26831127"
      description: <p>The domain-specific content to recognize. </p>
    - id: image
      type: ccd9418d
      description: <p>An image stream. </p>
    return:
      type: fc480ba2com.microsoft.azure.cognitiveservices.computervision.implementation._domain_model_results_innere7daa122
      description: <p>the observable to the <xref uid="com.microsoft.azure.cognitiveservices.computervision.implementation._domain_model_results_inner" data-throw-if-not-resolved="false">DomainModelResultsInner</xref> object </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageByDomainWithServiceResponseAsync(DomainModels,String)
  id: analyzeImageByDomainWithServiceResponseAsync(DomainModels,String)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: analyzeImageByDomainWithServiceResponseAsync(DomainModels model, String url)
  nameWithType: ComputerVisionAPIImpl.analyzeImageByDomainWithServiceResponseAsync(DomainModels model, String url)
  fullName: Observable<ServiceResponse<DomainModelResultsInner>> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.analyzeImageByDomainWithServiceResponseAsync(DomainModels model, String url)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageByDomainWithServiceResponseAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 1146
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>This operation recognizes content within an image by applying a domain-specific model. The list of domain-specific models that are supported by the Computer Vision API can be retrieved using the /models GET request. Currently, the API only provides a single domain-specific model: celebrities. Two input methods are supported <ndash></ndash> (1) Uploading an image or (2) specifying an image URL. A successful response will be returned in JSON. If the request failed, the response will contain an error code and a message to help understand what went wrong.</p>

    <p></p>
  syntax:
    content: public Observable<ServiceResponse<DomainModelResultsInner>> analyzeImageByDomainWithServiceResponseAsync(DomainModels model, String url)
    parameters:
    - id: model
      type: com.microsoft.azure.cognitiveservices.computervision._domain_models
      description: "<p>The domain-specific content to recognize. Possible values include: 'Celebrities', 'Landmarks' </p>"
    - id: url
      type: "26831127"
      description: <p>the String value </p>
    return:
      type: fc480ba2com.microsoft.azure.cognitiveservices.computervision.implementation._domain_model_results_innere7daa122
      description: <p>the observable to the <xref uid="com.microsoft.azure.cognitiveservices.computervision.implementation._domain_model_results_inner" data-throw-if-not-resolved="false">DomainModelResultsInner</xref> object </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageInStream(byte [])
  id: analyzeImageInStream(byte [])
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: analyzeImageInStream(byte[] image)
  nameWithType: ComputerVisionAPIImpl.analyzeImageInStream(byte[] image)
  fullName: ImageAnalysisInner com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.analyzeImageInStream(byte[] image)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageInStream*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 1420
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>This operation extracts a rich set of visual features based on the image content.</p>

    <p></p>
  syntax:
    content: public ImageAnalysisInner analyzeImageInStream(byte[] image)
    parameters:
    - id: image
      type: ccd9418d
      description: <p>An image stream. </p>
    return:
      type: com.microsoft.azure.cognitiveservices.computervision.implementation._image_analysis_inner
      description: <p>the <xref uid="com.microsoft.azure.cognitiveservices.computervision.implementation._image_analysis_inner" data-throw-if-not-resolved="false">ImageAnalysisInner</xref> object if successful. </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
  - type: com.microsoft.azure.cognitiveservices.computervision._computer_vision_error_exception
    description: <p>thrown if the request is rejected by server </p>
  - type: 9b2a4515
    description: <p>all other wrapped checked exceptions if the request fails to be sent </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageInStream(byte [],List<VisualFeatureTypes>,String,String)
  id: analyzeImageInStream(byte [],List<VisualFeatureTypes>,String,String)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: analyzeImageInStream(byte[] image, List<VisualFeatureTypes> visualFeatures, String details, String language)
  nameWithType: ComputerVisionAPIImpl.analyzeImageInStream(byte[] image, List<VisualFeatureTypes> visualFeatures, String details, String language)
  fullName: ImageAnalysisInner com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.analyzeImageInStream(byte[] image, List<VisualFeatureTypes> visualFeatures, String details, String language)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageInStream*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 1498
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>This operation extracts a rich set of visual features based on the image content.</p>

    <p></p>
  syntax:
    content: public ImageAnalysisInner analyzeImageInStream(byte[] image, List<VisualFeatureTypes> visualFeatures, String details, String language)
    parameters:
    - id: image
      type: ccd9418d
      description: <p>An image stream. </p>
    - id: visualFeatures
      type: 5618da2dcom.microsoft.azure.cognitiveservices.computervision._visual_feature_typesa08ddfce
      description: <p>A string indicating what visual feature types to return. Multiple values should be comma-separated. Valid visual feature types include:Categories - categorizes image content according to a taxonomy defined in documentation. Tags - tags the image with a detailed list of words related to the image content. Description - describes the image content with a complete English sentence. Faces - detects if faces are present. If present, generate coordinates, gender and age. <xref uid="com.microsoft.azure.cognitiveservices.computervision._image_type" data-throw-if-not-resolved="false">ImageType</xref> - detects if image is clipart or a line drawing. Color - determines the accent color, dominant color, and whether an image is black&amp;white.Adult - detects if the image is pornographic in nature (depicts nudity or a sex act). Sexually suggestive content is also detected. </p>
    - id: details
      type: "26831127"
      description: "<p>A string indicating which domain-specific details to return. Multiple values should be comma-separated. Valid visual feature types include:Celebrities - identifies celebrities if detected in the image. Possible values include: 'Celebrities', 'Landmarks' </p>"
    - id: language
      type: "26831127"
      description: "<p>A string indicating which language to return. The service will return recognition results in specified language. If this parameter is not specified, the default value is &amp;quot;en&amp;quot;.Supported languages:en - English, Default.zh - Simplified Chinese. Possible values include: 'en', 'zh' </p>"
    return:
      type: com.microsoft.azure.cognitiveservices.computervision.implementation._image_analysis_inner
      description: <p>the <xref uid="com.microsoft.azure.cognitiveservices.computervision.implementation._image_analysis_inner" data-throw-if-not-resolved="false">ImageAnalysisInner</xref> object if successful. </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
  - type: com.microsoft.azure.cognitiveservices.computervision._computer_vision_error_exception
    description: <p>thrown if the request is rejected by server </p>
  - type: 9b2a4515
    description: <p>all other wrapped checked exceptions if the request fails to be sent </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageInStreamAsync(byte [])
  id: analyzeImageInStreamAsync(byte [])
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: analyzeImageInStreamAsync(byte[] image)
  nameWithType: ComputerVisionAPIImpl.analyzeImageInStreamAsync(byte[] image)
  fullName: Observable<ImageAnalysisInner> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.analyzeImageInStreamAsync(byte[] image)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageInStreamAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 1443
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>This operation extracts a rich set of visual features based on the image content.</p>

    <p></p>
  syntax:
    content: public Observable<ImageAnalysisInner> analyzeImageInStreamAsync(byte[] image)
    parameters:
    - id: image
      type: ccd9418d
      description: <p>An image stream. </p>
    return:
      type: c2d0e8c6com.microsoft.azure.cognitiveservices.computervision.implementation._image_analysis_innera08ddfce
      description: <p>the observable to the <xref uid="com.microsoft.azure.cognitiveservices.computervision.implementation._image_analysis_inner" data-throw-if-not-resolved="false">ImageAnalysisInner</xref> object </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageInStreamAsync(byte [],final ServiceCallback<ImageAnalysisInner>)
  id: analyzeImageInStreamAsync(byte [],final ServiceCallback<ImageAnalysisInner>)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: analyzeImageInStreamAsync(byte[] image, final ServiceCallback<ImageAnalysisInner> serviceCallback)
  nameWithType: ComputerVisionAPIImpl.analyzeImageInStreamAsync(byte[] image, final ServiceCallback<ImageAnalysisInner> serviceCallback)
  fullName: ServiceFuture<ImageAnalysisInner> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.analyzeImageInStreamAsync(byte[] image, final ServiceCallback<ImageAnalysisInner> serviceCallback)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageInStreamAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 1432
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>This operation extracts a rich set of visual features based on the image content.</p>

    <p></p>
  syntax:
    content: public ServiceFuture<ImageAnalysisInner> analyzeImageInStreamAsync(byte[] image, final ServiceCallback<ImageAnalysisInner> serviceCallback)
    parameters:
    - id: image
      type: ccd9418d
      description: <p>An image stream. </p>
    - id: serviceCallback
      type: 897eb10acom.microsoft.azure.cognitiveservices.computervision.implementation._image_analysis_innera08ddfce
      description: <p>the async ServiceCallback to handle successful and failed responses. </p>
    return:
      type: c522ce07com.microsoft.azure.cognitiveservices.computervision.implementation._image_analysis_innera08ddfce
      description: <p>the <xref uid="" data-throw-if-not-resolved="false">ServiceFuture</xref> object </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageInStreamAsync(byte [],List<VisualFeatureTypes>,String,String)
  id: analyzeImageInStreamAsync(byte [],List<VisualFeatureTypes>,String,String)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: analyzeImageInStreamAsync(byte[] image, List<VisualFeatureTypes> visualFeatures, String details, String language)
  nameWithType: ComputerVisionAPIImpl.analyzeImageInStreamAsync(byte[] image, List<VisualFeatureTypes> visualFeatures, String details, String language)
  fullName: Observable<ImageAnalysisInner> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.analyzeImageInStreamAsync(byte[] image, List<VisualFeatureTypes> visualFeatures, String details, String language)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageInStreamAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 1527
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>This operation extracts a rich set of visual features based on the image content.</p>

    <p></p>
  syntax:
    content: public Observable<ImageAnalysisInner> analyzeImageInStreamAsync(byte[] image, List<VisualFeatureTypes> visualFeatures, String details, String language)
    parameters:
    - id: image
      type: ccd9418d
      description: <p>An image stream. </p>
    - id: visualFeatures
      type: 5618da2dcom.microsoft.azure.cognitiveservices.computervision._visual_feature_typesa08ddfce
      description: <p>A string indicating what visual feature types to return. Multiple values should be comma-separated. Valid visual feature types include:Categories - categorizes image content according to a taxonomy defined in documentation. Tags - tags the image with a detailed list of words related to the image content. Description - describes the image content with a complete English sentence. Faces - detects if faces are present. If present, generate coordinates, gender and age. <xref uid="com.microsoft.azure.cognitiveservices.computervision._image_type" data-throw-if-not-resolved="false">ImageType</xref> - detects if image is clipart or a line drawing. Color - determines the accent color, dominant color, and whether an image is black&amp;white.Adult - detects if the image is pornographic in nature (depicts nudity or a sex act). Sexually suggestive content is also detected. </p>
    - id: details
      type: "26831127"
      description: "<p>A string indicating which domain-specific details to return. Multiple values should be comma-separated. Valid visual feature types include:Celebrities - identifies celebrities if detected in the image. Possible values include: 'Celebrities', 'Landmarks' </p>"
    - id: language
      type: "26831127"
      description: "<p>A string indicating which language to return. The service will return recognition results in specified language. If this parameter is not specified, the default value is &amp;quot;en&amp;quot;.Supported languages:en - English, Default.zh - Simplified Chinese. Possible values include: 'en', 'zh' </p>"
    return:
      type: c2d0e8c6com.microsoft.azure.cognitiveservices.computervision.implementation._image_analysis_innera08ddfce
      description: <p>the observable to the <xref uid="com.microsoft.azure.cognitiveservices.computervision.implementation._image_analysis_inner" data-throw-if-not-resolved="false">ImageAnalysisInner</xref> object </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageInStreamAsync(byte [],List<VisualFeatureTypes>,String,String,final ServiceCallback<ImageAnalysisInner>)
  id: analyzeImageInStreamAsync(byte [],List<VisualFeatureTypes>,String,String,final ServiceCallback<ImageAnalysisInner>)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: analyzeImageInStreamAsync(byte[] image, List<VisualFeatureTypes> visualFeatures, String details, String language, final ServiceCallback<ImageAnalysisInner> serviceCallback)
  nameWithType: ComputerVisionAPIImpl.analyzeImageInStreamAsync(byte[] image, List<VisualFeatureTypes> visualFeatures, String details, String language, final ServiceCallback<ImageAnalysisInner> serviceCallback)
  fullName: ServiceFuture<ImageAnalysisInner> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.analyzeImageInStreamAsync(byte[] image, List<VisualFeatureTypes> visualFeatures, String details, String language, final ServiceCallback<ImageAnalysisInner> serviceCallback)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageInStreamAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 1513
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>This operation extracts a rich set of visual features based on the image content.</p>

    <p></p>
  syntax:
    content: public ServiceFuture<ImageAnalysisInner> analyzeImageInStreamAsync(byte[] image, List<VisualFeatureTypes> visualFeatures, String details, String language, final ServiceCallback<ImageAnalysisInner> serviceCallback)
    parameters:
    - id: image
      type: ccd9418d
      description: <p>An image stream. </p>
    - id: visualFeatures
      type: 5618da2dcom.microsoft.azure.cognitiveservices.computervision._visual_feature_typesa08ddfce
      description: <p>A string indicating what visual feature types to return. Multiple values should be comma-separated. Valid visual feature types include:Categories - categorizes image content according to a taxonomy defined in documentation. Tags - tags the image with a detailed list of words related to the image content. Description - describes the image content with a complete English sentence. Faces - detects if faces are present. If present, generate coordinates, gender and age. <xref uid="com.microsoft.azure.cognitiveservices.computervision._image_type" data-throw-if-not-resolved="false">ImageType</xref> - detects if image is clipart or a line drawing. Color - determines the accent color, dominant color, and whether an image is black&amp;white.Adult - detects if the image is pornographic in nature (depicts nudity or a sex act). Sexually suggestive content is also detected. </p>
    - id: details
      type: "26831127"
      description: "<p>A string indicating which domain-specific details to return. Multiple values should be comma-separated. Valid visual feature types include:Celebrities - identifies celebrities if detected in the image. Possible values include: 'Celebrities', 'Landmarks' </p>"
    - id: language
      type: "26831127"
      description: "<p>A string indicating which language to return. The service will return recognition results in specified language. If this parameter is not specified, the default value is &amp;quot;en&amp;quot;.Supported languages:en - English, Default.zh - Simplified Chinese. Possible values include: 'en', 'zh' </p>"
    - id: serviceCallback
      type: 897eb10acom.microsoft.azure.cognitiveservices.computervision.implementation._image_analysis_innera08ddfce
      description: <p>the async ServiceCallback to handle successful and failed responses. </p>
    return:
      type: c522ce07com.microsoft.azure.cognitiveservices.computervision.implementation._image_analysis_innera08ddfce
      description: <p>the <xref uid="" data-throw-if-not-resolved="false">ServiceFuture</xref> object </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageInStreamWithServiceResponseAsync(byte [])
  id: analyzeImageInStreamWithServiceResponseAsync(byte [])
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: analyzeImageInStreamWithServiceResponseAsync(byte[] image)
  nameWithType: ComputerVisionAPIImpl.analyzeImageInStreamWithServiceResponseAsync(byte[] image)
  fullName: Observable<ServiceResponse<ImageAnalysisInner>> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.analyzeImageInStreamWithServiceResponseAsync(byte[] image)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageInStreamWithServiceResponseAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 1459
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>This operation extracts a rich set of visual features based on the image content.</p>

    <p></p>
  syntax:
    content: public Observable<ServiceResponse<ImageAnalysisInner>> analyzeImageInStreamWithServiceResponseAsync(byte[] image)
    parameters:
    - id: image
      type: ccd9418d
      description: <p>An image stream. </p>
    return:
      type: fc480ba2com.microsoft.azure.cognitiveservices.computervision.implementation._image_analysis_innere7daa122
      description: <p>the observable to the <xref uid="com.microsoft.azure.cognitiveservices.computervision.implementation._image_analysis_inner" data-throw-if-not-resolved="false">ImageAnalysisInner</xref> object </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageInStreamWithServiceResponseAsync(byte [],List<VisualFeatureTypes>,String,String)
  id: analyzeImageInStreamWithServiceResponseAsync(byte [],List<VisualFeatureTypes>,String,String)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: analyzeImageInStreamWithServiceResponseAsync(byte[] image, List<VisualFeatureTypes> visualFeatures, String details, String language)
  nameWithType: ComputerVisionAPIImpl.analyzeImageInStreamWithServiceResponseAsync(byte[] image, List<VisualFeatureTypes> visualFeatures, String details, String language)
  fullName: Observable<ServiceResponse<ImageAnalysisInner>> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.analyzeImageInStreamWithServiceResponseAsync(byte[] image, List<VisualFeatureTypes> visualFeatures, String details, String language)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageInStreamWithServiceResponseAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 1546
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>This operation extracts a rich set of visual features based on the image content.</p>

    <p></p>
  syntax:
    content: public Observable<ServiceResponse<ImageAnalysisInner>> analyzeImageInStreamWithServiceResponseAsync(byte[] image, List<VisualFeatureTypes> visualFeatures, String details, String language)
    parameters:
    - id: image
      type: ccd9418d
      description: <p>An image stream. </p>
    - id: visualFeatures
      type: 5618da2dcom.microsoft.azure.cognitiveservices.computervision._visual_feature_typesa08ddfce
      description: <p>A string indicating what visual feature types to return. Multiple values should be comma-separated. Valid visual feature types include:Categories - categorizes image content according to a taxonomy defined in documentation. Tags - tags the image with a detailed list of words related to the image content. Description - describes the image content with a complete English sentence. Faces - detects if faces are present. If present, generate coordinates, gender and age. <xref uid="com.microsoft.azure.cognitiveservices.computervision._image_type" data-throw-if-not-resolved="false">ImageType</xref> - detects if image is clipart or a line drawing. Color - determines the accent color, dominant color, and whether an image is black&amp;white.Adult - detects if the image is pornographic in nature (depicts nudity or a sex act). Sexually suggestive content is also detected. </p>
    - id: details
      type: "26831127"
      description: "<p>A string indicating which domain-specific details to return. Multiple values should be comma-separated. Valid visual feature types include:Celebrities - identifies celebrities if detected in the image. Possible values include: 'Celebrities', 'Landmarks' </p>"
    - id: language
      type: "26831127"
      description: "<p>A string indicating which language to return. The service will return recognition results in specified language. If this parameter is not specified, the default value is &amp;quot;en&amp;quot;.Supported languages:en - English, Default.zh - Simplified Chinese. Possible values include: 'en', 'zh' </p>"
    return:
      type: fc480ba2com.microsoft.azure.cognitiveservices.computervision.implementation._image_analysis_innere7daa122
      description: <p>the observable to the <xref uid="com.microsoft.azure.cognitiveservices.computervision.implementation._image_analysis_inner" data-throw-if-not-resolved="false">ImageAnalysisInner</xref> object </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageWithServiceResponseAsync(String)
  id: analyzeImageWithServiceResponseAsync(String)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: analyzeImageWithServiceResponseAsync(String url)
  nameWithType: ComputerVisionAPIImpl.analyzeImageWithServiceResponseAsync(String url)
  fullName: Observable<ServiceResponse<ImageAnalysisInner>> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.analyzeImageWithServiceResponseAsync(String url)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageWithServiceResponseAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 399
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>This operation extracts a rich set of visual features based on the image content. Two input methods are supported <ndash></ndash> (1) Uploading an image or (2) specifying an image URL. Within your request, there is an optional parameter to allow you to choose which features to return. By default, image categories are returned in the response.</p>

    <p></p>
  syntax:
    content: public Observable<ServiceResponse<ImageAnalysisInner>> analyzeImageWithServiceResponseAsync(String url)
    parameters:
    - id: url
      type: "26831127"
      description: <p>the String value </p>
    return:
      type: fc480ba2com.microsoft.azure.cognitiveservices.computervision.implementation._image_analysis_innere7daa122
      description: <p>the observable to the <xref uid="com.microsoft.azure.cognitiveservices.computervision.implementation._image_analysis_inner" data-throw-if-not-resolved="false">ImageAnalysisInner</xref> object </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageWithServiceResponseAsync(String,List<VisualFeatureTypes>,List<Details>,Language1)
  id: analyzeImageWithServiceResponseAsync(String,List<VisualFeatureTypes>,List<Details>,Language1)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: analyzeImageWithServiceResponseAsync(String url, List<VisualFeatureTypes> visualFeatures, List<Details> details, Language1 language)
  nameWithType: ComputerVisionAPIImpl.analyzeImageWithServiceResponseAsync(String url, List<VisualFeatureTypes> visualFeatures, List<Details> details, Language1 language)
  fullName: Observable<ServiceResponse<ImageAnalysisInner>> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.analyzeImageWithServiceResponseAsync(String url, List<VisualFeatureTypes> visualFeatures, List<Details> details, Language1 language)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageWithServiceResponseAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 488
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>This operation extracts a rich set of visual features based on the image content. Two input methods are supported <ndash></ndash> (1) Uploading an image or (2) specifying an image URL. Within your request, there is an optional parameter to allow you to choose which features to return. By default, image categories are returned in the response.</p>

    <p></p>
  syntax:
    content: public Observable<ServiceResponse<ImageAnalysisInner>> analyzeImageWithServiceResponseAsync(String url, List<VisualFeatureTypes> visualFeatures, List<Details> details, Language1 language)
    parameters:
    - id: url
      type: "26831127"
      description: <p>the String value </p>
    - id: visualFeatures
      type: 5618da2dcom.microsoft.azure.cognitiveservices.computervision._visual_feature_typesa08ddfce
      description: <p>A string indicating what visual feature types to return. Multiple values should be comma-separated. Valid visual feature types include:Categories - categorizes image content according to a taxonomy defined in documentation. Tags - tags the image with a detailed list of words related to the image content. Description - describes the image content with a complete English sentence. Faces - detects if faces are present. If present, generate coordinates, gender and age. <xref uid="com.microsoft.azure.cognitiveservices.computervision._image_type" data-throw-if-not-resolved="false">ImageType</xref> - detects if image is clipart or a line drawing. Color - determines the accent color, dominant color, and whether an image is black&amp;white.Adult - detects if the image is pornographic in nature (depicts nudity or a sex act). Sexually suggestive content is also detected. </p>
    - id: details
      type: 5618da2dcom.microsoft.azure.cognitiveservices.computervision._detailsa08ddfce
      description: <p>A string indicating which domain-specific details to return. Multiple values should be comma-separated. Valid visual feature types include:Celebrities - identifies celebrities if detected in the image. </p>
    - id: language
      type: com.microsoft.azure.cognitiveservices.computervision._language1
      description: "<p>A string indicating which language to return. The service will return recognition results in specified language. If this parameter is not specified, the default value is &amp;quot;en&amp;quot;.Supported languages:en - English, Default.zh - Simplified Chinese. Possible values include: 'en', 'zh' </p>"
    return:
      type: fc480ba2com.microsoft.azure.cognitiveservices.computervision.implementation._image_analysis_innere7daa122
      description: <p>the observable to the <xref uid="com.microsoft.azure.cognitiveservices.computervision.implementation._image_analysis_inner" data-throw-if-not-resolved="false">ImageAnalysisInner</xref> object </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.azureRegion()
  id: azureRegion()
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: azureRegion()
  nameWithType: ComputerVisionAPIImpl.azureRegion()
  fullName: AzureRegions com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.azureRegion()
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.azureRegion*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 72
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>Gets Supported Azure regions for Cognitive Services endpoints. Possible values include: 'westus', 'westeurope', 'southeastasia', 'eastus2', 'westcentralus', 'westus2', 'eastus', 'southcentralus', 'northeurope', 'eastasia', 'australiaeast', 'brazilsouth'.</p>

    <p></p>
  syntax:
    content: public AzureRegions azureRegion()
    return:
      type: com.microsoft.azure.cognitiveservices.computervision._azure_regions
      description: <p>the azureRegion value. </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.ComputerVisionAPIImpl(RestClient)
  id: ComputerVisionAPIImpl(RestClient)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: ComputerVisionAPIImpl(RestClient restClient)
  nameWithType: ComputerVisionAPIImpl.ComputerVisionAPIImpl(RestClient restClient)
  fullName: com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.ComputerVisionAPIImpl(RestClient restClient)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.ComputerVisionAPIImpl*
  type: Constructor
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 181
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>Initializes an instance of ComputerVisionAPI client.</p>

    <p></p>
  syntax:
    content: public ComputerVisionAPIImpl(RestClient restClient)
    parameters:
    - id: restClient
      type: 9545a295
      description: <p>the REST client to connect to Azure. </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.ComputerVisionAPIImpl(ServiceClientCredentials)
  id: ComputerVisionAPIImpl(ServiceClientCredentials)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: ComputerVisionAPIImpl(ServiceClientCredentials credentials)
  nameWithType: ComputerVisionAPIImpl.ComputerVisionAPIImpl(ServiceClientCredentials credentials)
  fullName: com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.ComputerVisionAPIImpl(ServiceClientCredentials credentials)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.ComputerVisionAPIImpl*
  type: Constructor
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 161
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>Initializes an instance of ComputerVisionAPI client.</p>

    <p></p>
  syntax:
    content: public ComputerVisionAPIImpl(ServiceClientCredentials credentials)
    parameters:
    - id: credentials
      type: d7990412
      description: <p>the management credentials for Azure </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.ComputerVisionAPIImpl(String,ServiceClientCredentials)
  id: ComputerVisionAPIImpl(String,ServiceClientCredentials)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: ComputerVisionAPIImpl(String baseUrl, ServiceClientCredentials credentials)
  nameWithType: ComputerVisionAPIImpl.ComputerVisionAPIImpl(String baseUrl, ServiceClientCredentials credentials)
  fullName: com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.ComputerVisionAPIImpl(String baseUrl, ServiceClientCredentials credentials)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.ComputerVisionAPIImpl*
  type: Constructor
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 171
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>Initializes an instance of ComputerVisionAPI client.</p>

    <p></p>
  syntax:
    content: public ComputerVisionAPIImpl(String baseUrl, ServiceClientCredentials credentials)
    parameters:
    - id: baseUrl
      type: "26831127"
      description: <p>the base URL of the host </p>
    - id: credentials
      type: d7990412
      description: <p>the management credentials for Azure </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.describeImage(String)
  id: describeImage(String)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: describeImage(String url)
  nameWithType: ComputerVisionAPIImpl.describeImage(String url)
  fullName: ImageDescriptionInner com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.describeImage(String url)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.describeImage*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 868
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>This operation generates a description of an image in human readable language with complete sentences. The description is based on a collection of content tags, which are also returned by the operation. More than one description can be generated for each image. Descriptions are ordered by their confidence score. All descriptions are in English. Two input methods are supported <ndash></ndash> (1) Uploading an image or (2) specifying an image URL.A successful response will be returned in JSON. If the request failed, the response will contain an error code and a message to help understand what went wrong.</p>

    <p></p>
  syntax:
    content: public ImageDescriptionInner describeImage(String url)
    parameters:
    - id: url
      type: "26831127"
      description: <p>the String value </p>
    return:
      type: com.microsoft.azure.cognitiveservices.computervision.implementation._image_description_inner
      description: <p>the <xref uid="com.microsoft.azure.cognitiveservices.computervision.implementation._image_description_inner" data-throw-if-not-resolved="false">ImageDescriptionInner</xref> object if successful. </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
  - type: com.microsoft.azure.cognitiveservices.computervision._computer_vision_error_exception
    description: <p>thrown if the request is rejected by server </p>
  - type: 9b2a4515
    description: <p>all other wrapped checked exceptions if the request fails to be sent </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.describeImage(String,String)
  id: describeImage(String,String)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: describeImage(String url, String maxCandidates)
  nameWithType: ComputerVisionAPIImpl.describeImage(String url, String maxCandidates)
  fullName: ImageDescriptionInner com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.describeImage(String url, String maxCandidates)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.describeImage*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 942
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>This operation generates a description of an image in human readable language with complete sentences. The description is based on a collection of content tags, which are also returned by the operation. More than one description can be generated for each image. Descriptions are ordered by their confidence score. All descriptions are in English. Two input methods are supported <ndash></ndash> (1) Uploading an image or (2) specifying an image URL.A successful response will be returned in JSON. If the request failed, the response will contain an error code and a message to help understand what went wrong.</p>

    <p></p>
  syntax:
    content: public ImageDescriptionInner describeImage(String url, String maxCandidates)
    parameters:
    - id: url
      type: "26831127"
      description: <p>the String value </p>
    - id: maxCandidates
      type: "26831127"
      description: <p>Maximum number of candidate descriptions to be returned. The default is 1. </p>
    return:
      type: com.microsoft.azure.cognitiveservices.computervision.implementation._image_description_inner
      description: <p>the <xref uid="com.microsoft.azure.cognitiveservices.computervision.implementation._image_description_inner" data-throw-if-not-resolved="false">ImageDescriptionInner</xref> object if successful. </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
  - type: com.microsoft.azure.cognitiveservices.computervision._computer_vision_error_exception
    description: <p>thrown if the request is rejected by server </p>
  - type: 9b2a4515
    description: <p>all other wrapped checked exceptions if the request fails to be sent </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.describeImageAsync(String)
  id: describeImageAsync(String)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: describeImageAsync(String url)
  nameWithType: ComputerVisionAPIImpl.describeImageAsync(String url)
  fullName: Observable<ImageDescriptionInner> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.describeImageAsync(String url)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.describeImageAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 891
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>This operation generates a description of an image in human readable language with complete sentences. The description is based on a collection of content tags, which are also returned by the operation. More than one description can be generated for each image. Descriptions are ordered by their confidence score. All descriptions are in English. Two input methods are supported <ndash></ndash> (1) Uploading an image or (2) specifying an image URL.A successful response will be returned in JSON. If the request failed, the response will contain an error code and a message to help understand what went wrong.</p>

    <p></p>
  syntax:
    content: public Observable<ImageDescriptionInner> describeImageAsync(String url)
    parameters:
    - id: url
      type: "26831127"
      description: <p>the String value </p>
    return:
      type: c2d0e8c6com.microsoft.azure.cognitiveservices.computervision.implementation._image_description_innera08ddfce
      description: <p>the observable to the <xref uid="com.microsoft.azure.cognitiveservices.computervision.implementation._image_description_inner" data-throw-if-not-resolved="false">ImageDescriptionInner</xref> object </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.describeImageAsync(String,final ServiceCallback<ImageDescriptionInner>)
  id: describeImageAsync(String,final ServiceCallback<ImageDescriptionInner>)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: describeImageAsync(String url, final ServiceCallback<ImageDescriptionInner> serviceCallback)
  nameWithType: ComputerVisionAPIImpl.describeImageAsync(String url, final ServiceCallback<ImageDescriptionInner> serviceCallback)
  fullName: ServiceFuture<ImageDescriptionInner> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.describeImageAsync(String url, final ServiceCallback<ImageDescriptionInner> serviceCallback)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.describeImageAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 880
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>This operation generates a description of an image in human readable language with complete sentences. The description is based on a collection of content tags, which are also returned by the operation. More than one description can be generated for each image. Descriptions are ordered by their confidence score. All descriptions are in English. Two input methods are supported <ndash></ndash> (1) Uploading an image or (2) specifying an image URL.A successful response will be returned in JSON. If the request failed, the response will contain an error code and a message to help understand what went wrong.</p>

    <p></p>
  syntax:
    content: public ServiceFuture<ImageDescriptionInner> describeImageAsync(String url, final ServiceCallback<ImageDescriptionInner> serviceCallback)
    parameters:
    - id: url
      type: "26831127"
      description: <p>the String value </p>
    - id: serviceCallback
      type: 897eb10acom.microsoft.azure.cognitiveservices.computervision.implementation._image_description_innera08ddfce
      description: <p>the async ServiceCallback to handle successful and failed responses. </p>
    return:
      type: c522ce07com.microsoft.azure.cognitiveservices.computervision.implementation._image_description_innera08ddfce
      description: <p>the <xref uid="" data-throw-if-not-resolved="false">ServiceFuture</xref> object </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.describeImageAsync(String,String)
  id: describeImageAsync(String,String)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: describeImageAsync(String url, String maxCandidates)
  nameWithType: ComputerVisionAPIImpl.describeImageAsync(String url, String maxCandidates)
  fullName: Observable<ImageDescriptionInner> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.describeImageAsync(String url, String maxCandidates)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.describeImageAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 967
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>This operation generates a description of an image in human readable language with complete sentences. The description is based on a collection of content tags, which are also returned by the operation. More than one description can be generated for each image. Descriptions are ordered by their confidence score. All descriptions are in English. Two input methods are supported <ndash></ndash> (1) Uploading an image or (2) specifying an image URL.A successful response will be returned in JSON. If the request failed, the response will contain an error code and a message to help understand what went wrong.</p>

    <p></p>
  syntax:
    content: public Observable<ImageDescriptionInner> describeImageAsync(String url, String maxCandidates)
    parameters:
    - id: url
      type: "26831127"
      description: <p>the String value </p>
    - id: maxCandidates
      type: "26831127"
      description: <p>Maximum number of candidate descriptions to be returned. The default is 1. </p>
    return:
      type: c2d0e8c6com.microsoft.azure.cognitiveservices.computervision.implementation._image_description_innera08ddfce
      description: <p>the observable to the <xref uid="com.microsoft.azure.cognitiveservices.computervision.implementation._image_description_inner" data-throw-if-not-resolved="false">ImageDescriptionInner</xref> object </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.describeImageAsync(String,String,final ServiceCallback<ImageDescriptionInner>)
  id: describeImageAsync(String,String,final ServiceCallback<ImageDescriptionInner>)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: describeImageAsync(String url, String maxCandidates, final ServiceCallback<ImageDescriptionInner> serviceCallback)
  nameWithType: ComputerVisionAPIImpl.describeImageAsync(String url, String maxCandidates, final ServiceCallback<ImageDescriptionInner> serviceCallback)
  fullName: ServiceFuture<ImageDescriptionInner> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.describeImageAsync(String url, String maxCandidates, final ServiceCallback<ImageDescriptionInner> serviceCallback)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.describeImageAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 955
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>This operation generates a description of an image in human readable language with complete sentences. The description is based on a collection of content tags, which are also returned by the operation. More than one description can be generated for each image. Descriptions are ordered by their confidence score. All descriptions are in English. Two input methods are supported <ndash></ndash> (1) Uploading an image or (2) specifying an image URL.A successful response will be returned in JSON. If the request failed, the response will contain an error code and a message to help understand what went wrong.</p>

    <p></p>
  syntax:
    content: public ServiceFuture<ImageDescriptionInner> describeImageAsync(String url, String maxCandidates, final ServiceCallback<ImageDescriptionInner> serviceCallback)
    parameters:
    - id: url
      type: "26831127"
      description: <p>the String value </p>
    - id: maxCandidates
      type: "26831127"
      description: <p>Maximum number of candidate descriptions to be returned. The default is 1. </p>
    - id: serviceCallback
      type: 897eb10acom.microsoft.azure.cognitiveservices.computervision.implementation._image_description_innera08ddfce
      description: <p>the async ServiceCallback to handle successful and failed responses. </p>
    return:
      type: c522ce07com.microsoft.azure.cognitiveservices.computervision.implementation._image_description_innera08ddfce
      description: <p>the <xref uid="" data-throw-if-not-resolved="false">ServiceFuture</xref> object </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.describeImageInStream(byte [])
  id: describeImageInStream(byte [])
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: describeImageInStream(byte[] image)
  nameWithType: ComputerVisionAPIImpl.describeImageInStream(byte[] image)
  fullName: ImageDescriptionInner com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.describeImageInStream(byte[] image)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.describeImageInStream*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 1919
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>This operation generates a description of an image in human readable language with complete sentences. The description is based on a collection of content tags, which are also returned by the operation. More than one description can be generated for each image. Descriptions are ordered by their confidence score. All descriptions are in English. Two input methods are supported <ndash></ndash> (1) Uploading an image or (2) specifying an image URL.A successful response will be returned in JSON. If the request failed, the response will contain an error code and a message to help understand what went wrong.</p>

    <p></p>
  syntax:
    content: public ImageDescriptionInner describeImageInStream(byte[] image)
    parameters:
    - id: image
      type: ccd9418d
      description: <p>An image stream. </p>
    return:
      type: com.microsoft.azure.cognitiveservices.computervision.implementation._image_description_inner
      description: <p>the <xref uid="com.microsoft.azure.cognitiveservices.computervision.implementation._image_description_inner" data-throw-if-not-resolved="false">ImageDescriptionInner</xref> object if successful. </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
  - type: com.microsoft.azure.cognitiveservices.computervision._computer_vision_error_exception
    description: <p>thrown if the request is rejected by server </p>
  - type: 9b2a4515
    description: <p>all other wrapped checked exceptions if the request fails to be sent </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.describeImageInStream(byte [],String)
  id: describeImageInStream(byte [],String)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: describeImageInStream(byte[] image, String maxCandidates)
  nameWithType: ComputerVisionAPIImpl.describeImageInStream(byte[] image, String maxCandidates)
  fullName: ImageDescriptionInner com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.describeImageInStream(byte[] image, String maxCandidates)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.describeImageInStream*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 1992
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>This operation generates a description of an image in human readable language with complete sentences. The description is based on a collection of content tags, which are also returned by the operation. More than one description can be generated for each image. Descriptions are ordered by their confidence score. All descriptions are in English. Two input methods are supported <ndash></ndash> (1) Uploading an image or (2) specifying an image URL.A successful response will be returned in JSON. If the request failed, the response will contain an error code and a message to help understand what went wrong.</p>

    <p></p>
  syntax:
    content: public ImageDescriptionInner describeImageInStream(byte[] image, String maxCandidates)
    parameters:
    - id: image
      type: ccd9418d
      description: <p>An image stream. </p>
    - id: maxCandidates
      type: "26831127"
      description: <p>Maximum number of candidate descriptions to be returned. The default is 1. </p>
    return:
      type: com.microsoft.azure.cognitiveservices.computervision.implementation._image_description_inner
      description: <p>the <xref uid="com.microsoft.azure.cognitiveservices.computervision.implementation._image_description_inner" data-throw-if-not-resolved="false">ImageDescriptionInner</xref> object if successful. </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
  - type: com.microsoft.azure.cognitiveservices.computervision._computer_vision_error_exception
    description: <p>thrown if the request is rejected by server </p>
  - type: 9b2a4515
    description: <p>all other wrapped checked exceptions if the request fails to be sent </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.describeImageInStreamAsync(byte [])
  id: describeImageInStreamAsync(byte [])
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: describeImageInStreamAsync(byte[] image)
  nameWithType: ComputerVisionAPIImpl.describeImageInStreamAsync(byte[] image)
  fullName: Observable<ImageDescriptionInner> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.describeImageInStreamAsync(byte[] image)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.describeImageInStreamAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 1942
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>This operation generates a description of an image in human readable language with complete sentences. The description is based on a collection of content tags, which are also returned by the operation. More than one description can be generated for each image. Descriptions are ordered by their confidence score. All descriptions are in English. Two input methods are supported <ndash></ndash> (1) Uploading an image or (2) specifying an image URL.A successful response will be returned in JSON. If the request failed, the response will contain an error code and a message to help understand what went wrong.</p>

    <p></p>
  syntax:
    content: public Observable<ImageDescriptionInner> describeImageInStreamAsync(byte[] image)
    parameters:
    - id: image
      type: ccd9418d
      description: <p>An image stream. </p>
    return:
      type: c2d0e8c6com.microsoft.azure.cognitiveservices.computervision.implementation._image_description_innera08ddfce
      description: <p>the observable to the <xref uid="com.microsoft.azure.cognitiveservices.computervision.implementation._image_description_inner" data-throw-if-not-resolved="false">ImageDescriptionInner</xref> object </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.describeImageInStreamAsync(byte [],final ServiceCallback<ImageDescriptionInner>)
  id: describeImageInStreamAsync(byte [],final ServiceCallback<ImageDescriptionInner>)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: describeImageInStreamAsync(byte[] image, final ServiceCallback<ImageDescriptionInner> serviceCallback)
  nameWithType: ComputerVisionAPIImpl.describeImageInStreamAsync(byte[] image, final ServiceCallback<ImageDescriptionInner> serviceCallback)
  fullName: ServiceFuture<ImageDescriptionInner> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.describeImageInStreamAsync(byte[] image, final ServiceCallback<ImageDescriptionInner> serviceCallback)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.describeImageInStreamAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 1931
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>This operation generates a description of an image in human readable language with complete sentences. The description is based on a collection of content tags, which are also returned by the operation. More than one description can be generated for each image. Descriptions are ordered by their confidence score. All descriptions are in English. Two input methods are supported <ndash></ndash> (1) Uploading an image or (2) specifying an image URL.A successful response will be returned in JSON. If the request failed, the response will contain an error code and a message to help understand what went wrong.</p>

    <p></p>
  syntax:
    content: public ServiceFuture<ImageDescriptionInner> describeImageInStreamAsync(byte[] image, final ServiceCallback<ImageDescriptionInner> serviceCallback)
    parameters:
    - id: image
      type: ccd9418d
      description: <p>An image stream. </p>
    - id: serviceCallback
      type: 897eb10acom.microsoft.azure.cognitiveservices.computervision.implementation._image_description_innera08ddfce
      description: <p>the async ServiceCallback to handle successful and failed responses. </p>
    return:
      type: c522ce07com.microsoft.azure.cognitiveservices.computervision.implementation._image_description_innera08ddfce
      description: <p>the <xref uid="" data-throw-if-not-resolved="false">ServiceFuture</xref> object </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.describeImageInStreamAsync(byte [],String)
  id: describeImageInStreamAsync(byte [],String)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: describeImageInStreamAsync(byte[] image, String maxCandidates)
  nameWithType: ComputerVisionAPIImpl.describeImageInStreamAsync(byte[] image, String maxCandidates)
  fullName: Observable<ImageDescriptionInner> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.describeImageInStreamAsync(byte[] image, String maxCandidates)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.describeImageInStreamAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 2017
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>This operation generates a description of an image in human readable language with complete sentences. The description is based on a collection of content tags, which are also returned by the operation. More than one description can be generated for each image. Descriptions are ordered by their confidence score. All descriptions are in English. Two input methods are supported <ndash></ndash> (1) Uploading an image or (2) specifying an image URL.A successful response will be returned in JSON. If the request failed, the response will contain an error code and a message to help understand what went wrong.</p>

    <p></p>
  syntax:
    content: public Observable<ImageDescriptionInner> describeImageInStreamAsync(byte[] image, String maxCandidates)
    parameters:
    - id: image
      type: ccd9418d
      description: <p>An image stream. </p>
    - id: maxCandidates
      type: "26831127"
      description: <p>Maximum number of candidate descriptions to be returned. The default is 1. </p>
    return:
      type: c2d0e8c6com.microsoft.azure.cognitiveservices.computervision.implementation._image_description_innera08ddfce
      description: <p>the observable to the <xref uid="com.microsoft.azure.cognitiveservices.computervision.implementation._image_description_inner" data-throw-if-not-resolved="false">ImageDescriptionInner</xref> object </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.describeImageInStreamAsync(byte [],String,final ServiceCallback<ImageDescriptionInner>)
  id: describeImageInStreamAsync(byte [],String,final ServiceCallback<ImageDescriptionInner>)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: describeImageInStreamAsync(byte[] image, String maxCandidates, final ServiceCallback<ImageDescriptionInner> serviceCallback)
  nameWithType: ComputerVisionAPIImpl.describeImageInStreamAsync(byte[] image, String maxCandidates, final ServiceCallback<ImageDescriptionInner> serviceCallback)
  fullName: ServiceFuture<ImageDescriptionInner> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.describeImageInStreamAsync(byte[] image, String maxCandidates, final ServiceCallback<ImageDescriptionInner> serviceCallback)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.describeImageInStreamAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 2005
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>This operation generates a description of an image in human readable language with complete sentences. The description is based on a collection of content tags, which are also returned by the operation. More than one description can be generated for each image. Descriptions are ordered by their confidence score. All descriptions are in English. Two input methods are supported <ndash></ndash> (1) Uploading an image or (2) specifying an image URL.A successful response will be returned in JSON. If the request failed, the response will contain an error code and a message to help understand what went wrong.</p>

    <p></p>
  syntax:
    content: public ServiceFuture<ImageDescriptionInner> describeImageInStreamAsync(byte[] image, String maxCandidates, final ServiceCallback<ImageDescriptionInner> serviceCallback)
    parameters:
    - id: image
      type: ccd9418d
      description: <p>An image stream. </p>
    - id: maxCandidates
      type: "26831127"
      description: <p>Maximum number of candidate descriptions to be returned. The default is 1. </p>
    - id: serviceCallback
      type: 897eb10acom.microsoft.azure.cognitiveservices.computervision.implementation._image_description_innera08ddfce
      description: <p>the async ServiceCallback to handle successful and failed responses. </p>
    return:
      type: c522ce07com.microsoft.azure.cognitiveservices.computervision.implementation._image_description_innera08ddfce
      description: <p>the <xref uid="" data-throw-if-not-resolved="false">ServiceFuture</xref> object </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.describeImageInStreamWithServiceResponseAsync(byte [])
  id: describeImageInStreamWithServiceResponseAsync(byte [])
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: describeImageInStreamWithServiceResponseAsync(byte[] image)
  nameWithType: ComputerVisionAPIImpl.describeImageInStreamWithServiceResponseAsync(byte[] image)
  fullName: Observable<ServiceResponse<ImageDescriptionInner>> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.describeImageInStreamWithServiceResponseAsync(byte[] image)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.describeImageInStreamWithServiceResponseAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 1958
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>This operation generates a description of an image in human readable language with complete sentences. The description is based on a collection of content tags, which are also returned by the operation. More than one description can be generated for each image. Descriptions are ordered by their confidence score. All descriptions are in English. Two input methods are supported <ndash></ndash> (1) Uploading an image or (2) specifying an image URL.A successful response will be returned in JSON. If the request failed, the response will contain an error code and a message to help understand what went wrong.</p>

    <p></p>
  syntax:
    content: public Observable<ServiceResponse<ImageDescriptionInner>> describeImageInStreamWithServiceResponseAsync(byte[] image)
    parameters:
    - id: image
      type: ccd9418d
      description: <p>An image stream. </p>
    return:
      type: fc480ba2com.microsoft.azure.cognitiveservices.computervision.implementation._image_description_innere7daa122
      description: <p>the observable to the <xref uid="com.microsoft.azure.cognitiveservices.computervision.implementation._image_description_inner" data-throw-if-not-resolved="false">ImageDescriptionInner</xref> object </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.describeImageInStreamWithServiceResponseAsync(byte [],String)
  id: describeImageInStreamWithServiceResponseAsync(byte [],String)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: describeImageInStreamWithServiceResponseAsync(byte[] image, String maxCandidates)
  nameWithType: ComputerVisionAPIImpl.describeImageInStreamWithServiceResponseAsync(byte[] image, String maxCandidates)
  fullName: Observable<ServiceResponse<ImageDescriptionInner>> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.describeImageInStreamWithServiceResponseAsync(byte[] image, String maxCandidates)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.describeImageInStreamWithServiceResponseAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 2034
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>This operation generates a description of an image in human readable language with complete sentences. The description is based on a collection of content tags, which are also returned by the operation. More than one description can be generated for each image. Descriptions are ordered by their confidence score. All descriptions are in English. Two input methods are supported <ndash></ndash> (1) Uploading an image or (2) specifying an image URL.A successful response will be returned in JSON. If the request failed, the response will contain an error code and a message to help understand what went wrong.</p>

    <p></p>
  syntax:
    content: public Observable<ServiceResponse<ImageDescriptionInner>> describeImageInStreamWithServiceResponseAsync(byte[] image, String maxCandidates)
    parameters:
    - id: image
      type: ccd9418d
      description: <p>An image stream. </p>
    - id: maxCandidates
      type: "26831127"
      description: <p>Maximum number of candidate descriptions to be returned. The default is 1. </p>
    return:
      type: fc480ba2com.microsoft.azure.cognitiveservices.computervision.implementation._image_description_innere7daa122
      description: <p>the observable to the <xref uid="com.microsoft.azure.cognitiveservices.computervision.implementation._image_description_inner" data-throw-if-not-resolved="false">ImageDescriptionInner</xref> object </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.describeImageWithServiceResponseAsync(String)
  id: describeImageWithServiceResponseAsync(String)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: describeImageWithServiceResponseAsync(String url)
  nameWithType: ComputerVisionAPIImpl.describeImageWithServiceResponseAsync(String url)
  fullName: Observable<ServiceResponse<ImageDescriptionInner>> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.describeImageWithServiceResponseAsync(String url)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.describeImageWithServiceResponseAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 907
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>This operation generates a description of an image in human readable language with complete sentences. The description is based on a collection of content tags, which are also returned by the operation. More than one description can be generated for each image. Descriptions are ordered by their confidence score. All descriptions are in English. Two input methods are supported <ndash></ndash> (1) Uploading an image or (2) specifying an image URL.A successful response will be returned in JSON. If the request failed, the response will contain an error code and a message to help understand what went wrong.</p>

    <p></p>
  syntax:
    content: public Observable<ServiceResponse<ImageDescriptionInner>> describeImageWithServiceResponseAsync(String url)
    parameters:
    - id: url
      type: "26831127"
      description: <p>the String value </p>
    return:
      type: fc480ba2com.microsoft.azure.cognitiveservices.computervision.implementation._image_description_innere7daa122
      description: <p>the observable to the <xref uid="com.microsoft.azure.cognitiveservices.computervision.implementation._image_description_inner" data-throw-if-not-resolved="false">ImageDescriptionInner</xref> object </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.describeImageWithServiceResponseAsync(String,String)
  id: describeImageWithServiceResponseAsync(String,String)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: describeImageWithServiceResponseAsync(String url, String maxCandidates)
  nameWithType: ComputerVisionAPIImpl.describeImageWithServiceResponseAsync(String url, String maxCandidates)
  fullName: Observable<ServiceResponse<ImageDescriptionInner>> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.describeImageWithServiceResponseAsync(String url, String maxCandidates)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.describeImageWithServiceResponseAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 984
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>This operation generates a description of an image in human readable language with complete sentences. The description is based on a collection of content tags, which are also returned by the operation. More than one description can be generated for each image. Descriptions are ordered by their confidence score. All descriptions are in English. Two input methods are supported <ndash></ndash> (1) Uploading an image or (2) specifying an image URL.A successful response will be returned in JSON. If the request failed, the response will contain an error code and a message to help understand what went wrong.</p>

    <p></p>
  syntax:
    content: public Observable<ServiceResponse<ImageDescriptionInner>> describeImageWithServiceResponseAsync(String url, String maxCandidates)
    parameters:
    - id: url
      type: "26831127"
      description: <p>the String value </p>
    - id: maxCandidates
      type: "26831127"
      description: <p>Maximum number of candidate descriptions to be returned. The default is 1. </p>
    return:
      type: fc480ba2com.microsoft.azure.cognitiveservices.computervision.implementation._image_description_innere7daa122
      description: <p>the observable to the <xref uid="com.microsoft.azure.cognitiveservices.computervision.implementation._image_description_inner" data-throw-if-not-resolved="false">ImageDescriptionInner</xref> object </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.generateClientRequestId()
  id: generateClientRequestId()
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: generateClientRequestId()
  nameWithType: ComputerVisionAPIImpl.generateClientRequestId()
  fullName: boolean com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.generateClientRequestId()
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.generateClientRequestId*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 141
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>Gets When set to true a unique x-ms-client-request-id value is generated and included in each request. Default is true.</p>

    <p></p>
  syntax:
    content: public boolean generateClientRequestId()
    return:
      type: 4fc6e284
      description: <p>the generateClientRequestId value. </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.generateThumbnail(int,int,String)
  id: generateThumbnail(int,int,String)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: generateThumbnail(int width, int height, String url)
  nameWithType: ComputerVisionAPIImpl.generateThumbnail(int width, int height, String url)
  fullName: InputStream com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.generateThumbnail(int width, int height, String url)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.generateThumbnail*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 534
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>This operation generates a thumbnail image with the user-specified width and height. By default, the service analyzes the image, identifies the region of interest (ROI), and generates smart cropping coordinates based on the ROI. Smart cropping helps when you specify an aspect ratio that differs from that of the input image. A successful response contains the thumbnail image binary. If the request failed, the response contains an error code and a message to help determine what went wrong.</p>

    <p></p>
  syntax:
    content: public InputStream generateThumbnail(int width, int height, String url)
    parameters:
    - id: width
      type: f75371fa
      description: <p>Width of the thumbnail. It must be between 1 and 1024. Recommended minimum of 50. </p>
    - id: height
      type: f75371fa
      description: <p>Height of the thumbnail. It must be between 1 and 1024. Recommended minimum of 50. </p>
    - id: url
      type: "26831127"
      description: <p>the String value </p>
    return:
      type: 76fcb9b7
      description: <p>the InputStream object if successful. </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
  - type: dc385fd4
    description: <p>thrown if the request is rejected by server </p>
  - type: 9b2a4515
    description: <p>all other wrapped checked exceptions if the request fails to be sent </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.generateThumbnail(int,int,String,Boolean)
  id: generateThumbnail(int,int,String,Boolean)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: generateThumbnail(int width, int height, String url, Boolean smartCropping)
  nameWithType: ComputerVisionAPIImpl.generateThumbnail(int width, int height, String url, Boolean smartCropping)
  fullName: InputStream com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.generateThumbnail(int width, int height, String url, Boolean smartCropping)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.generateThumbnail*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 616
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>This operation generates a thumbnail image with the user-specified width and height. By default, the service analyzes the image, identifies the region of interest (ROI), and generates smart cropping coordinates based on the ROI. Smart cropping helps when you specify an aspect ratio that differs from that of the input image. A successful response contains the thumbnail image binary. If the request failed, the response contains an error code and a message to help determine what went wrong.</p>

    <p></p>
  syntax:
    content: public InputStream generateThumbnail(int width, int height, String url, Boolean smartCropping)
    parameters:
    - id: width
      type: f75371fa
      description: <p>Width of the thumbnail. It must be between 1 and 1024. Recommended minimum of 50. </p>
    - id: height
      type: f75371fa
      description: <p>Height of the thumbnail. It must be between 1 and 1024. Recommended minimum of 50. </p>
    - id: url
      type: "26831127"
      description: <p>the String value </p>
    - id: smartCropping
      type: 866c2227
      description: <p>Boolean flag for enabling smart cropping. </p>
    return:
      type: 76fcb9b7
      description: <p>the InputStream object if successful. </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
  - type: dc385fd4
    description: <p>thrown if the request is rejected by server </p>
  - type: 9b2a4515
    description: <p>all other wrapped checked exceptions if the request fails to be sent </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.generateThumbnailAsync(int,int,String)
  id: generateThumbnailAsync(int,int,String)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: generateThumbnailAsync(int width, int height, String url)
  nameWithType: ComputerVisionAPIImpl.generateThumbnailAsync(int width, int height, String url)
  fullName: Observable<InputStream> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.generateThumbnailAsync(int width, int height, String url)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.generateThumbnailAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 561
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>This operation generates a thumbnail image with the user-specified width and height. By default, the service analyzes the image, identifies the region of interest (ROI), and generates smart cropping coordinates based on the ROI. Smart cropping helps when you specify an aspect ratio that differs from that of the input image. A successful response contains the thumbnail image binary. If the request failed, the response contains an error code and a message to help determine what went wrong.</p>

    <p></p>
  syntax:
    content: public Observable<InputStream> generateThumbnailAsync(int width, int height, String url)
    parameters:
    - id: width
      type: f75371fa
      description: <p>Width of the thumbnail. It must be between 1 and 1024. Recommended minimum of 50. </p>
    - id: height
      type: f75371fa
      description: <p>Height of the thumbnail. It must be between 1 and 1024. Recommended minimum of 50. </p>
    - id: url
      type: "26831127"
      description: <p>the String value </p>
    return:
      type: 3ab19265
      description: <p>the observable to the InputStream object </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.generateThumbnailAsync(int,int,String,Boolean)
  id: generateThumbnailAsync(int,int,String,Boolean)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: generateThumbnailAsync(int width, int height, String url, Boolean smartCropping)
  nameWithType: ComputerVisionAPIImpl.generateThumbnailAsync(int width, int height, String url, Boolean smartCropping)
  fullName: Observable<InputStream> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.generateThumbnailAsync(int width, int height, String url, Boolean smartCropping)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.generateThumbnailAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 645
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>This operation generates a thumbnail image with the user-specified width and height. By default, the service analyzes the image, identifies the region of interest (ROI), and generates smart cropping coordinates based on the ROI. Smart cropping helps when you specify an aspect ratio that differs from that of the input image. A successful response contains the thumbnail image binary. If the request failed, the response contains an error code and a message to help determine what went wrong.</p>

    <p></p>
  syntax:
    content: public Observable<InputStream> generateThumbnailAsync(int width, int height, String url, Boolean smartCropping)
    parameters:
    - id: width
      type: f75371fa
      description: <p>Width of the thumbnail. It must be between 1 and 1024. Recommended minimum of 50. </p>
    - id: height
      type: f75371fa
      description: <p>Height of the thumbnail. It must be between 1 and 1024. Recommended minimum of 50. </p>
    - id: url
      type: "26831127"
      description: <p>the String value </p>
    - id: smartCropping
      type: 866c2227
      description: <p>Boolean flag for enabling smart cropping. </p>
    return:
      type: 3ab19265
      description: <p>the observable to the InputStream object </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.generateThumbnailAsync(int,int,String,Boolean,final ServiceCallback<InputStream>)
  id: generateThumbnailAsync(int,int,String,Boolean,final ServiceCallback<InputStream>)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: generateThumbnailAsync(int width, int height, String url, Boolean smartCropping, final ServiceCallback<InputStream> serviceCallback)
  nameWithType: ComputerVisionAPIImpl.generateThumbnailAsync(int width, int height, String url, Boolean smartCropping, final ServiceCallback<InputStream> serviceCallback)
  fullName: ServiceFuture<InputStream> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.generateThumbnailAsync(int width, int height, String url, Boolean smartCropping, final ServiceCallback<InputStream> serviceCallback)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.generateThumbnailAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 631
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>This operation generates a thumbnail image with the user-specified width and height. By default, the service analyzes the image, identifies the region of interest (ROI), and generates smart cropping coordinates based on the ROI. Smart cropping helps when you specify an aspect ratio that differs from that of the input image. A successful response contains the thumbnail image binary. If the request failed, the response contains an error code and a message to help determine what went wrong.</p>

    <p></p>
  syntax:
    content: public ServiceFuture<InputStream> generateThumbnailAsync(int width, int height, String url, Boolean smartCropping, final ServiceCallback<InputStream> serviceCallback)
    parameters:
    - id: width
      type: f75371fa
      description: <p>Width of the thumbnail. It must be between 1 and 1024. Recommended minimum of 50. </p>
    - id: height
      type: f75371fa
      description: <p>Height of the thumbnail. It must be between 1 and 1024. Recommended minimum of 50. </p>
    - id: url
      type: "26831127"
      description: <p>the String value </p>
    - id: smartCropping
      type: 866c2227
      description: <p>Boolean flag for enabling smart cropping. </p>
    - id: serviceCallback
      type: 0377aee2
      description: <p>the async ServiceCallback to handle successful and failed responses. </p>
    return:
      type: 8601070c
      description: <p>the <xref uid="" data-throw-if-not-resolved="false">ServiceFuture</xref> object </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.generateThumbnailAsync(int,int,String,final ServiceCallback<InputStream>)
  id: generateThumbnailAsync(int,int,String,final ServiceCallback<InputStream>)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: generateThumbnailAsync(int width, int height, String url, final ServiceCallback<InputStream> serviceCallback)
  nameWithType: ComputerVisionAPIImpl.generateThumbnailAsync(int width, int height, String url, final ServiceCallback<InputStream> serviceCallback)
  fullName: ServiceFuture<InputStream> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.generateThumbnailAsync(int width, int height, String url, final ServiceCallback<InputStream> serviceCallback)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.generateThumbnailAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 548
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>This operation generates a thumbnail image with the user-specified width and height. By default, the service analyzes the image, identifies the region of interest (ROI), and generates smart cropping coordinates based on the ROI. Smart cropping helps when you specify an aspect ratio that differs from that of the input image. A successful response contains the thumbnail image binary. If the request failed, the response contains an error code and a message to help determine what went wrong.</p>

    <p></p>
  syntax:
    content: public ServiceFuture<InputStream> generateThumbnailAsync(int width, int height, String url, final ServiceCallback<InputStream> serviceCallback)
    parameters:
    - id: width
      type: f75371fa
      description: <p>Width of the thumbnail. It must be between 1 and 1024. Recommended minimum of 50. </p>
    - id: height
      type: f75371fa
      description: <p>Height of the thumbnail. It must be between 1 and 1024. Recommended minimum of 50. </p>
    - id: url
      type: "26831127"
      description: <p>the String value </p>
    - id: serviceCallback
      type: 0377aee2
      description: <p>the async ServiceCallback to handle successful and failed responses. </p>
    return:
      type: 8601070c
      description: <p>the <xref uid="" data-throw-if-not-resolved="false">ServiceFuture</xref> object </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.generateThumbnailInStream(int,int,byte [])
  id: generateThumbnailInStream(int,int,byte [])
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: generateThumbnailInStream(int width, int height, byte[] image)
  nameWithType: ComputerVisionAPIImpl.generateThumbnailInStream(int width, int height, byte[] image)
  fullName: InputStream com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.generateThumbnailInStream(int width, int height, byte[] image)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.generateThumbnailInStream*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 1589
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>This operation generates a thumbnail image with the user-specified width and height. By default, the service analyzes the image, identifies the region of interest (ROI), and generates smart cropping coordinates based on the ROI. Smart cropping helps when you specify an aspect ratio that differs from that of the input image. A successful response contains the thumbnail image binary. If the request failed, the response contains an error code and a message to help determine what went wrong.</p>

    <p></p>
  syntax:
    content: public InputStream generateThumbnailInStream(int width, int height, byte[] image)
    parameters:
    - id: width
      type: f75371fa
      description: <p>Width of the thumbnail. It must be between 1 and 1024. Recommended minimum of 50. </p>
    - id: height
      type: f75371fa
      description: <p>Height of the thumbnail. It must be between 1 and 1024. Recommended minimum of 50. </p>
    - id: image
      type: ccd9418d
      description: <p>An image stream. </p>
    return:
      type: 76fcb9b7
      description: <p>the InputStream object if successful. </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
  - type: com.microsoft.azure.cognitiveservices.computervision._computer_vision_error_exception
    description: <p>thrown if the request is rejected by server </p>
  - type: 9b2a4515
    description: <p>all other wrapped checked exceptions if the request fails to be sent </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.generateThumbnailInStream(int,int,byte [],Boolean)
  id: generateThumbnailInStream(int,int,byte [],Boolean)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: generateThumbnailInStream(int width, int height, byte[] image, Boolean smartCropping)
  nameWithType: ComputerVisionAPIImpl.generateThumbnailInStream(int width, int height, byte[] image, Boolean smartCropping)
  fullName: InputStream com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.generateThumbnailInStream(int width, int height, byte[] image, Boolean smartCropping)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.generateThumbnailInStream*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 1670
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>This operation generates a thumbnail image with the user-specified width and height. By default, the service analyzes the image, identifies the region of interest (ROI), and generates smart cropping coordinates based on the ROI. Smart cropping helps when you specify an aspect ratio that differs from that of the input image. A successful response contains the thumbnail image binary. If the request failed, the response contains an error code and a message to help determine what went wrong.</p>

    <p></p>
  syntax:
    content: public InputStream generateThumbnailInStream(int width, int height, byte[] image, Boolean smartCropping)
    parameters:
    - id: width
      type: f75371fa
      description: <p>Width of the thumbnail. It must be between 1 and 1024. Recommended minimum of 50. </p>
    - id: height
      type: f75371fa
      description: <p>Height of the thumbnail. It must be between 1 and 1024. Recommended minimum of 50. </p>
    - id: image
      type: ccd9418d
      description: <p>An image stream. </p>
    - id: smartCropping
      type: 866c2227
      description: <p>Boolean flag for enabling smart cropping. </p>
    return:
      type: 76fcb9b7
      description: <p>the InputStream object if successful. </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
  - type: com.microsoft.azure.cognitiveservices.computervision._computer_vision_error_exception
    description: <p>thrown if the request is rejected by server </p>
  - type: 9b2a4515
    description: <p>all other wrapped checked exceptions if the request fails to be sent </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.generateThumbnailInStreamAsync(int,int,byte [])
  id: generateThumbnailInStreamAsync(int,int,byte [])
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: generateThumbnailInStreamAsync(int width, int height, byte[] image)
  nameWithType: ComputerVisionAPIImpl.generateThumbnailInStreamAsync(int width, int height, byte[] image)
  fullName: Observable<InputStream> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.generateThumbnailInStreamAsync(int width, int height, byte[] image)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.generateThumbnailInStreamAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 1616
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>This operation generates a thumbnail image with the user-specified width and height. By default, the service analyzes the image, identifies the region of interest (ROI), and generates smart cropping coordinates based on the ROI. Smart cropping helps when you specify an aspect ratio that differs from that of the input image. A successful response contains the thumbnail image binary. If the request failed, the response contains an error code and a message to help determine what went wrong.</p>

    <p></p>
  syntax:
    content: public Observable<InputStream> generateThumbnailInStreamAsync(int width, int height, byte[] image)
    parameters:
    - id: width
      type: f75371fa
      description: <p>Width of the thumbnail. It must be between 1 and 1024. Recommended minimum of 50. </p>
    - id: height
      type: f75371fa
      description: <p>Height of the thumbnail. It must be between 1 and 1024. Recommended minimum of 50. </p>
    - id: image
      type: ccd9418d
      description: <p>An image stream. </p>
    return:
      type: 3ab19265
      description: <p>the observable to the InputStream object </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.generateThumbnailInStreamAsync(int,int,byte [],Boolean)
  id: generateThumbnailInStreamAsync(int,int,byte [],Boolean)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: generateThumbnailInStreamAsync(int width, int height, byte[] image, Boolean smartCropping)
  nameWithType: ComputerVisionAPIImpl.generateThumbnailInStreamAsync(int width, int height, byte[] image, Boolean smartCropping)
  fullName: Observable<InputStream> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.generateThumbnailInStreamAsync(int width, int height, byte[] image, Boolean smartCropping)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.generateThumbnailInStreamAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 1699
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>This operation generates a thumbnail image with the user-specified width and height. By default, the service analyzes the image, identifies the region of interest (ROI), and generates smart cropping coordinates based on the ROI. Smart cropping helps when you specify an aspect ratio that differs from that of the input image. A successful response contains the thumbnail image binary. If the request failed, the response contains an error code and a message to help determine what went wrong.</p>

    <p></p>
  syntax:
    content: public Observable<InputStream> generateThumbnailInStreamAsync(int width, int height, byte[] image, Boolean smartCropping)
    parameters:
    - id: width
      type: f75371fa
      description: <p>Width of the thumbnail. It must be between 1 and 1024. Recommended minimum of 50. </p>
    - id: height
      type: f75371fa
      description: <p>Height of the thumbnail. It must be between 1 and 1024. Recommended minimum of 50. </p>
    - id: image
      type: ccd9418d
      description: <p>An image stream. </p>
    - id: smartCropping
      type: 866c2227
      description: <p>Boolean flag for enabling smart cropping. </p>
    return:
      type: 3ab19265
      description: <p>the observable to the InputStream object </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.generateThumbnailInStreamAsync(int,int,byte [],Boolean,final ServiceCallback<InputStream>)
  id: generateThumbnailInStreamAsync(int,int,byte [],Boolean,final ServiceCallback<InputStream>)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: generateThumbnailInStreamAsync(int width, int height, byte[] image, Boolean smartCropping, final ServiceCallback<InputStream> serviceCallback)
  nameWithType: ComputerVisionAPIImpl.generateThumbnailInStreamAsync(int width, int height, byte[] image, Boolean smartCropping, final ServiceCallback<InputStream> serviceCallback)
  fullName: ServiceFuture<InputStream> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.generateThumbnailInStreamAsync(int width, int height, byte[] image, Boolean smartCropping, final ServiceCallback<InputStream> serviceCallback)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.generateThumbnailInStreamAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 1685
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>This operation generates a thumbnail image with the user-specified width and height. By default, the service analyzes the image, identifies the region of interest (ROI), and generates smart cropping coordinates based on the ROI. Smart cropping helps when you specify an aspect ratio that differs from that of the input image. A successful response contains the thumbnail image binary. If the request failed, the response contains an error code and a message to help determine what went wrong.</p>

    <p></p>
  syntax:
    content: public ServiceFuture<InputStream> generateThumbnailInStreamAsync(int width, int height, byte[] image, Boolean smartCropping, final ServiceCallback<InputStream> serviceCallback)
    parameters:
    - id: width
      type: f75371fa
      description: <p>Width of the thumbnail. It must be between 1 and 1024. Recommended minimum of 50. </p>
    - id: height
      type: f75371fa
      description: <p>Height of the thumbnail. It must be between 1 and 1024. Recommended minimum of 50. </p>
    - id: image
      type: ccd9418d
      description: <p>An image stream. </p>
    - id: smartCropping
      type: 866c2227
      description: <p>Boolean flag for enabling smart cropping. </p>
    - id: serviceCallback
      type: 0377aee2
      description: <p>the async ServiceCallback to handle successful and failed responses. </p>
    return:
      type: 8601070c
      description: <p>the <xref uid="" data-throw-if-not-resolved="false">ServiceFuture</xref> object </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.generateThumbnailInStreamAsync(int,int,byte [],final ServiceCallback<InputStream>)
  id: generateThumbnailInStreamAsync(int,int,byte [],final ServiceCallback<InputStream>)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: generateThumbnailInStreamAsync(int width, int height, byte[] image, final ServiceCallback<InputStream> serviceCallback)
  nameWithType: ComputerVisionAPIImpl.generateThumbnailInStreamAsync(int width, int height, byte[] image, final ServiceCallback<InputStream> serviceCallback)
  fullName: ServiceFuture<InputStream> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.generateThumbnailInStreamAsync(int width, int height, byte[] image, final ServiceCallback<InputStream> serviceCallback)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.generateThumbnailInStreamAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 1603
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>This operation generates a thumbnail image with the user-specified width and height. By default, the service analyzes the image, identifies the region of interest (ROI), and generates smart cropping coordinates based on the ROI. Smart cropping helps when you specify an aspect ratio that differs from that of the input image. A successful response contains the thumbnail image binary. If the request failed, the response contains an error code and a message to help determine what went wrong.</p>

    <p></p>
  syntax:
    content: public ServiceFuture<InputStream> generateThumbnailInStreamAsync(int width, int height, byte[] image, final ServiceCallback<InputStream> serviceCallback)
    parameters:
    - id: width
      type: f75371fa
      description: <p>Width of the thumbnail. It must be between 1 and 1024. Recommended minimum of 50. </p>
    - id: height
      type: f75371fa
      description: <p>Height of the thumbnail. It must be between 1 and 1024. Recommended minimum of 50. </p>
    - id: image
      type: ccd9418d
      description: <p>An image stream. </p>
    - id: serviceCallback
      type: 0377aee2
      description: <p>the async ServiceCallback to handle successful and failed responses. </p>
    return:
      type: 8601070c
      description: <p>the <xref uid="" data-throw-if-not-resolved="false">ServiceFuture</xref> object </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.generateThumbnailInStreamWithServiceResponseAsync(int,int,byte [])
  id: generateThumbnailInStreamWithServiceResponseAsync(int,int,byte [])
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: generateThumbnailInStreamWithServiceResponseAsync(int width, int height, byte[] image)
  nameWithType: ComputerVisionAPIImpl.generateThumbnailInStreamWithServiceResponseAsync(int width, int height, byte[] image)
  fullName: Observable<ServiceResponse<InputStream>> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.generateThumbnailInStreamWithServiceResponseAsync(int width, int height, byte[] image)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.generateThumbnailInStreamWithServiceResponseAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 1634
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>This operation generates a thumbnail image with the user-specified width and height. By default, the service analyzes the image, identifies the region of interest (ROI), and generates smart cropping coordinates based on the ROI. Smart cropping helps when you specify an aspect ratio that differs from that of the input image. A successful response contains the thumbnail image binary. If the request failed, the response contains an error code and a message to help determine what went wrong.</p>

    <p></p>
  syntax:
    content: public Observable<ServiceResponse<InputStream>> generateThumbnailInStreamWithServiceResponseAsync(int width, int height, byte[] image)
    parameters:
    - id: width
      type: f75371fa
      description: <p>Width of the thumbnail. It must be between 1 and 1024. Recommended minimum of 50. </p>
    - id: height
      type: f75371fa
      description: <p>Height of the thumbnail. It must be between 1 and 1024. Recommended minimum of 50. </p>
    - id: image
      type: ccd9418d
      description: <p>An image stream. </p>
    return:
      type: b4669ca9
      description: <p>the observable to the InputStream object </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.generateThumbnailInStreamWithServiceResponseAsync(int,int,byte [],Boolean)
  id: generateThumbnailInStreamWithServiceResponseAsync(int,int,byte [],Boolean)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: generateThumbnailInStreamWithServiceResponseAsync(int width, int height, byte[] image, Boolean smartCropping)
  nameWithType: ComputerVisionAPIImpl.generateThumbnailInStreamWithServiceResponseAsync(int width, int height, byte[] image, Boolean smartCropping)
  fullName: Observable<ServiceResponse<InputStream>> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.generateThumbnailInStreamWithServiceResponseAsync(int width, int height, byte[] image, Boolean smartCropping)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.generateThumbnailInStreamWithServiceResponseAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 1718
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>This operation generates a thumbnail image with the user-specified width and height. By default, the service analyzes the image, identifies the region of interest (ROI), and generates smart cropping coordinates based on the ROI. Smart cropping helps when you specify an aspect ratio that differs from that of the input image. A successful response contains the thumbnail image binary. If the request failed, the response contains an error code and a message to help determine what went wrong.</p>

    <p></p>
  syntax:
    content: public Observable<ServiceResponse<InputStream>> generateThumbnailInStreamWithServiceResponseAsync(int width, int height, byte[] image, Boolean smartCropping)
    parameters:
    - id: width
      type: f75371fa
      description: <p>Width of the thumbnail. It must be between 1 and 1024. Recommended minimum of 50. </p>
    - id: height
      type: f75371fa
      description: <p>Height of the thumbnail. It must be between 1 and 1024. Recommended minimum of 50. </p>
    - id: image
      type: ccd9418d
      description: <p>An image stream. </p>
    - id: smartCropping
      type: 866c2227
      description: <p>Boolean flag for enabling smart cropping. </p>
    return:
      type: b4669ca9
      description: <p>the observable to the InputStream object </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.generateThumbnailWithServiceResponseAsync(int,int,String)
  id: generateThumbnailWithServiceResponseAsync(int,int,String)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: generateThumbnailWithServiceResponseAsync(int width, int height, String url)
  nameWithType: ComputerVisionAPIImpl.generateThumbnailWithServiceResponseAsync(int width, int height, String url)
  fullName: Observable<ServiceResponse<InputStream>> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.generateThumbnailWithServiceResponseAsync(int width, int height, String url)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.generateThumbnailWithServiceResponseAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 579
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>This operation generates a thumbnail image with the user-specified width and height. By default, the service analyzes the image, identifies the region of interest (ROI), and generates smart cropping coordinates based on the ROI. Smart cropping helps when you specify an aspect ratio that differs from that of the input image. A successful response contains the thumbnail image binary. If the request failed, the response contains an error code and a message to help determine what went wrong.</p>

    <p></p>
  syntax:
    content: public Observable<ServiceResponse<InputStream>> generateThumbnailWithServiceResponseAsync(int width, int height, String url)
    parameters:
    - id: width
      type: f75371fa
      description: <p>Width of the thumbnail. It must be between 1 and 1024. Recommended minimum of 50. </p>
    - id: height
      type: f75371fa
      description: <p>Height of the thumbnail. It must be between 1 and 1024. Recommended minimum of 50. </p>
    - id: url
      type: "26831127"
      description: <p>the String value </p>
    return:
      type: b4669ca9
      description: <p>the observable to the InputStream object </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.generateThumbnailWithServiceResponseAsync(int,int,String,Boolean)
  id: generateThumbnailWithServiceResponseAsync(int,int,String,Boolean)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: generateThumbnailWithServiceResponseAsync(int width, int height, String url, Boolean smartCropping)
  nameWithType: ComputerVisionAPIImpl.generateThumbnailWithServiceResponseAsync(int width, int height, String url, Boolean smartCropping)
  fullName: Observable<ServiceResponse<InputStream>> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.generateThumbnailWithServiceResponseAsync(int width, int height, String url, Boolean smartCropping)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.generateThumbnailWithServiceResponseAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 664
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>This operation generates a thumbnail image with the user-specified width and height. By default, the service analyzes the image, identifies the region of interest (ROI), and generates smart cropping coordinates based on the ROI. Smart cropping helps when you specify an aspect ratio that differs from that of the input image. A successful response contains the thumbnail image binary. If the request failed, the response contains an error code and a message to help determine what went wrong.</p>

    <p></p>
  syntax:
    content: public Observable<ServiceResponse<InputStream>> generateThumbnailWithServiceResponseAsync(int width, int height, String url, Boolean smartCropping)
    parameters:
    - id: width
      type: f75371fa
      description: <p>Width of the thumbnail. It must be between 1 and 1024. Recommended minimum of 50. </p>
    - id: height
      type: f75371fa
      description: <p>Height of the thumbnail. It must be between 1 and 1024. Recommended minimum of 50. </p>
    - id: url
      type: "26831127"
      description: <p>the String value </p>
    - id: smartCropping
      type: 866c2227
      description: <p>Boolean flag for enabling smart cropping. </p>
    return:
      type: b4669ca9
      description: <p>the observable to the InputStream object </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.getAzureClient()
  id: getAzureClient()
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: getAzureClient()
  nameWithType: ComputerVisionAPIImpl.getAzureClient()
  fullName: AzureClient com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.getAzureClient()
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.getAzureClient*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 60
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: <p>Gets the <xref uid="" data-throw-if-not-resolved="false">AzureClient</xref> used for long running operations. </p>
  syntax:
    content: public AzureClient getAzureClient()
    return:
      type: c1c26e8d
      description: <p>the azure client; </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.getTextOperationResult(String)
  id: getTextOperationResult(String)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: getTextOperationResult(String operationId)
  nameWithType: ComputerVisionAPIImpl.getTextOperationResult(String operationId)
  fullName: TextOperationResultInner com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.getTextOperationResult(String operationId)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.getTextOperationResult*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 1343
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>This interface is used for getting text operation result. The URL to this interface should be retrieved from 'Operation-Location' field returned from Recognize Text interface.</p>

    <p></p>
  syntax:
    content: public TextOperationResultInner getTextOperationResult(String operationId)
    parameters:
    - id: operationId
      type: "26831127"
      description: <p>Id of the text operation returned in the response of the 'Recognize Handwritten Text' </p>
    return:
      type: com.microsoft.azure.cognitiveservices.computervision.implementation._text_operation_result_inner
      description: <p>the <xref uid="com.microsoft.azure.cognitiveservices.computervision.implementation._text_operation_result_inner" data-throw-if-not-resolved="false">TextOperationResultInner</xref> object if successful. </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
  - type: com.microsoft.azure.cognitiveservices.computervision._computer_vision_error_exception
    description: <p>thrown if the request is rejected by server </p>
  - type: 9b2a4515
    description: <p>all other wrapped checked exceptions if the request fails to be sent </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.getTextOperationResultAsync(String)
  id: getTextOperationResultAsync(String)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: getTextOperationResultAsync(String operationId)
  nameWithType: ComputerVisionAPIImpl.getTextOperationResultAsync(String operationId)
  fullName: Observable<TextOperationResultInner> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.getTextOperationResultAsync(String operationId)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.getTextOperationResultAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 1366
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>This interface is used for getting text operation result. The URL to this interface should be retrieved from 'Operation-Location' field returned from Recognize Text interface.</p>

    <p></p>
  syntax:
    content: public Observable<TextOperationResultInner> getTextOperationResultAsync(String operationId)
    parameters:
    - id: operationId
      type: "26831127"
      description: <p>Id of the text operation returned in the response of the 'Recognize Handwritten Text' </p>
    return:
      type: c2d0e8c6com.microsoft.azure.cognitiveservices.computervision.implementation._text_operation_result_innera08ddfce
      description: <p>the observable to the <xref uid="com.microsoft.azure.cognitiveservices.computervision.implementation._text_operation_result_inner" data-throw-if-not-resolved="false">TextOperationResultInner</xref> object </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.getTextOperationResultAsync(String,final ServiceCallback<TextOperationResultInner>)
  id: getTextOperationResultAsync(String,final ServiceCallback<TextOperationResultInner>)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: getTextOperationResultAsync(String operationId, final ServiceCallback<TextOperationResultInner> serviceCallback)
  nameWithType: ComputerVisionAPIImpl.getTextOperationResultAsync(String operationId, final ServiceCallback<TextOperationResultInner> serviceCallback)
  fullName: ServiceFuture<TextOperationResultInner> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.getTextOperationResultAsync(String operationId, final ServiceCallback<TextOperationResultInner> serviceCallback)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.getTextOperationResultAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 1355
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>This interface is used for getting text operation result. The URL to this interface should be retrieved from 'Operation-Location' field returned from Recognize Text interface.</p>

    <p></p>
  syntax:
    content: public ServiceFuture<TextOperationResultInner> getTextOperationResultAsync(String operationId, final ServiceCallback<TextOperationResultInner> serviceCallback)
    parameters:
    - id: operationId
      type: "26831127"
      description: <p>Id of the text operation returned in the response of the 'Recognize Handwritten Text' </p>
    - id: serviceCallback
      type: 897eb10acom.microsoft.azure.cognitiveservices.computervision.implementation._text_operation_result_innera08ddfce
      description: <p>the async ServiceCallback to handle successful and failed responses. </p>
    return:
      type: c522ce07com.microsoft.azure.cognitiveservices.computervision.implementation._text_operation_result_innera08ddfce
      description: <p>the <xref uid="" data-throw-if-not-resolved="false">ServiceFuture</xref> object </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.getTextOperationResultWithServiceResponseAsync(String)
  id: getTextOperationResultWithServiceResponseAsync(String)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: getTextOperationResultWithServiceResponseAsync(String operationId)
  nameWithType: ComputerVisionAPIImpl.getTextOperationResultWithServiceResponseAsync(String operationId)
  fullName: Observable<ServiceResponse<TextOperationResultInner>> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.getTextOperationResultWithServiceResponseAsync(String operationId)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.getTextOperationResultWithServiceResponseAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 1382
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>This interface is used for getting text operation result. The URL to this interface should be retrieved from 'Operation-Location' field returned from Recognize Text interface.</p>

    <p></p>
  syntax:
    content: public Observable<ServiceResponse<TextOperationResultInner>> getTextOperationResultWithServiceResponseAsync(String operationId)
    parameters:
    - id: operationId
      type: "26831127"
      description: <p>Id of the text operation returned in the response of the 'Recognize Handwritten Text' </p>
    return:
      type: fc480ba2com.microsoft.azure.cognitiveservices.computervision.implementation._text_operation_result_innere7daa122
      description: <p>the observable to the <xref uid="com.microsoft.azure.cognitiveservices.computervision.implementation._text_operation_result_inner" data-throw-if-not-resolved="false">TextOperationResultInner</xref> object </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.initialize()
  id: initialize()
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: initialize()
  nameWithType: ComputerVisionAPIImpl.initialize()
  fullName: void com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.initialize()
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.initialize*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 186
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  syntax:
    content: protected void initialize()
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.listModels()
  id: listModels()
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: listModels()
  nameWithType: ComputerVisionAPIImpl.listModels()
  fullName: ListModelsResultInner com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.listModels()
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.listModels*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 289
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>This operation returns the list of domain-specific models that are supported by the Computer Vision API. Currently, the API only supports one domain-specific model: a celebrity recognizer. A successful response will be returned in JSON. If the request failed, the response will contain an error code and a message to help understand what went wrong.</p>

    <p></p>
  syntax:
    content: public ListModelsResultInner listModels()
    return:
      type: com.microsoft.azure.cognitiveservices.computervision.implementation._list_models_result_inner
      description: <p>the <xref uid="com.microsoft.azure.cognitiveservices.computervision.implementation._list_models_result_inner" data-throw-if-not-resolved="false">ListModelsResultInner</xref> object if successful. </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
  - type: com.microsoft.azure.cognitiveservices.computervision._computer_vision_error_exception
    description: <p>thrown if the request is rejected by server </p>
  - type: 9b2a4515
    description: <p>all other wrapped checked exceptions if the request fails to be sent </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.listModelsAsync()
  id: listModelsAsync()
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: listModelsAsync()
  nameWithType: ComputerVisionAPIImpl.listModelsAsync()
  fullName: Observable<ListModelsResultInner> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.listModelsAsync()
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.listModelsAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 310
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>This operation returns the list of domain-specific models that are supported by the Computer Vision API. Currently, the API only supports one domain-specific model: a celebrity recognizer. A successful response will be returned in JSON. If the request failed, the response will contain an error code and a message to help understand what went wrong.</p>

    <p></p>
  syntax:
    content: public Observable<ListModelsResultInner> listModelsAsync()
    return:
      type: c2d0e8c6com.microsoft.azure.cognitiveservices.computervision.implementation._list_models_result_innera08ddfce
      description: <p>the observable to the <xref uid="com.microsoft.azure.cognitiveservices.computervision.implementation._list_models_result_inner" data-throw-if-not-resolved="false">ListModelsResultInner</xref> object </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.listModelsAsync(final ServiceCallback<ListModelsResultInner>)
  id: listModelsAsync(final ServiceCallback<ListModelsResultInner>)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: listModelsAsync(final ServiceCallback<ListModelsResultInner> serviceCallback)
  nameWithType: ComputerVisionAPIImpl.listModelsAsync(final ServiceCallback<ListModelsResultInner> serviceCallback)
  fullName: ServiceFuture<ListModelsResultInner> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.listModelsAsync(final ServiceCallback<ListModelsResultInner> serviceCallback)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.listModelsAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 300
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>This operation returns the list of domain-specific models that are supported by the Computer Vision API. Currently, the API only supports one domain-specific model: a celebrity recognizer. A successful response will be returned in JSON. If the request failed, the response will contain an error code and a message to help understand what went wrong.</p>

    <p></p>
  syntax:
    content: public ServiceFuture<ListModelsResultInner> listModelsAsync(final ServiceCallback<ListModelsResultInner> serviceCallback)
    parameters:
    - id: serviceCallback
      type: 897eb10acom.microsoft.azure.cognitiveservices.computervision.implementation._list_models_result_innera08ddfce
      description: <p>the async ServiceCallback to handle successful and failed responses. </p>
    return:
      type: c522ce07com.microsoft.azure.cognitiveservices.computervision.implementation._list_models_result_innera08ddfce
      description: <p>the <xref uid="" data-throw-if-not-resolved="false">ServiceFuture</xref> object </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.listModelsWithServiceResponseAsync()
  id: listModelsWithServiceResponseAsync()
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: listModelsWithServiceResponseAsync()
  nameWithType: ComputerVisionAPIImpl.listModelsWithServiceResponseAsync()
  fullName: Observable<ServiceResponse<ListModelsResultInner>> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.listModelsWithServiceResponseAsync()
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.listModelsWithServiceResponseAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 325
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>This operation returns the list of domain-specific models that are supported by the Computer Vision API. Currently, the API only supports one domain-specific model: a celebrity recognizer. A successful response will be returned in JSON. If the request failed, the response will contain an error code and a message to help understand what went wrong.</p>

    <p></p>
  syntax:
    content: public Observable<ServiceResponse<ListModelsResultInner>> listModelsWithServiceResponseAsync()
    return:
      type: fc480ba2com.microsoft.azure.cognitiveservices.computervision.implementation._list_models_result_innere7daa122
      description: <p>the observable to the <xref uid="com.microsoft.azure.cognitiveservices.computervision.implementation._list_models_result_inner" data-throw-if-not-resolved="false">ListModelsResultInner</xref> object </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.longRunningOperationRetryTimeout()
  id: longRunningOperationRetryTimeout()
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: longRunningOperationRetryTimeout()
  nameWithType: ComputerVisionAPIImpl.longRunningOperationRetryTimeout()
  fullName: int com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.longRunningOperationRetryTimeout()
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.longRunningOperationRetryTimeout*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 118
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>Gets Gets or sets the retry timeout in seconds for Long Running Operations. Default value is 30.</p>

    <p></p>
  syntax:
    content: public int longRunningOperationRetryTimeout()
    return:
      type: f75371fa
      description: <p>the longRunningOperationRetryTimeout value. </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizePrintedText(boolean,String)
  id: recognizePrintedText(boolean,String)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: recognizePrintedText(boolean detectOrientation, String url)
  nameWithType: ComputerVisionAPIImpl.recognizePrintedText(boolean detectOrientation, String url)
  fullName: OcrResultInner com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.recognizePrintedText(boolean detectOrientation, String url)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizePrintedText*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 705
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>Optical Character Recognition (OCR) detects printed text in an image and extracts the recognized characters into a machine-usable character stream. Upon success, the OCR results will be returned. Upon failure, the error code together with an error message will be returned. The error code can be one of InvalidImageUrl, InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage, or InternalServerError.</p>

    <p></p>
  syntax:
    content: public OcrResultInner recognizePrintedText(boolean detectOrientation, String url)
    parameters:
    - id: detectOrientation
      type: 4fc6e284
      description: <p>Whether detect the text orientation in the image. With detectOrientation=true the OCR service tries to detect the image orientation and correct it before further processing (e.g. if it's upside-down). </p>
    - id: url
      type: "26831127"
      description: <p>the String value </p>
    return:
      type: com.microsoft.azure.cognitiveservices.computervision.implementation._ocr_result_inner
      description: <p>the <xref uid="com.microsoft.azure.cognitiveservices.computervision.implementation._ocr_result_inner" data-throw-if-not-resolved="false">OcrResultInner</xref> object if successful. </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
  - type: com.microsoft.azure.cognitiveservices.computervision._computer_vision_error_exception
    description: <p>thrown if the request is rejected by server </p>
  - type: 9b2a4515
    description: <p>all other wrapped checked exceptions if the request fails to be sent </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizePrintedText(boolean,String,OcrLanguages)
  id: recognizePrintedText(boolean,String,OcrLanguages)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: recognizePrintedText(boolean detectOrientation, String url, OcrLanguages language)
  nameWithType: ComputerVisionAPIImpl.recognizePrintedText(boolean detectOrientation, String url, OcrLanguages language)
  fullName: OcrResultInner com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.recognizePrintedText(boolean detectOrientation, String url, OcrLanguages language)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizePrintedText*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 783
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>Optical Character Recognition (OCR) detects printed text in an image and extracts the recognized characters into a machine-usable character stream. Upon success, the OCR results will be returned. Upon failure, the error code together with an error message will be returned. The error code can be one of InvalidImageUrl, InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage, or InternalServerError.</p>

    <p></p>
  syntax:
    content: public OcrResultInner recognizePrintedText(boolean detectOrientation, String url, OcrLanguages language)
    parameters:
    - id: detectOrientation
      type: 4fc6e284
      description: <p>Whether detect the text orientation in the image. With detectOrientation=true the OCR service tries to detect the image orientation and correct it before further processing (e.g. if it's upside-down). </p>
    - id: url
      type: "26831127"
      description: <p>the String value </p>
    - id: language
      type: com.microsoft.azure.cognitiveservices.computervision._ocr_languages
      description: "<p>The BCP-47 language code of the text to be detected in the image. The default value is 'unk'. Possible values include: 'unk', 'zh-Hans', 'zh-Hant', 'cs', 'da', 'nl', 'en', 'fi', 'fr', 'de', 'el', 'hu', 'it', 'ja', 'ko', 'nb', 'pl', 'pt', 'ru', 'es', 'sv', 'tr', 'ar', 'ro', 'sr-Cyrl', 'sr-Latn', 'sk' </p>"
    return:
      type: com.microsoft.azure.cognitiveservices.computervision.implementation._ocr_result_inner
      description: <p>the <xref uid="com.microsoft.azure.cognitiveservices.computervision.implementation._ocr_result_inner" data-throw-if-not-resolved="false">OcrResultInner</xref> object if successful. </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
  - type: com.microsoft.azure.cognitiveservices.computervision._computer_vision_error_exception
    description: <p>thrown if the request is rejected by server </p>
  - type: 9b2a4515
    description: <p>all other wrapped checked exceptions if the request fails to be sent </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizePrintedTextAsync(boolean,String)
  id: recognizePrintedTextAsync(boolean,String)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: recognizePrintedTextAsync(boolean detectOrientation, String url)
  nameWithType: ComputerVisionAPIImpl.recognizePrintedTextAsync(boolean detectOrientation, String url)
  fullName: Observable<OcrResultInner> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.recognizePrintedTextAsync(boolean detectOrientation, String url)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizePrintedTextAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 730
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>Optical Character Recognition (OCR) detects printed text in an image and extracts the recognized characters into a machine-usable character stream. Upon success, the OCR results will be returned. Upon failure, the error code together with an error message will be returned. The error code can be one of InvalidImageUrl, InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage, or InternalServerError.</p>

    <p></p>
  syntax:
    content: public Observable<OcrResultInner> recognizePrintedTextAsync(boolean detectOrientation, String url)
    parameters:
    - id: detectOrientation
      type: 4fc6e284
      description: <p>Whether detect the text orientation in the image. With detectOrientation=true the OCR service tries to detect the image orientation and correct it before further processing (e.g. if it's upside-down). </p>
    - id: url
      type: "26831127"
      description: <p>the String value </p>
    return:
      type: c2d0e8c6com.microsoft.azure.cognitiveservices.computervision.implementation._ocr_result_innera08ddfce
      description: <p>the observable to the <xref uid="com.microsoft.azure.cognitiveservices.computervision.implementation._ocr_result_inner" data-throw-if-not-resolved="false">OcrResultInner</xref> object </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizePrintedTextAsync(boolean,String,final ServiceCallback<OcrResultInner>)
  id: recognizePrintedTextAsync(boolean,String,final ServiceCallback<OcrResultInner>)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: recognizePrintedTextAsync(boolean detectOrientation, String url, final ServiceCallback<OcrResultInner> serviceCallback)
  nameWithType: ComputerVisionAPIImpl.recognizePrintedTextAsync(boolean detectOrientation, String url, final ServiceCallback<OcrResultInner> serviceCallback)
  fullName: ServiceFuture<OcrResultInner> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.recognizePrintedTextAsync(boolean detectOrientation, String url, final ServiceCallback<OcrResultInner> serviceCallback)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizePrintedTextAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 718
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>Optical Character Recognition (OCR) detects printed text in an image and extracts the recognized characters into a machine-usable character stream. Upon success, the OCR results will be returned. Upon failure, the error code together with an error message will be returned. The error code can be one of InvalidImageUrl, InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage, or InternalServerError.</p>

    <p></p>
  syntax:
    content: public ServiceFuture<OcrResultInner> recognizePrintedTextAsync(boolean detectOrientation, String url, final ServiceCallback<OcrResultInner> serviceCallback)
    parameters:
    - id: detectOrientation
      type: 4fc6e284
      description: <p>Whether detect the text orientation in the image. With detectOrientation=true the OCR service tries to detect the image orientation and correct it before further processing (e.g. if it's upside-down). </p>
    - id: url
      type: "26831127"
      description: <p>the String value </p>
    - id: serviceCallback
      type: 897eb10acom.microsoft.azure.cognitiveservices.computervision.implementation._ocr_result_innera08ddfce
      description: <p>the async ServiceCallback to handle successful and failed responses. </p>
    return:
      type: c522ce07com.microsoft.azure.cognitiveservices.computervision.implementation._ocr_result_innera08ddfce
      description: <p>the <xref uid="" data-throw-if-not-resolved="false">ServiceFuture</xref> object </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizePrintedTextAsync(boolean,String,OcrLanguages)
  id: recognizePrintedTextAsync(boolean,String,OcrLanguages)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: recognizePrintedTextAsync(boolean detectOrientation, String url, OcrLanguages language)
  nameWithType: ComputerVisionAPIImpl.recognizePrintedTextAsync(boolean detectOrientation, String url, OcrLanguages language)
  fullName: Observable<OcrResultInner> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.recognizePrintedTextAsync(boolean detectOrientation, String url, OcrLanguages language)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizePrintedTextAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 810
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>Optical Character Recognition (OCR) detects printed text in an image and extracts the recognized characters into a machine-usable character stream. Upon success, the OCR results will be returned. Upon failure, the error code together with an error message will be returned. The error code can be one of InvalidImageUrl, InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage, or InternalServerError.</p>

    <p></p>
  syntax:
    content: public Observable<OcrResultInner> recognizePrintedTextAsync(boolean detectOrientation, String url, OcrLanguages language)
    parameters:
    - id: detectOrientation
      type: 4fc6e284
      description: <p>Whether detect the text orientation in the image. With detectOrientation=true the OCR service tries to detect the image orientation and correct it before further processing (e.g. if it's upside-down). </p>
    - id: url
      type: "26831127"
      description: <p>the String value </p>
    - id: language
      type: com.microsoft.azure.cognitiveservices.computervision._ocr_languages
      description: "<p>The BCP-47 language code of the text to be detected in the image. The default value is 'unk'. Possible values include: 'unk', 'zh-Hans', 'zh-Hant', 'cs', 'da', 'nl', 'en', 'fi', 'fr', 'de', 'el', 'hu', 'it', 'ja', 'ko', 'nb', 'pl', 'pt', 'ru', 'es', 'sv', 'tr', 'ar', 'ro', 'sr-Cyrl', 'sr-Latn', 'sk' </p>"
    return:
      type: c2d0e8c6com.microsoft.azure.cognitiveservices.computervision.implementation._ocr_result_innera08ddfce
      description: <p>the observable to the <xref uid="com.microsoft.azure.cognitiveservices.computervision.implementation._ocr_result_inner" data-throw-if-not-resolved="false">OcrResultInner</xref> object </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizePrintedTextAsync(boolean,String,OcrLanguages,final ServiceCallback<OcrResultInner>)
  id: recognizePrintedTextAsync(boolean,String,OcrLanguages,final ServiceCallback<OcrResultInner>)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: recognizePrintedTextAsync(boolean detectOrientation, String url, OcrLanguages language, final ServiceCallback<OcrResultInner> serviceCallback)
  nameWithType: ComputerVisionAPIImpl.recognizePrintedTextAsync(boolean detectOrientation, String url, OcrLanguages language, final ServiceCallback<OcrResultInner> serviceCallback)
  fullName: ServiceFuture<OcrResultInner> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.recognizePrintedTextAsync(boolean detectOrientation, String url, OcrLanguages language, final ServiceCallback<OcrResultInner> serviceCallback)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizePrintedTextAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 797
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>Optical Character Recognition (OCR) detects printed text in an image and extracts the recognized characters into a machine-usable character stream. Upon success, the OCR results will be returned. Upon failure, the error code together with an error message will be returned. The error code can be one of InvalidImageUrl, InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage, or InternalServerError.</p>

    <p></p>
  syntax:
    content: public ServiceFuture<OcrResultInner> recognizePrintedTextAsync(boolean detectOrientation, String url, OcrLanguages language, final ServiceCallback<OcrResultInner> serviceCallback)
    parameters:
    - id: detectOrientation
      type: 4fc6e284
      description: <p>Whether detect the text orientation in the image. With detectOrientation=true the OCR service tries to detect the image orientation and correct it before further processing (e.g. if it's upside-down). </p>
    - id: url
      type: "26831127"
      description: <p>the String value </p>
    - id: language
      type: com.microsoft.azure.cognitiveservices.computervision._ocr_languages
      description: "<p>The BCP-47 language code of the text to be detected in the image. The default value is 'unk'. Possible values include: 'unk', 'zh-Hans', 'zh-Hant', 'cs', 'da', 'nl', 'en', 'fi', 'fr', 'de', 'el', 'hu', 'it', 'ja', 'ko', 'nb', 'pl', 'pt', 'ru', 'es', 'sv', 'tr', 'ar', 'ro', 'sr-Cyrl', 'sr-Latn', 'sk' </p>"
    - id: serviceCallback
      type: 897eb10acom.microsoft.azure.cognitiveservices.computervision.implementation._ocr_result_innera08ddfce
      description: <p>the async ServiceCallback to handle successful and failed responses. </p>
    return:
      type: c522ce07com.microsoft.azure.cognitiveservices.computervision.implementation._ocr_result_innera08ddfce
      description: <p>the <xref uid="" data-throw-if-not-resolved="false">ServiceFuture</xref> object </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizePrintedTextInStream(boolean,byte [])
  id: recognizePrintedTextInStream(boolean,byte [])
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: recognizePrintedTextInStream(boolean detectOrientation, byte[] image)
  nameWithType: ComputerVisionAPIImpl.recognizePrintedTextInStream(boolean detectOrientation, byte[] image)
  fullName: OcrResultInner com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.recognizePrintedTextInStream(boolean detectOrientation, byte[] image)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizePrintedTextInStream*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 1758
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>Optical Character Recognition (OCR) detects printed text in an image and extracts the recognized characters into a machine-usable character stream. Upon success, the OCR results will be returned. Upon failure, the error code together with an error message will be returned. The error code can be one of InvalidImageUrl, InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage, or InternalServerError.</p>

    <p></p>
  syntax:
    content: public OcrResultInner recognizePrintedTextInStream(boolean detectOrientation, byte[] image)
    parameters:
    - id: detectOrientation
      type: 4fc6e284
      description: <p>Whether detect the text orientation in the image. With detectOrientation=true the OCR service tries to detect the image orientation and correct it before further processing (e.g. if it's upside-down). </p>
    - id: image
      type: ccd9418d
      description: <p>An image stream. </p>
    return:
      type: com.microsoft.azure.cognitiveservices.computervision.implementation._ocr_result_inner
      description: <p>the <xref uid="com.microsoft.azure.cognitiveservices.computervision.implementation._ocr_result_inner" data-throw-if-not-resolved="false">OcrResultInner</xref> object if successful. </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
  - type: com.microsoft.azure.cognitiveservices.computervision._computer_vision_error_exception
    description: <p>thrown if the request is rejected by server </p>
  - type: 9b2a4515
    description: <p>all other wrapped checked exceptions if the request fails to be sent </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizePrintedTextInStream(boolean,byte [],OcrLanguages)
  id: recognizePrintedTextInStream(boolean,byte [],OcrLanguages)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: recognizePrintedTextInStream(boolean detectOrientation, byte[] image, OcrLanguages language)
  nameWithType: ComputerVisionAPIImpl.recognizePrintedTextInStream(boolean detectOrientation, byte[] image, OcrLanguages language)
  fullName: OcrResultInner com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.recognizePrintedTextInStream(boolean detectOrientation, byte[] image, OcrLanguages language)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizePrintedTextInStream*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 1835
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>Optical Character Recognition (OCR) detects printed text in an image and extracts the recognized characters into a machine-usable character stream. Upon success, the OCR results will be returned. Upon failure, the error code together with an error message will be returned. The error code can be one of InvalidImageUrl, InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage, or InternalServerError.</p>

    <p></p>
  syntax:
    content: public OcrResultInner recognizePrintedTextInStream(boolean detectOrientation, byte[] image, OcrLanguages language)
    parameters:
    - id: detectOrientation
      type: 4fc6e284
      description: <p>Whether detect the text orientation in the image. With detectOrientation=true the OCR service tries to detect the image orientation and correct it before further processing (e.g. if it's upside-down). </p>
    - id: image
      type: ccd9418d
      description: <p>An image stream. </p>
    - id: language
      type: com.microsoft.azure.cognitiveservices.computervision._ocr_languages
      description: "<p>The BCP-47 language code of the text to be detected in the image. The default value is 'unk'. Possible values include: 'unk', 'zh-Hans', 'zh-Hant', 'cs', 'da', 'nl', 'en', 'fi', 'fr', 'de', 'el', 'hu', 'it', 'ja', 'ko', 'nb', 'pl', 'pt', 'ru', 'es', 'sv', 'tr', 'ar', 'ro', 'sr-Cyrl', 'sr-Latn', 'sk' </p>"
    return:
      type: com.microsoft.azure.cognitiveservices.computervision.implementation._ocr_result_inner
      description: <p>the <xref uid="com.microsoft.azure.cognitiveservices.computervision.implementation._ocr_result_inner" data-throw-if-not-resolved="false">OcrResultInner</xref> object if successful. </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
  - type: com.microsoft.azure.cognitiveservices.computervision._computer_vision_error_exception
    description: <p>thrown if the request is rejected by server </p>
  - type: 9b2a4515
    description: <p>all other wrapped checked exceptions if the request fails to be sent </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizePrintedTextInStreamAsync(boolean,byte [])
  id: recognizePrintedTextInStreamAsync(boolean,byte [])
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: recognizePrintedTextInStreamAsync(boolean detectOrientation, byte[] image)
  nameWithType: ComputerVisionAPIImpl.recognizePrintedTextInStreamAsync(boolean detectOrientation, byte[] image)
  fullName: Observable<OcrResultInner> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.recognizePrintedTextInStreamAsync(boolean detectOrientation, byte[] image)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizePrintedTextInStreamAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 1783
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>Optical Character Recognition (OCR) detects printed text in an image and extracts the recognized characters into a machine-usable character stream. Upon success, the OCR results will be returned. Upon failure, the error code together with an error message will be returned. The error code can be one of InvalidImageUrl, InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage, or InternalServerError.</p>

    <p></p>
  syntax:
    content: public Observable<OcrResultInner> recognizePrintedTextInStreamAsync(boolean detectOrientation, byte[] image)
    parameters:
    - id: detectOrientation
      type: 4fc6e284
      description: <p>Whether detect the text orientation in the image. With detectOrientation=true the OCR service tries to detect the image orientation and correct it before further processing (e.g. if it's upside-down). </p>
    - id: image
      type: ccd9418d
      description: <p>An image stream. </p>
    return:
      type: c2d0e8c6com.microsoft.azure.cognitiveservices.computervision.implementation._ocr_result_innera08ddfce
      description: <p>the observable to the <xref uid="com.microsoft.azure.cognitiveservices.computervision.implementation._ocr_result_inner" data-throw-if-not-resolved="false">OcrResultInner</xref> object </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizePrintedTextInStreamAsync(boolean,byte [],final ServiceCallback<OcrResultInner>)
  id: recognizePrintedTextInStreamAsync(boolean,byte [],final ServiceCallback<OcrResultInner>)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: recognizePrintedTextInStreamAsync(boolean detectOrientation, byte[] image, final ServiceCallback<OcrResultInner> serviceCallback)
  nameWithType: ComputerVisionAPIImpl.recognizePrintedTextInStreamAsync(boolean detectOrientation, byte[] image, final ServiceCallback<OcrResultInner> serviceCallback)
  fullName: ServiceFuture<OcrResultInner> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.recognizePrintedTextInStreamAsync(boolean detectOrientation, byte[] image, final ServiceCallback<OcrResultInner> serviceCallback)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizePrintedTextInStreamAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 1771
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>Optical Character Recognition (OCR) detects printed text in an image and extracts the recognized characters into a machine-usable character stream. Upon success, the OCR results will be returned. Upon failure, the error code together with an error message will be returned. The error code can be one of InvalidImageUrl, InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage, or InternalServerError.</p>

    <p></p>
  syntax:
    content: public ServiceFuture<OcrResultInner> recognizePrintedTextInStreamAsync(boolean detectOrientation, byte[] image, final ServiceCallback<OcrResultInner> serviceCallback)
    parameters:
    - id: detectOrientation
      type: 4fc6e284
      description: <p>Whether detect the text orientation in the image. With detectOrientation=true the OCR service tries to detect the image orientation and correct it before further processing (e.g. if it's upside-down). </p>
    - id: image
      type: ccd9418d
      description: <p>An image stream. </p>
    - id: serviceCallback
      type: 897eb10acom.microsoft.azure.cognitiveservices.computervision.implementation._ocr_result_innera08ddfce
      description: <p>the async ServiceCallback to handle successful and failed responses. </p>
    return:
      type: c522ce07com.microsoft.azure.cognitiveservices.computervision.implementation._ocr_result_innera08ddfce
      description: <p>the <xref uid="" data-throw-if-not-resolved="false">ServiceFuture</xref> object </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizePrintedTextInStreamAsync(boolean,byte [],OcrLanguages)
  id: recognizePrintedTextInStreamAsync(boolean,byte [],OcrLanguages)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: recognizePrintedTextInStreamAsync(boolean detectOrientation, byte[] image, OcrLanguages language)
  nameWithType: ComputerVisionAPIImpl.recognizePrintedTextInStreamAsync(boolean detectOrientation, byte[] image, OcrLanguages language)
  fullName: Observable<OcrResultInner> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.recognizePrintedTextInStreamAsync(boolean detectOrientation, byte[] image, OcrLanguages language)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizePrintedTextInStreamAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 1862
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>Optical Character Recognition (OCR) detects printed text in an image and extracts the recognized characters into a machine-usable character stream. Upon success, the OCR results will be returned. Upon failure, the error code together with an error message will be returned. The error code can be one of InvalidImageUrl, InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage, or InternalServerError.</p>

    <p></p>
  syntax:
    content: public Observable<OcrResultInner> recognizePrintedTextInStreamAsync(boolean detectOrientation, byte[] image, OcrLanguages language)
    parameters:
    - id: detectOrientation
      type: 4fc6e284
      description: <p>Whether detect the text orientation in the image. With detectOrientation=true the OCR service tries to detect the image orientation and correct it before further processing (e.g. if it's upside-down). </p>
    - id: image
      type: ccd9418d
      description: <p>An image stream. </p>
    - id: language
      type: com.microsoft.azure.cognitiveservices.computervision._ocr_languages
      description: "<p>The BCP-47 language code of the text to be detected in the image. The default value is 'unk'. Possible values include: 'unk', 'zh-Hans', 'zh-Hant', 'cs', 'da', 'nl', 'en', 'fi', 'fr', 'de', 'el', 'hu', 'it', 'ja', 'ko', 'nb', 'pl', 'pt', 'ru', 'es', 'sv', 'tr', 'ar', 'ro', 'sr-Cyrl', 'sr-Latn', 'sk' </p>"
    return:
      type: c2d0e8c6com.microsoft.azure.cognitiveservices.computervision.implementation._ocr_result_innera08ddfce
      description: <p>the observable to the <xref uid="com.microsoft.azure.cognitiveservices.computervision.implementation._ocr_result_inner" data-throw-if-not-resolved="false">OcrResultInner</xref> object </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizePrintedTextInStreamAsync(boolean,byte [],OcrLanguages,final ServiceCallback<OcrResultInner>)
  id: recognizePrintedTextInStreamAsync(boolean,byte [],OcrLanguages,final ServiceCallback<OcrResultInner>)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: recognizePrintedTextInStreamAsync(boolean detectOrientation, byte[] image, OcrLanguages language, final ServiceCallback<OcrResultInner> serviceCallback)
  nameWithType: ComputerVisionAPIImpl.recognizePrintedTextInStreamAsync(boolean detectOrientation, byte[] image, OcrLanguages language, final ServiceCallback<OcrResultInner> serviceCallback)
  fullName: ServiceFuture<OcrResultInner> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.recognizePrintedTextInStreamAsync(boolean detectOrientation, byte[] image, OcrLanguages language, final ServiceCallback<OcrResultInner> serviceCallback)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizePrintedTextInStreamAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 1849
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>Optical Character Recognition (OCR) detects printed text in an image and extracts the recognized characters into a machine-usable character stream. Upon success, the OCR results will be returned. Upon failure, the error code together with an error message will be returned. The error code can be one of InvalidImageUrl, InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage, or InternalServerError.</p>

    <p></p>
  syntax:
    content: public ServiceFuture<OcrResultInner> recognizePrintedTextInStreamAsync(boolean detectOrientation, byte[] image, OcrLanguages language, final ServiceCallback<OcrResultInner> serviceCallback)
    parameters:
    - id: detectOrientation
      type: 4fc6e284
      description: <p>Whether detect the text orientation in the image. With detectOrientation=true the OCR service tries to detect the image orientation and correct it before further processing (e.g. if it's upside-down). </p>
    - id: image
      type: ccd9418d
      description: <p>An image stream. </p>
    - id: language
      type: com.microsoft.azure.cognitiveservices.computervision._ocr_languages
      description: "<p>The BCP-47 language code of the text to be detected in the image. The default value is 'unk'. Possible values include: 'unk', 'zh-Hans', 'zh-Hant', 'cs', 'da', 'nl', 'en', 'fi', 'fr', 'de', 'el', 'hu', 'it', 'ja', 'ko', 'nb', 'pl', 'pt', 'ru', 'es', 'sv', 'tr', 'ar', 'ro', 'sr-Cyrl', 'sr-Latn', 'sk' </p>"
    - id: serviceCallback
      type: 897eb10acom.microsoft.azure.cognitiveservices.computervision.implementation._ocr_result_innera08ddfce
      description: <p>the async ServiceCallback to handle successful and failed responses. </p>
    return:
      type: c522ce07com.microsoft.azure.cognitiveservices.computervision.implementation._ocr_result_innera08ddfce
      description: <p>the <xref uid="" data-throw-if-not-resolved="false">ServiceFuture</xref> object </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizePrintedTextInStreamWithServiceResponseAsync(boolean,byte [])
  id: recognizePrintedTextInStreamWithServiceResponseAsync(boolean,byte [])
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: recognizePrintedTextInStreamWithServiceResponseAsync(boolean detectOrientation, byte[] image)
  nameWithType: ComputerVisionAPIImpl.recognizePrintedTextInStreamWithServiceResponseAsync(boolean detectOrientation, byte[] image)
  fullName: Observable<ServiceResponse<OcrResultInner>> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.recognizePrintedTextInStreamWithServiceResponseAsync(boolean detectOrientation, byte[] image)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizePrintedTextInStreamWithServiceResponseAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 1800
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>Optical Character Recognition (OCR) detects printed text in an image and extracts the recognized characters into a machine-usable character stream. Upon success, the OCR results will be returned. Upon failure, the error code together with an error message will be returned. The error code can be one of InvalidImageUrl, InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage, or InternalServerError.</p>

    <p></p>
  syntax:
    content: public Observable<ServiceResponse<OcrResultInner>> recognizePrintedTextInStreamWithServiceResponseAsync(boolean detectOrientation, byte[] image)
    parameters:
    - id: detectOrientation
      type: 4fc6e284
      description: <p>Whether detect the text orientation in the image. With detectOrientation=true the OCR service tries to detect the image orientation and correct it before further processing (e.g. if it's upside-down). </p>
    - id: image
      type: ccd9418d
      description: <p>An image stream. </p>
    return:
      type: fc480ba2com.microsoft.azure.cognitiveservices.computervision.implementation._ocr_result_innere7daa122
      description: <p>the observable to the <xref uid="com.microsoft.azure.cognitiveservices.computervision.implementation._ocr_result_inner" data-throw-if-not-resolved="false">OcrResultInner</xref> object </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizePrintedTextInStreamWithServiceResponseAsync(boolean,byte [],OcrLanguages)
  id: recognizePrintedTextInStreamWithServiceResponseAsync(boolean,byte [],OcrLanguages)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: recognizePrintedTextInStreamWithServiceResponseAsync(boolean detectOrientation, byte[] image, OcrLanguages language)
  nameWithType: ComputerVisionAPIImpl.recognizePrintedTextInStreamWithServiceResponseAsync(boolean detectOrientation, byte[] image, OcrLanguages language)
  fullName: Observable<ServiceResponse<OcrResultInner>> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.recognizePrintedTextInStreamWithServiceResponseAsync(boolean detectOrientation, byte[] image, OcrLanguages language)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizePrintedTextInStreamWithServiceResponseAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 1880
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>Optical Character Recognition (OCR) detects printed text in an image and extracts the recognized characters into a machine-usable character stream. Upon success, the OCR results will be returned. Upon failure, the error code together with an error message will be returned. The error code can be one of InvalidImageUrl, InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage, or InternalServerError.</p>

    <p></p>
  syntax:
    content: public Observable<ServiceResponse<OcrResultInner>> recognizePrintedTextInStreamWithServiceResponseAsync(boolean detectOrientation, byte[] image, OcrLanguages language)
    parameters:
    - id: detectOrientation
      type: 4fc6e284
      description: <p>Whether detect the text orientation in the image. With detectOrientation=true the OCR service tries to detect the image orientation and correct it before further processing (e.g. if it's upside-down). </p>
    - id: image
      type: ccd9418d
      description: <p>An image stream. </p>
    - id: language
      type: com.microsoft.azure.cognitiveservices.computervision._ocr_languages
      description: "<p>The BCP-47 language code of the text to be detected in the image. The default value is 'unk'. Possible values include: 'unk', 'zh-Hans', 'zh-Hant', 'cs', 'da', 'nl', 'en', 'fi', 'fr', 'de', 'el', 'hu', 'it', 'ja', 'ko', 'nb', 'pl', 'pt', 'ru', 'es', 'sv', 'tr', 'ar', 'ro', 'sr-Cyrl', 'sr-Latn', 'sk' </p>"
    return:
      type: fc480ba2com.microsoft.azure.cognitiveservices.computervision.implementation._ocr_result_innere7daa122
      description: <p>the observable to the <xref uid="com.microsoft.azure.cognitiveservices.computervision.implementation._ocr_result_inner" data-throw-if-not-resolved="false">OcrResultInner</xref> object </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizePrintedTextWithServiceResponseAsync(boolean,String)
  id: recognizePrintedTextWithServiceResponseAsync(boolean,String)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: recognizePrintedTextWithServiceResponseAsync(boolean detectOrientation, String url)
  nameWithType: ComputerVisionAPIImpl.recognizePrintedTextWithServiceResponseAsync(boolean detectOrientation, String url)
  fullName: Observable<ServiceResponse<OcrResultInner>> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.recognizePrintedTextWithServiceResponseAsync(boolean detectOrientation, String url)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizePrintedTextWithServiceResponseAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 747
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>Optical Character Recognition (OCR) detects printed text in an image and extracts the recognized characters into a machine-usable character stream. Upon success, the OCR results will be returned. Upon failure, the error code together with an error message will be returned. The error code can be one of InvalidImageUrl, InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage, or InternalServerError.</p>

    <p></p>
  syntax:
    content: public Observable<ServiceResponse<OcrResultInner>> recognizePrintedTextWithServiceResponseAsync(boolean detectOrientation, String url)
    parameters:
    - id: detectOrientation
      type: 4fc6e284
      description: <p>Whether detect the text orientation in the image. With detectOrientation=true the OCR service tries to detect the image orientation and correct it before further processing (e.g. if it's upside-down). </p>
    - id: url
      type: "26831127"
      description: <p>the String value </p>
    return:
      type: fc480ba2com.microsoft.azure.cognitiveservices.computervision.implementation._ocr_result_innere7daa122
      description: <p>the observable to the <xref uid="com.microsoft.azure.cognitiveservices.computervision.implementation._ocr_result_inner" data-throw-if-not-resolved="false">OcrResultInner</xref> object </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizePrintedTextWithServiceResponseAsync(boolean,String,OcrLanguages)
  id: recognizePrintedTextWithServiceResponseAsync(boolean,String,OcrLanguages)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: recognizePrintedTextWithServiceResponseAsync(boolean detectOrientation, String url, OcrLanguages language)
  nameWithType: ComputerVisionAPIImpl.recognizePrintedTextWithServiceResponseAsync(boolean detectOrientation, String url, OcrLanguages language)
  fullName: Observable<ServiceResponse<OcrResultInner>> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.recognizePrintedTextWithServiceResponseAsync(boolean detectOrientation, String url, OcrLanguages language)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizePrintedTextWithServiceResponseAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 828
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>Optical Character Recognition (OCR) detects printed text in an image and extracts the recognized characters into a machine-usable character stream. Upon success, the OCR results will be returned. Upon failure, the error code together with an error message will be returned. The error code can be one of InvalidImageUrl, InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage, or InternalServerError.</p>

    <p></p>
  syntax:
    content: public Observable<ServiceResponse<OcrResultInner>> recognizePrintedTextWithServiceResponseAsync(boolean detectOrientation, String url, OcrLanguages language)
    parameters:
    - id: detectOrientation
      type: 4fc6e284
      description: <p>Whether detect the text orientation in the image. With detectOrientation=true the OCR service tries to detect the image orientation and correct it before further processing (e.g. if it's upside-down). </p>
    - id: url
      type: "26831127"
      description: <p>the String value </p>
    - id: language
      type: com.microsoft.azure.cognitiveservices.computervision._ocr_languages
      description: "<p>The BCP-47 language code of the text to be detected in the image. The default value is 'unk'. Possible values include: 'unk', 'zh-Hans', 'zh-Hant', 'cs', 'da', 'nl', 'en', 'fi', 'fr', 'de', 'el', 'hu', 'it', 'ja', 'ko', 'nb', 'pl', 'pt', 'ru', 'es', 'sv', 'tr', 'ar', 'ro', 'sr-Cyrl', 'sr-Latn', 'sk' </p>"
    return:
      type: fc480ba2com.microsoft.azure.cognitiveservices.computervision.implementation._ocr_result_innere7daa122
      description: <p>the observable to the <xref uid="com.microsoft.azure.cognitiveservices.computervision.implementation._ocr_result_inner" data-throw-if-not-resolved="false">OcrResultInner</xref> object </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizeText(String)
  id: recognizeText(String)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: recognizeText(String url)
  nameWithType: ComputerVisionAPIImpl.recognizeText(String url)
  fullName: void com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.recognizeText(String url)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizeText*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 1188
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>Recognize Text operation. When you use the Recognize Text interface, the response contains a field called “Operation-Location”. The “Operation-Location” field contains the URL that you must use for your Get Handwritten Text Operation Result operation.</p>

    <p></p>
  syntax:
    content: public void recognizeText(String url)
    parameters:
    - id: url
      type: "26831127"
      description: <p>the String value </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
  - type: com.microsoft.azure.cognitiveservices.computervision._computer_vision_error_exception
    description: <p>thrown if the request is rejected by server </p>
  - type: 9b2a4515
    description: <p>all other wrapped checked exceptions if the request fails to be sent </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizeText(String,Boolean)
  id: recognizeText(String,Boolean)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: recognizeText(String url, Boolean detectHandwriting)
  nameWithType: ComputerVisionAPIImpl.recognizeText(String url, Boolean detectHandwriting)
  fullName: void com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.recognizeText(String url, Boolean detectHandwriting)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizeText*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 1261
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>Recognize Text operation. When you use the Recognize Text interface, the response contains a field called “Operation-Location”. The “Operation-Location” field contains the URL that you must use for your Get Handwritten Text Operation Result operation.</p>

    <p></p>
  syntax:
    content: public void recognizeText(String url, Boolean detectHandwriting)
    parameters:
    - id: url
      type: "26831127"
      description: <p>the String value </p>
    - id: detectHandwriting
      type: 866c2227
      description: <p>If “true” is specified, handwriting recognition is performed. If this parameter is set to “false” or is not specified, printed text recognition is performed. </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
  - type: com.microsoft.azure.cognitiveservices.computervision._computer_vision_error_exception
    description: <p>thrown if the request is rejected by server </p>
  - type: 9b2a4515
    description: <p>all other wrapped checked exceptions if the request fails to be sent </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizeTextAsync(String)
  id: recognizeTextAsync(String)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: recognizeTextAsync(String url)
  nameWithType: ComputerVisionAPIImpl.recognizeTextAsync(String url)
  fullName: Observable<Void> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.recognizeTextAsync(String url)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizeTextAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 1211
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>Recognize Text operation. When you use the Recognize Text interface, the response contains a field called “Operation-Location”. The “Operation-Location” field contains the URL that you must use for your Get Handwritten Text Operation Result operation.</p>

    <p></p>
  syntax:
    content: public Observable<Void> recognizeTextAsync(String url)
    parameters:
    - id: url
      type: "26831127"
      description: <p>the String value </p>
    return:
      type: dcd884b2
      description: <p>the <xref uid="" data-throw-if-not-resolved="false">ServiceResponseWithHeaders</xref> object if successful. </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizeTextAsync(String,Boolean)
  id: recognizeTextAsync(String,Boolean)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: recognizeTextAsync(String url, Boolean detectHandwriting)
  nameWithType: ComputerVisionAPIImpl.recognizeTextAsync(String url, Boolean detectHandwriting)
  fullName: Observable<Void> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.recognizeTextAsync(String url, Boolean detectHandwriting)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizeTextAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 1286
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>Recognize Text operation. When you use the Recognize Text interface, the response contains a field called “Operation-Location”. The “Operation-Location” field contains the URL that you must use for your Get Handwritten Text Operation Result operation.</p>

    <p></p>
  syntax:
    content: public Observable<Void> recognizeTextAsync(String url, Boolean detectHandwriting)
    parameters:
    - id: url
      type: "26831127"
      description: <p>the String value </p>
    - id: detectHandwriting
      type: 866c2227
      description: <p>If “true” is specified, handwriting recognition is performed. If this parameter is set to “false” or is not specified, printed text recognition is performed. </p>
    return:
      type: dcd884b2
      description: <p>the <xref uid="" data-throw-if-not-resolved="false">ServiceResponseWithHeaders</xref> object if successful. </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizeTextAsync(String,Boolean,final ServiceCallback<Void>)
  id: recognizeTextAsync(String,Boolean,final ServiceCallback<Void>)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: recognizeTextAsync(String url, Boolean detectHandwriting, final ServiceCallback<Void> serviceCallback)
  nameWithType: ComputerVisionAPIImpl.recognizeTextAsync(String url, Boolean detectHandwriting, final ServiceCallback<Void> serviceCallback)
  fullName: ServiceFuture<Void> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.recognizeTextAsync(String url, Boolean detectHandwriting, final ServiceCallback<Void> serviceCallback)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizeTextAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 1274
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>Recognize Text operation. When you use the Recognize Text interface, the response contains a field called “Operation-Location”. The “Operation-Location” field contains the URL that you must use for your Get Handwritten Text Operation Result operation.</p>

    <p></p>
  syntax:
    content: public ServiceFuture<Void> recognizeTextAsync(String url, Boolean detectHandwriting, final ServiceCallback<Void> serviceCallback)
    parameters:
    - id: url
      type: "26831127"
      description: <p>the String value </p>
    - id: detectHandwriting
      type: 866c2227
      description: <p>If “true” is specified, handwriting recognition is performed. If this parameter is set to “false” or is not specified, printed text recognition is performed. </p>
    - id: serviceCallback
      type: 1c186eb5
      description: <p>the async ServiceCallback to handle successful and failed responses. </p>
    return:
      type: aa81d378
      description: <p>the <xref uid="" data-throw-if-not-resolved="false">ServiceFuture</xref> object </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizeTextAsync(String,final ServiceCallback<Void>)
  id: recognizeTextAsync(String,final ServiceCallback<Void>)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: recognizeTextAsync(String url, final ServiceCallback<Void> serviceCallback)
  nameWithType: ComputerVisionAPIImpl.recognizeTextAsync(String url, final ServiceCallback<Void> serviceCallback)
  fullName: ServiceFuture<Void> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.recognizeTextAsync(String url, final ServiceCallback<Void> serviceCallback)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizeTextAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 1200
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>Recognize Text operation. When you use the Recognize Text interface, the response contains a field called “Operation-Location”. The “Operation-Location” field contains the URL that you must use for your Get Handwritten Text Operation Result operation.</p>

    <p></p>
  syntax:
    content: public ServiceFuture<Void> recognizeTextAsync(String url, final ServiceCallback<Void> serviceCallback)
    parameters:
    - id: url
      type: "26831127"
      description: <p>the String value </p>
    - id: serviceCallback
      type: 1c186eb5
      description: <p>the async ServiceCallback to handle successful and failed responses. </p>
    return:
      type: aa81d378
      description: <p>the <xref uid="" data-throw-if-not-resolved="false">ServiceFuture</xref> object </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizeTextInStream(byte [])
  id: recognizeTextInStream(byte [])
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: recognizeTextInStream(byte[] image)
  nameWithType: ComputerVisionAPIImpl.recognizeTextInStream(byte[] image)
  fullName: void com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.recognizeTextInStream(byte[] image)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizeTextInStream*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 2235
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>Recognize Text operation. When you use the Recognize Text interface, the response contains a field called “Operation-Location”. The “Operation-Location” field contains the URL that you must use for your Get Handwritten Text Operation Result operation.</p>

    <p></p>
  syntax:
    content: public void recognizeTextInStream(byte[] image)
    parameters:
    - id: image
      type: ccd9418d
      description: <p>An image stream. </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
  - type: com.microsoft.azure.cognitiveservices.computervision._computer_vision_error_exception
    description: <p>thrown if the request is rejected by server </p>
  - type: 9b2a4515
    description: <p>all other wrapped checked exceptions if the request fails to be sent </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizeTextInStream(byte [],Boolean)
  id: recognizeTextInStream(byte [],Boolean)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: recognizeTextInStream(byte[] image, Boolean detectHandwriting)
  nameWithType: ComputerVisionAPIImpl.recognizeTextInStream(byte[] image, Boolean detectHandwriting)
  fullName: void com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.recognizeTextInStream(byte[] image, Boolean detectHandwriting)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizeTextInStream*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 2307
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>Recognize Text operation. When you use the Recognize Text interface, the response contains a field called “Operation-Location”. The “Operation-Location” field contains the URL that you must use for your Get Handwritten Text Operation Result operation.</p>

    <p></p>
  syntax:
    content: public void recognizeTextInStream(byte[] image, Boolean detectHandwriting)
    parameters:
    - id: image
      type: ccd9418d
      description: <p>An image stream. </p>
    - id: detectHandwriting
      type: 866c2227
      description: <p>If “true” is specified, handwriting recognition is performed. If this parameter is set to “false” or is not specified, printed text recognition is performed. </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
  - type: com.microsoft.azure.cognitiveservices.computervision._computer_vision_error_exception
    description: <p>thrown if the request is rejected by server </p>
  - type: 9b2a4515
    description: <p>all other wrapped checked exceptions if the request fails to be sent </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizeTextInStreamAsync(byte [])
  id: recognizeTextInStreamAsync(byte [])
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: recognizeTextInStreamAsync(byte[] image)
  nameWithType: ComputerVisionAPIImpl.recognizeTextInStreamAsync(byte[] image)
  fullName: Observable<Void> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.recognizeTextInStreamAsync(byte[] image)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizeTextInStreamAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 2258
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>Recognize Text operation. When you use the Recognize Text interface, the response contains a field called “Operation-Location”. The “Operation-Location” field contains the URL that you must use for your Get Handwritten Text Operation Result operation.</p>

    <p></p>
  syntax:
    content: public Observable<Void> recognizeTextInStreamAsync(byte[] image)
    parameters:
    - id: image
      type: ccd9418d
      description: <p>An image stream. </p>
    return:
      type: dcd884b2
      description: <p>the <xref uid="" data-throw-if-not-resolved="false">ServiceResponseWithHeaders</xref> object if successful. </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizeTextInStreamAsync(byte [],Boolean)
  id: recognizeTextInStreamAsync(byte [],Boolean)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: recognizeTextInStreamAsync(byte[] image, Boolean detectHandwriting)
  nameWithType: ComputerVisionAPIImpl.recognizeTextInStreamAsync(byte[] image, Boolean detectHandwriting)
  fullName: Observable<Void> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.recognizeTextInStreamAsync(byte[] image, Boolean detectHandwriting)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizeTextInStreamAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 2332
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>Recognize Text operation. When you use the Recognize Text interface, the response contains a field called “Operation-Location”. The “Operation-Location” field contains the URL that you must use for your Get Handwritten Text Operation Result operation.</p>

    <p></p>
  syntax:
    content: public Observable<Void> recognizeTextInStreamAsync(byte[] image, Boolean detectHandwriting)
    parameters:
    - id: image
      type: ccd9418d
      description: <p>An image stream. </p>
    - id: detectHandwriting
      type: 866c2227
      description: <p>If “true” is specified, handwriting recognition is performed. If this parameter is set to “false” or is not specified, printed text recognition is performed. </p>
    return:
      type: dcd884b2
      description: <p>the <xref uid="" data-throw-if-not-resolved="false">ServiceResponseWithHeaders</xref> object if successful. </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizeTextInStreamAsync(byte [],Boolean,final ServiceCallback<Void>)
  id: recognizeTextInStreamAsync(byte [],Boolean,final ServiceCallback<Void>)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: recognizeTextInStreamAsync(byte[] image, Boolean detectHandwriting, final ServiceCallback<Void> serviceCallback)
  nameWithType: ComputerVisionAPIImpl.recognizeTextInStreamAsync(byte[] image, Boolean detectHandwriting, final ServiceCallback<Void> serviceCallback)
  fullName: ServiceFuture<Void> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.recognizeTextInStreamAsync(byte[] image, Boolean detectHandwriting, final ServiceCallback<Void> serviceCallback)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizeTextInStreamAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 2320
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>Recognize Text operation. When you use the Recognize Text interface, the response contains a field called “Operation-Location”. The “Operation-Location” field contains the URL that you must use for your Get Handwritten Text Operation Result operation.</p>

    <p></p>
  syntax:
    content: public ServiceFuture<Void> recognizeTextInStreamAsync(byte[] image, Boolean detectHandwriting, final ServiceCallback<Void> serviceCallback)
    parameters:
    - id: image
      type: ccd9418d
      description: <p>An image stream. </p>
    - id: detectHandwriting
      type: 866c2227
      description: <p>If “true” is specified, handwriting recognition is performed. If this parameter is set to “false” or is not specified, printed text recognition is performed. </p>
    - id: serviceCallback
      type: 1c186eb5
      description: <p>the async ServiceCallback to handle successful and failed responses. </p>
    return:
      type: aa81d378
      description: <p>the <xref uid="" data-throw-if-not-resolved="false">ServiceFuture</xref> object </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizeTextInStreamAsync(byte [],final ServiceCallback<Void>)
  id: recognizeTextInStreamAsync(byte [],final ServiceCallback<Void>)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: recognizeTextInStreamAsync(byte[] image, final ServiceCallback<Void> serviceCallback)
  nameWithType: ComputerVisionAPIImpl.recognizeTextInStreamAsync(byte[] image, final ServiceCallback<Void> serviceCallback)
  fullName: ServiceFuture<Void> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.recognizeTextInStreamAsync(byte[] image, final ServiceCallback<Void> serviceCallback)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizeTextInStreamAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 2247
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>Recognize Text operation. When you use the Recognize Text interface, the response contains a field called “Operation-Location”. The “Operation-Location” field contains the URL that you must use for your Get Handwritten Text Operation Result operation.</p>

    <p></p>
  syntax:
    content: public ServiceFuture<Void> recognizeTextInStreamAsync(byte[] image, final ServiceCallback<Void> serviceCallback)
    parameters:
    - id: image
      type: ccd9418d
      description: <p>An image stream. </p>
    - id: serviceCallback
      type: 1c186eb5
      description: <p>the async ServiceCallback to handle successful and failed responses. </p>
    return:
      type: aa81d378
      description: <p>the <xref uid="" data-throw-if-not-resolved="false">ServiceFuture</xref> object </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizeTextInStreamWithServiceResponseAsync(byte [])
  id: recognizeTextInStreamWithServiceResponseAsync(byte [])
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: recognizeTextInStreamWithServiceResponseAsync(byte[] image)
  nameWithType: ComputerVisionAPIImpl.recognizeTextInStreamWithServiceResponseAsync(byte[] image)
  fullName: Observable<ServiceResponseWithHeaders<Void, RecognizeTextInStreamHeadersInner>> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.recognizeTextInStreamWithServiceResponseAsync(byte[] image)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizeTextInStreamWithServiceResponseAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 2274
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>Recognize Text operation. When you use the Recognize Text interface, the response contains a field called “Operation-Location”. The “Operation-Location” field contains the URL that you must use for your Get Handwritten Text Operation Result operation.</p>

    <p></p>
  syntax:
    content: public Observable<ServiceResponseWithHeaders<Void, RecognizeTextInStreamHeadersInner>> recognizeTextInStreamWithServiceResponseAsync(byte[] image)
    parameters:
    - id: image
      type: ccd9418d
      description: <p>An image stream. </p>
    return:
      type: 6738ce59com.microsoft.azure.cognitiveservices.computervision.implementation._reco2bb3a00c0d01a8e8a9d04b46d2399ab7e7daa122
      description: <p>the <xref uid="" data-throw-if-not-resolved="false">ServiceResponseWithHeaders</xref> object if successful. </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizeTextInStreamWithServiceResponseAsync(byte [],Boolean)
  id: recognizeTextInStreamWithServiceResponseAsync(byte [],Boolean)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: recognizeTextInStreamWithServiceResponseAsync(byte[] image, Boolean detectHandwriting)
  nameWithType: ComputerVisionAPIImpl.recognizeTextInStreamWithServiceResponseAsync(byte[] image, Boolean detectHandwriting)
  fullName: Observable<ServiceResponseWithHeaders<Void, RecognizeTextInStreamHeadersInner>> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.recognizeTextInStreamWithServiceResponseAsync(byte[] image, Boolean detectHandwriting)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizeTextInStreamWithServiceResponseAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 2349
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>Recognize Text operation. When you use the Recognize Text interface, the response contains a field called “Operation-Location”. The “Operation-Location” field contains the URL that you must use for your Get Handwritten Text Operation Result operation.</p>

    <p></p>
  syntax:
    content: public Observable<ServiceResponseWithHeaders<Void, RecognizeTextInStreamHeadersInner>> recognizeTextInStreamWithServiceResponseAsync(byte[] image, Boolean detectHandwriting)
    parameters:
    - id: image
      type: ccd9418d
      description: <p>An image stream. </p>
    - id: detectHandwriting
      type: 866c2227
      description: <p>If “true” is specified, handwriting recognition is performed. If this parameter is set to “false” or is not specified, printed text recognition is performed. </p>
    return:
      type: 6738ce59com.microsoft.azure.cognitiveservices.computervision.implementation._reco2bb3a00c0d01a8e8a9d04b46d2399ab7e7daa122
      description: <p>the <xref uid="" data-throw-if-not-resolved="false">ServiceResponseWithHeaders</xref> object if successful. </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizeTextWithServiceResponseAsync(String)
  id: recognizeTextWithServiceResponseAsync(String)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: recognizeTextWithServiceResponseAsync(String url)
  nameWithType: ComputerVisionAPIImpl.recognizeTextWithServiceResponseAsync(String url)
  fullName: Observable<ServiceResponseWithHeaders<Void, RecognizeTextHeadersInner>> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.recognizeTextWithServiceResponseAsync(String url)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizeTextWithServiceResponseAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 1227
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>Recognize Text operation. When you use the Recognize Text interface, the response contains a field called “Operation-Location”. The “Operation-Location” field contains the URL that you must use for your Get Handwritten Text Operation Result operation.</p>

    <p></p>
  syntax:
    content: public Observable<ServiceResponseWithHeaders<Void, RecognizeTextHeadersInner>> recognizeTextWithServiceResponseAsync(String url)
    parameters:
    - id: url
      type: "26831127"
      description: <p>the String value </p>
    return:
      type: 6738ce59com.microsoft.azure.cognitiveservices.computervision.implementation._recognize_text_headers_innere7daa122
      description: <p>the <xref uid="" data-throw-if-not-resolved="false">ServiceResponseWithHeaders</xref> object if successful. </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizeTextWithServiceResponseAsync(String,Boolean)
  id: recognizeTextWithServiceResponseAsync(String,Boolean)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: recognizeTextWithServiceResponseAsync(String url, Boolean detectHandwriting)
  nameWithType: ComputerVisionAPIImpl.recognizeTextWithServiceResponseAsync(String url, Boolean detectHandwriting)
  fullName: Observable<ServiceResponseWithHeaders<Void, RecognizeTextHeadersInner>> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.recognizeTextWithServiceResponseAsync(String url, Boolean detectHandwriting)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizeTextWithServiceResponseAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 1303
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>Recognize Text operation. When you use the Recognize Text interface, the response contains a field called “Operation-Location”. The “Operation-Location” field contains the URL that you must use for your Get Handwritten Text Operation Result operation.</p>

    <p></p>
  syntax:
    content: public Observable<ServiceResponseWithHeaders<Void, RecognizeTextHeadersInner>> recognizeTextWithServiceResponseAsync(String url, Boolean detectHandwriting)
    parameters:
    - id: url
      type: "26831127"
      description: <p>the String value </p>
    - id: detectHandwriting
      type: 866c2227
      description: <p>If “true” is specified, handwriting recognition is performed. If this parameter is set to “false” or is not specified, printed text recognition is performed. </p>
    return:
      type: 6738ce59com.microsoft.azure.cognitiveservices.computervision.implementation._recognize_text_headers_innere7daa122
      description: <p>the <xref uid="" data-throw-if-not-resolved="false">ServiceResponseWithHeaders</xref> object if successful. </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.tagImage(String)
  id: tagImage(String)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: tagImage(String url)
  nameWithType: ComputerVisionAPIImpl.tagImage(String url)
  fullName: TagResultInner com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.tagImage(String url)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.tagImage*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 1024
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>This operation generates a list of words, or tags, that are relevant to the content of the supplied image. The Computer Vision API can return tags based on objects, living beings, scenery or actions found in images. Unlike categories, tags are not organized according to a hierarchical classification system, but correspond to image content. Tags may contain hints to avoid ambiguity or provide context, for example the tag “cello” may be accompanied by the hint “musical instrument”. All tags are in English.</p>

    <p></p>
  syntax:
    content: public TagResultInner tagImage(String url)
    parameters:
    - id: url
      type: "26831127"
      description: <p>the String value </p>
    return:
      type: com.microsoft.azure.cognitiveservices.computervision.implementation._tag_result_inner
      description: <p>the <xref uid="com.microsoft.azure.cognitiveservices.computervision.implementation._tag_result_inner" data-throw-if-not-resolved="false">TagResultInner</xref> object if successful. </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
  - type: com.microsoft.azure.cognitiveservices.computervision._computer_vision_error_exception
    description: <p>thrown if the request is rejected by server </p>
  - type: 9b2a4515
    description: <p>all other wrapped checked exceptions if the request fails to be sent </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.tagImageAsync(String)
  id: tagImageAsync(String)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: tagImageAsync(String url)
  nameWithType: ComputerVisionAPIImpl.tagImageAsync(String url)
  fullName: Observable<TagResultInner> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.tagImageAsync(String url)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.tagImageAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 1047
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>This operation generates a list of words, or tags, that are relevant to the content of the supplied image. The Computer Vision API can return tags based on objects, living beings, scenery or actions found in images. Unlike categories, tags are not organized according to a hierarchical classification system, but correspond to image content. Tags may contain hints to avoid ambiguity or provide context, for example the tag “cello” may be accompanied by the hint “musical instrument”. All tags are in English.</p>

    <p></p>
  syntax:
    content: public Observable<TagResultInner> tagImageAsync(String url)
    parameters:
    - id: url
      type: "26831127"
      description: <p>the String value </p>
    return:
      type: c2d0e8c6com.microsoft.azure.cognitiveservices.computervision.implementation._tag_result_innera08ddfce
      description: <p>the observable to the <xref uid="com.microsoft.azure.cognitiveservices.computervision.implementation._tag_result_inner" data-throw-if-not-resolved="false">TagResultInner</xref> object </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.tagImageAsync(String,final ServiceCallback<TagResultInner>)
  id: tagImageAsync(String,final ServiceCallback<TagResultInner>)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: tagImageAsync(String url, final ServiceCallback<TagResultInner> serviceCallback)
  nameWithType: ComputerVisionAPIImpl.tagImageAsync(String url, final ServiceCallback<TagResultInner> serviceCallback)
  fullName: ServiceFuture<TagResultInner> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.tagImageAsync(String url, final ServiceCallback<TagResultInner> serviceCallback)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.tagImageAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 1036
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>This operation generates a list of words, or tags, that are relevant to the content of the supplied image. The Computer Vision API can return tags based on objects, living beings, scenery or actions found in images. Unlike categories, tags are not organized according to a hierarchical classification system, but correspond to image content. Tags may contain hints to avoid ambiguity or provide context, for example the tag “cello” may be accompanied by the hint “musical instrument”. All tags are in English.</p>

    <p></p>
  syntax:
    content: public ServiceFuture<TagResultInner> tagImageAsync(String url, final ServiceCallback<TagResultInner> serviceCallback)
    parameters:
    - id: url
      type: "26831127"
      description: <p>the String value </p>
    - id: serviceCallback
      type: 897eb10acom.microsoft.azure.cognitiveservices.computervision.implementation._tag_result_innera08ddfce
      description: <p>the async ServiceCallback to handle successful and failed responses. </p>
    return:
      type: c522ce07com.microsoft.azure.cognitiveservices.computervision.implementation._tag_result_innera08ddfce
      description: <p>the <xref uid="" data-throw-if-not-resolved="false">ServiceFuture</xref> object </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.tagImageInStream(byte [])
  id: tagImageInStream(byte [])
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: tagImageInStream(byte[] image)
  nameWithType: ComputerVisionAPIImpl.tagImageInStream(byte[] image)
  fullName: TagResultInner com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.tagImageInStream(byte[] image)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.tagImageInStream*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 2073
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>This operation generates a list of words, or tags, that are relevant to the content of the supplied image. The Computer Vision API can return tags based on objects, living beings, scenery or actions found in images. Unlike categories, tags are not organized according to a hierarchical classification system, but correspond to image content. Tags may contain hints to avoid ambiguity or provide context, for example the tag “cello” may be accompanied by the hint “musical instrument”. All tags are in English.</p>

    <p></p>
  syntax:
    content: public TagResultInner tagImageInStream(byte[] image)
    parameters:
    - id: image
      type: ccd9418d
      description: <p>An image stream. </p>
    return:
      type: com.microsoft.azure.cognitiveservices.computervision.implementation._tag_result_inner
      description: <p>the <xref uid="com.microsoft.azure.cognitiveservices.computervision.implementation._tag_result_inner" data-throw-if-not-resolved="false">TagResultInner</xref> object if successful. </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
  - type: com.microsoft.azure.cognitiveservices.computervision._computer_vision_error_exception
    description: <p>thrown if the request is rejected by server </p>
  - type: 9b2a4515
    description: <p>all other wrapped checked exceptions if the request fails to be sent </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.tagImageInStreamAsync(byte [])
  id: tagImageInStreamAsync(byte [])
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: tagImageInStreamAsync(byte[] image)
  nameWithType: ComputerVisionAPIImpl.tagImageInStreamAsync(byte[] image)
  fullName: Observable<TagResultInner> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.tagImageInStreamAsync(byte[] image)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.tagImageInStreamAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 2096
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>This operation generates a list of words, or tags, that are relevant to the content of the supplied image. The Computer Vision API can return tags based on objects, living beings, scenery or actions found in images. Unlike categories, tags are not organized according to a hierarchical classification system, but correspond to image content. Tags may contain hints to avoid ambiguity or provide context, for example the tag “cello” may be accompanied by the hint “musical instrument”. All tags are in English.</p>

    <p></p>
  syntax:
    content: public Observable<TagResultInner> tagImageInStreamAsync(byte[] image)
    parameters:
    - id: image
      type: ccd9418d
      description: <p>An image stream. </p>
    return:
      type: c2d0e8c6com.microsoft.azure.cognitiveservices.computervision.implementation._tag_result_innera08ddfce
      description: <p>the observable to the <xref uid="com.microsoft.azure.cognitiveservices.computervision.implementation._tag_result_inner" data-throw-if-not-resolved="false">TagResultInner</xref> object </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.tagImageInStreamAsync(byte [],final ServiceCallback<TagResultInner>)
  id: tagImageInStreamAsync(byte [],final ServiceCallback<TagResultInner>)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: tagImageInStreamAsync(byte[] image, final ServiceCallback<TagResultInner> serviceCallback)
  nameWithType: ComputerVisionAPIImpl.tagImageInStreamAsync(byte[] image, final ServiceCallback<TagResultInner> serviceCallback)
  fullName: ServiceFuture<TagResultInner> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.tagImageInStreamAsync(byte[] image, final ServiceCallback<TagResultInner> serviceCallback)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.tagImageInStreamAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 2085
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>This operation generates a list of words, or tags, that are relevant to the content of the supplied image. The Computer Vision API can return tags based on objects, living beings, scenery or actions found in images. Unlike categories, tags are not organized according to a hierarchical classification system, but correspond to image content. Tags may contain hints to avoid ambiguity or provide context, for example the tag “cello” may be accompanied by the hint “musical instrument”. All tags are in English.</p>

    <p></p>
  syntax:
    content: public ServiceFuture<TagResultInner> tagImageInStreamAsync(byte[] image, final ServiceCallback<TagResultInner> serviceCallback)
    parameters:
    - id: image
      type: ccd9418d
      description: <p>An image stream. </p>
    - id: serviceCallback
      type: 897eb10acom.microsoft.azure.cognitiveservices.computervision.implementation._tag_result_innera08ddfce
      description: <p>the async ServiceCallback to handle successful and failed responses. </p>
    return:
      type: c522ce07com.microsoft.azure.cognitiveservices.computervision.implementation._tag_result_innera08ddfce
      description: <p>the <xref uid="" data-throw-if-not-resolved="false">ServiceFuture</xref> object </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.tagImageInStreamWithServiceResponseAsync(byte [])
  id: tagImageInStreamWithServiceResponseAsync(byte [])
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: tagImageInStreamWithServiceResponseAsync(byte[] image)
  nameWithType: ComputerVisionAPIImpl.tagImageInStreamWithServiceResponseAsync(byte[] image)
  fullName: Observable<ServiceResponse<TagResultInner>> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.tagImageInStreamWithServiceResponseAsync(byte[] image)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.tagImageInStreamWithServiceResponseAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 2112
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>This operation generates a list of words, or tags, that are relevant to the content of the supplied image. The Computer Vision API can return tags based on objects, living beings, scenery or actions found in images. Unlike categories, tags are not organized according to a hierarchical classification system, but correspond to image content. Tags may contain hints to avoid ambiguity or provide context, for example the tag “cello” may be accompanied by the hint “musical instrument”. All tags are in English.</p>

    <p></p>
  syntax:
    content: public Observable<ServiceResponse<TagResultInner>> tagImageInStreamWithServiceResponseAsync(byte[] image)
    parameters:
    - id: image
      type: ccd9418d
      description: <p>An image stream. </p>
    return:
      type: fc480ba2com.microsoft.azure.cognitiveservices.computervision.implementation._tag_result_innere7daa122
      description: <p>the observable to the <xref uid="com.microsoft.azure.cognitiveservices.computervision.implementation._tag_result_inner" data-throw-if-not-resolved="false">TagResultInner</xref> object </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.tagImageWithServiceResponseAsync(String)
  id: tagImageWithServiceResponseAsync(String)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: tagImageWithServiceResponseAsync(String url)
  nameWithType: ComputerVisionAPIImpl.tagImageWithServiceResponseAsync(String url)
  fullName: Observable<ServiceResponse<TagResultInner>> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.tagImageWithServiceResponseAsync(String url)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.tagImageWithServiceResponseAsync*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 1063
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>This operation generates a list of words, or tags, that are relevant to the content of the supplied image. The Computer Vision API can return tags based on objects, living beings, scenery or actions found in images. Unlike categories, tags are not organized according to a hierarchical classification system, but correspond to image content. Tags may contain hints to avoid ambiguity or provide context, for example the tag “cello” may be accompanied by the hint “musical instrument”. All tags are in English.</p>

    <p></p>
  syntax:
    content: public Observable<ServiceResponse<TagResultInner>> tagImageWithServiceResponseAsync(String url)
    parameters:
    - id: url
      type: "26831127"
      description: <p>the String value </p>
    return:
      type: fc480ba2com.microsoft.azure.cognitiveservices.computervision.implementation._tag_result_innere7daa122
      description: <p>the observable to the <xref uid="com.microsoft.azure.cognitiveservices.computervision.implementation._tag_result_inner" data-throw-if-not-resolved="false">TagResultInner</xref> object </p>
  exceptions:
  - type: 3c87bd19
    description: <p>thrown if parameters fail the validation </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.userAgent()
  id: userAgent()
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: userAgent()
  nameWithType: ComputerVisionAPIImpl.userAgent()
  fullName: String com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.userAgent()
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.userAgent*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 200
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>Gets the User-Agent header for the client.</p>

    <p></p>
  syntax:
    content: public String userAgent()
    return:
      type: "26831127"
      description: <p>the user agent string. </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.withAcceptLanguage(String)
  id: withAcceptLanguage(String)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: withAcceptLanguage(String acceptLanguage)
  nameWithType: ComputerVisionAPIImpl.withAcceptLanguage(String acceptLanguage)
  fullName: ComputerVisionAPIImpl com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.withAcceptLanguage(String acceptLanguage)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.withAcceptLanguage*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 105
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>Sets Gets or sets the preferred language for the response.</p>

    <p></p>
  syntax:
    content: public ComputerVisionAPIImpl withAcceptLanguage(String acceptLanguage)
    parameters:
    - id: acceptLanguage
      type: "26831127"
      description: <p>the acceptLanguage value. </p>
    return:
      type: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
      description: <p>the service client itself </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.withAzureRegion(AzureRegions)
  id: withAzureRegion(AzureRegions)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: withAzureRegion(AzureRegions azureRegion)
  nameWithType: ComputerVisionAPIImpl.withAzureRegion(AzureRegions azureRegion)
  fullName: ComputerVisionAPIImpl com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.withAzureRegion(AzureRegions azureRegion)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.withAzureRegion*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 82
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>Sets Supported Azure regions for Cognitive Services endpoints. Possible values include: 'westus', 'westeurope', 'southeastasia', 'eastus2', 'westcentralus', 'westus2', 'eastus', 'southcentralus', 'northeurope', 'eastasia', 'australiaeast', 'brazilsouth'.</p>

    <p></p>
  syntax:
    content: public ComputerVisionAPIImpl withAzureRegion(AzureRegions azureRegion)
    parameters:
    - id: azureRegion
      type: com.microsoft.azure.cognitiveservices.computervision._azure_regions
      description: <p>the azureRegion value. </p>
    return:
      type: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
      description: <p>the service client itself </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.withGenerateClientRequestId(boolean)
  id: withGenerateClientRequestId(boolean)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: withGenerateClientRequestId(boolean generateClientRequestId)
  nameWithType: ComputerVisionAPIImpl.withGenerateClientRequestId(boolean generateClientRequestId)
  fullName: ComputerVisionAPIImpl com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.withGenerateClientRequestId(boolean generateClientRequestId)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.withGenerateClientRequestId*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 151
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>Sets When set to true a unique x-ms-client-request-id value is generated and included in each request. Default is true.</p>

    <p></p>
  syntax:
    content: public ComputerVisionAPIImpl withGenerateClientRequestId(boolean generateClientRequestId)
    parameters:
    - id: generateClientRequestId
      type: 4fc6e284
      description: <p>the generateClientRequestId value. </p>
    return:
      type: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
      description: <p>the service client itself </p>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.withLongRunningOperationRetryTimeout(int)
  id: withLongRunningOperationRetryTimeout(int)
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  langs:
  - java
  name: withLongRunningOperationRetryTimeout(int longRunningOperationRetryTimeout)
  nameWithType: ComputerVisionAPIImpl.withLongRunningOperationRetryTimeout(int longRunningOperationRetryTimeout)
  fullName: ComputerVisionAPIImpl com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.withLongRunningOperationRetryTimeout(int longRunningOperationRetryTimeout)
  overload: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.withLongRunningOperationRetryTimeout*
  type: Method
  source:
    remote: *o0
    path: cognitiveservices/azure-computervision/src/main/java/com/microsoft/azure/cognitiveservices/computervision/implementation/ComputerVisionAPIImpl.java
    startLine: 128
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
  summary: >-
    <p>Sets Gets or sets the retry timeout in seconds for Long Running Operations. Default value is 30.</p>

    <p></p>
  syntax:
    content: public ComputerVisionAPIImpl withLongRunningOperationRetryTimeout(int longRunningOperationRetryTimeout)
    parameters:
    - id: longRunningOperationRetryTimeout
      type: f75371fa
      description: <p>the longRunningOperationRetryTimeout value. </p>
    return:
      type: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
      description: <p>the service client itself </p>
references:
- uid: c1c26e8d
  spec.java:
  - name: AzureClient
    fullName: AzureClient
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.getAzureClient*
  name: getAzureClient
  nameWithType: ComputerVisionAPIImpl.getAzureClient
  fullName: AzureClient com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.getAzureClient
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.azureRegion*
  name: azureRegion
  nameWithType: ComputerVisionAPIImpl.azureRegion
  fullName: AzureRegions com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.azureRegion
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.withAzureRegion*
  name: withAzureRegion
  nameWithType: ComputerVisionAPIImpl.withAzureRegion
  fullName: ComputerVisionAPIImpl com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.withAzureRegion
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
- uid: "26831127"
  spec.java:
  - name: String
    fullName: String
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.acceptLanguage*
  name: acceptLanguage
  nameWithType: ComputerVisionAPIImpl.acceptLanguage
  fullName: String com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.acceptLanguage
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.withAcceptLanguage*
  name: withAcceptLanguage
  nameWithType: ComputerVisionAPIImpl.withAcceptLanguage
  fullName: ComputerVisionAPIImpl com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.withAcceptLanguage
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
- uid: f75371fa
  spec.java:
  - name: int
    fullName: int
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.longRunningOperationRetryTimeout*
  name: longRunningOperationRetryTimeout
  nameWithType: ComputerVisionAPIImpl.longRunningOperationRetryTimeout
  fullName: int com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.longRunningOperationRetryTimeout
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.withLongRunningOperationRetryTimeout*
  name: withLongRunningOperationRetryTimeout
  nameWithType: ComputerVisionAPIImpl.withLongRunningOperationRetryTimeout
  fullName: ComputerVisionAPIImpl com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.withLongRunningOperationRetryTimeout
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
- uid: 4fc6e284
  spec.java:
  - name: boolean
    fullName: boolean
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.generateClientRequestId*
  name: generateClientRequestId
  nameWithType: ComputerVisionAPIImpl.generateClientRequestId
  fullName: boolean com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.generateClientRequestId
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.withGenerateClientRequestId*
  name: withGenerateClientRequestId
  nameWithType: ComputerVisionAPIImpl.withGenerateClientRequestId
  fullName: ComputerVisionAPIImpl com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.withGenerateClientRequestId
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
- uid: d7990412
  spec.java:
  - name: ServiceClientCredentials
    fullName: ServiceClientCredentials
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.ComputerVisionAPIImpl*
  name: ComputerVisionAPIImpl
  nameWithType: ComputerVisionAPIImpl.ComputerVisionAPIImpl
  fullName: com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.ComputerVisionAPIImpl
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
- uid: 9545a295
  spec.java:
  - name: RestClient
    fullName: RestClient
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.userAgent*
  name: userAgent
  nameWithType: ComputerVisionAPIImpl.userAgent
  fullName: String com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.userAgent
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
- uid: 3c87bd19
  spec.java:
  - name: IllegalArgumentException
    fullName: IllegalArgumentException
- uid: 9b2a4515
  spec.java:
  - name: RuntimeException
    fullName: RuntimeException
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.listModels*
  name: listModels
  nameWithType: ComputerVisionAPIImpl.listModels
  fullName: ListModelsResultInner com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.listModels
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
- uid: 897eb10acom.microsoft.azure.cognitiveservices.computervision.implementation._list_models_result_innera08ddfce
  spec.java:
  - name: final ServiceCallback<
    fullName: final ServiceCallback<
  - uid: com.microsoft.azure.cognitiveservices.computervision.implementation._list_models_result_inner
    name: ListModelsResultInner
    fullName: com.microsoft.azure.cognitiveservices.computervision.implementation.ListModelsResultInner
    href: com.microsoft.azure.cognitiveservices.computervision.implementation._list_models_result_inner.yml
  - name: '>'
    fullName: '>'
- uid: c522ce07com.microsoft.azure.cognitiveservices.computervision.implementation._list_models_result_innera08ddfce
  spec.java:
  - name: ServiceFuture<
    fullName: ServiceFuture<
  - uid: com.microsoft.azure.cognitiveservices.computervision.implementation._list_models_result_inner
    name: ListModelsResultInner
    fullName: com.microsoft.azure.cognitiveservices.computervision.implementation.ListModelsResultInner
    href: com.microsoft.azure.cognitiveservices.computervision.implementation._list_models_result_inner.yml
  - name: '>'
    fullName: '>'
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.listModelsAsync*
  name: listModelsAsync
  nameWithType: ComputerVisionAPIImpl.listModelsAsync
  fullName: ServiceFuture<ListModelsResultInner> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.listModelsAsync
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
- uid: c2d0e8c6com.microsoft.azure.cognitiveservices.computervision.implementation._list_models_result_innera08ddfce
  spec.java:
  - name: Observable<
    fullName: Observable<
  - uid: com.microsoft.azure.cognitiveservices.computervision.implementation._list_models_result_inner
    name: ListModelsResultInner
    fullName: com.microsoft.azure.cognitiveservices.computervision.implementation.ListModelsResultInner
    href: com.microsoft.azure.cognitiveservices.computervision.implementation._list_models_result_inner.yml
  - name: '>'
    fullName: '>'
- uid: fc480ba2com.microsoft.azure.cognitiveservices.computervision.implementation._list_models_result_innere7daa122
  spec.java:
  - name: Observable<ServiceResponse<
    fullName: Observable<ServiceResponse<
  - uid: com.microsoft.azure.cognitiveservices.computervision.implementation._list_models_result_inner
    name: ListModelsResultInner
    fullName: com.microsoft.azure.cognitiveservices.computervision.implementation.ListModelsResultInner
    href: com.microsoft.azure.cognitiveservices.computervision.implementation._list_models_result_inner.yml
  - name: '>>'
    fullName: '>>'
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.listModelsWithServiceResponseAsync*
  name: listModelsWithServiceResponseAsync
  nameWithType: ComputerVisionAPIImpl.listModelsWithServiceResponseAsync
  fullName: Observable<ServiceResponse<ListModelsResultInner>> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.listModelsWithServiceResponseAsync
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImage*
  name: analyzeImage
  nameWithType: ComputerVisionAPIImpl.analyzeImage
  fullName: ImageAnalysisInner com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.analyzeImage
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
- uid: 897eb10acom.microsoft.azure.cognitiveservices.computervision.implementation._image_analysis_innera08ddfce
  spec.java:
  - name: final ServiceCallback<
    fullName: final ServiceCallback<
  - uid: com.microsoft.azure.cognitiveservices.computervision.implementation._image_analysis_inner
    name: ImageAnalysisInner
    fullName: com.microsoft.azure.cognitiveservices.computervision.implementation.ImageAnalysisInner
    href: com.microsoft.azure.cognitiveservices.computervision.implementation._image_analysis_inner.yml
  - name: '>'
    fullName: '>'
- uid: c522ce07com.microsoft.azure.cognitiveservices.computervision.implementation._image_analysis_innera08ddfce
  spec.java:
  - name: ServiceFuture<
    fullName: ServiceFuture<
  - uid: com.microsoft.azure.cognitiveservices.computervision.implementation._image_analysis_inner
    name: ImageAnalysisInner
    fullName: com.microsoft.azure.cognitiveservices.computervision.implementation.ImageAnalysisInner
    href: com.microsoft.azure.cognitiveservices.computervision.implementation._image_analysis_inner.yml
  - name: '>'
    fullName: '>'
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageAsync*
  name: analyzeImageAsync
  nameWithType: ComputerVisionAPIImpl.analyzeImageAsync
  fullName: ServiceFuture<ImageAnalysisInner> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.analyzeImageAsync
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
- uid: c2d0e8c6com.microsoft.azure.cognitiveservices.computervision.implementation._image_analysis_innera08ddfce
  spec.java:
  - name: Observable<
    fullName: Observable<
  - uid: com.microsoft.azure.cognitiveservices.computervision.implementation._image_analysis_inner
    name: ImageAnalysisInner
    fullName: com.microsoft.azure.cognitiveservices.computervision.implementation.ImageAnalysisInner
    href: com.microsoft.azure.cognitiveservices.computervision.implementation._image_analysis_inner.yml
  - name: '>'
    fullName: '>'
- uid: fc480ba2com.microsoft.azure.cognitiveservices.computervision.implementation._image_analysis_innere7daa122
  spec.java:
  - name: Observable<ServiceResponse<
    fullName: Observable<ServiceResponse<
  - uid: com.microsoft.azure.cognitiveservices.computervision.implementation._image_analysis_inner
    name: ImageAnalysisInner
    fullName: com.microsoft.azure.cognitiveservices.computervision.implementation.ImageAnalysisInner
    href: com.microsoft.azure.cognitiveservices.computervision.implementation._image_analysis_inner.yml
  - name: '>>'
    fullName: '>>'
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageWithServiceResponseAsync*
  name: analyzeImageWithServiceResponseAsync
  nameWithType: ComputerVisionAPIImpl.analyzeImageWithServiceResponseAsync
  fullName: Observable<ServiceResponse<ImageAnalysisInner>> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.analyzeImageWithServiceResponseAsync
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
- uid: 5618da2dcom.microsoft.azure.cognitiveservices.computervision._visual_feature_typesa08ddfce
  spec.java:
  - name: List<
    fullName: List<
  - uid: com.microsoft.azure.cognitiveservices.computervision._visual_feature_types
    name: VisualFeatureTypes
    fullName: com.microsoft.azure.cognitiveservices.computervision.VisualFeatureTypes
    href: com.microsoft.azure.cognitiveservices.computervision._visual_feature_types.yml
  - name: '>'
    fullName: '>'
- uid: 5618da2dcom.microsoft.azure.cognitiveservices.computervision._detailsa08ddfce
  spec.java:
  - name: List<
    fullName: List<
  - uid: com.microsoft.azure.cognitiveservices.computervision._details
    name: Details
    fullName: com.microsoft.azure.cognitiveservices.computervision.Details
    href: com.microsoft.azure.cognitiveservices.computervision._details.yml
  - name: '>'
    fullName: '>'
- uid: dc385fd4
  spec.java:
  - name: CloudException
    fullName: CloudException
- uid: 76fcb9b7
  spec.java:
  - name: InputStream
    fullName: InputStream
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.generateThumbnail*
  name: generateThumbnail
  nameWithType: ComputerVisionAPIImpl.generateThumbnail
  fullName: InputStream com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.generateThumbnail
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
- uid: 0377aee2
  spec.java:
  - name: final ServiceCallback<InputStream>
    fullName: final ServiceCallback<InputStream>
- uid: 8601070c
  spec.java:
  - name: ServiceFuture<InputStream>
    fullName: ServiceFuture<InputStream>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.generateThumbnailAsync*
  name: generateThumbnailAsync
  nameWithType: ComputerVisionAPIImpl.generateThumbnailAsync
  fullName: ServiceFuture<InputStream> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.generateThumbnailAsync
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
- uid: 3ab19265
  spec.java:
  - name: Observable<InputStream>
    fullName: Observable<InputStream>
- uid: b4669ca9
  spec.java:
  - name: Observable<ServiceResponse<InputStream>>
    fullName: Observable<ServiceResponse<InputStream>>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.generateThumbnailWithServiceResponseAsync*
  name: generateThumbnailWithServiceResponseAsync
  nameWithType: ComputerVisionAPIImpl.generateThumbnailWithServiceResponseAsync
  fullName: Observable<ServiceResponse<InputStream>> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.generateThumbnailWithServiceResponseAsync
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
- uid: 866c2227
  spec.java:
  - name: Boolean
    fullName: Boolean
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizePrintedText*
  name: recognizePrintedText
  nameWithType: ComputerVisionAPIImpl.recognizePrintedText
  fullName: OcrResultInner com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.recognizePrintedText
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
- uid: 897eb10acom.microsoft.azure.cognitiveservices.computervision.implementation._ocr_result_innera08ddfce
  spec.java:
  - name: final ServiceCallback<
    fullName: final ServiceCallback<
  - uid: com.microsoft.azure.cognitiveservices.computervision.implementation._ocr_result_inner
    name: OcrResultInner
    fullName: com.microsoft.azure.cognitiveservices.computervision.implementation.OcrResultInner
    href: com.microsoft.azure.cognitiveservices.computervision.implementation._ocr_result_inner.yml
  - name: '>'
    fullName: '>'
- uid: c522ce07com.microsoft.azure.cognitiveservices.computervision.implementation._ocr_result_innera08ddfce
  spec.java:
  - name: ServiceFuture<
    fullName: ServiceFuture<
  - uid: com.microsoft.azure.cognitiveservices.computervision.implementation._ocr_result_inner
    name: OcrResultInner
    fullName: com.microsoft.azure.cognitiveservices.computervision.implementation.OcrResultInner
    href: com.microsoft.azure.cognitiveservices.computervision.implementation._ocr_result_inner.yml
  - name: '>'
    fullName: '>'
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizePrintedTextAsync*
  name: recognizePrintedTextAsync
  nameWithType: ComputerVisionAPIImpl.recognizePrintedTextAsync
  fullName: ServiceFuture<OcrResultInner> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.recognizePrintedTextAsync
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
- uid: c2d0e8c6com.microsoft.azure.cognitiveservices.computervision.implementation._ocr_result_innera08ddfce
  spec.java:
  - name: Observable<
    fullName: Observable<
  - uid: com.microsoft.azure.cognitiveservices.computervision.implementation._ocr_result_inner
    name: OcrResultInner
    fullName: com.microsoft.azure.cognitiveservices.computervision.implementation.OcrResultInner
    href: com.microsoft.azure.cognitiveservices.computervision.implementation._ocr_result_inner.yml
  - name: '>'
    fullName: '>'
- uid: fc480ba2com.microsoft.azure.cognitiveservices.computervision.implementation._ocr_result_innere7daa122
  spec.java:
  - name: Observable<ServiceResponse<
    fullName: Observable<ServiceResponse<
  - uid: com.microsoft.azure.cognitiveservices.computervision.implementation._ocr_result_inner
    name: OcrResultInner
    fullName: com.microsoft.azure.cognitiveservices.computervision.implementation.OcrResultInner
    href: com.microsoft.azure.cognitiveservices.computervision.implementation._ocr_result_inner.yml
  - name: '>>'
    fullName: '>>'
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizePrintedTextWithServiceResponseAsync*
  name: recognizePrintedTextWithServiceResponseAsync
  nameWithType: ComputerVisionAPIImpl.recognizePrintedTextWithServiceResponseAsync
  fullName: Observable<ServiceResponse<OcrResultInner>> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.recognizePrintedTextWithServiceResponseAsync
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.describeImage*
  name: describeImage
  nameWithType: ComputerVisionAPIImpl.describeImage
  fullName: ImageDescriptionInner com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.describeImage
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
- uid: 897eb10acom.microsoft.azure.cognitiveservices.computervision.implementation._image_description_innera08ddfce
  spec.java:
  - name: final ServiceCallback<
    fullName: final ServiceCallback<
  - uid: com.microsoft.azure.cognitiveservices.computervision.implementation._image_description_inner
    name: ImageDescriptionInner
    fullName: com.microsoft.azure.cognitiveservices.computervision.implementation.ImageDescriptionInner
    href: com.microsoft.azure.cognitiveservices.computervision.implementation._image_description_inner.yml
  - name: '>'
    fullName: '>'
- uid: c522ce07com.microsoft.azure.cognitiveservices.computervision.implementation._image_description_innera08ddfce
  spec.java:
  - name: ServiceFuture<
    fullName: ServiceFuture<
  - uid: com.microsoft.azure.cognitiveservices.computervision.implementation._image_description_inner
    name: ImageDescriptionInner
    fullName: com.microsoft.azure.cognitiveservices.computervision.implementation.ImageDescriptionInner
    href: com.microsoft.azure.cognitiveservices.computervision.implementation._image_description_inner.yml
  - name: '>'
    fullName: '>'
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.describeImageAsync*
  name: describeImageAsync
  nameWithType: ComputerVisionAPIImpl.describeImageAsync
  fullName: ServiceFuture<ImageDescriptionInner> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.describeImageAsync
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
- uid: c2d0e8c6com.microsoft.azure.cognitiveservices.computervision.implementation._image_description_innera08ddfce
  spec.java:
  - name: Observable<
    fullName: Observable<
  - uid: com.microsoft.azure.cognitiveservices.computervision.implementation._image_description_inner
    name: ImageDescriptionInner
    fullName: com.microsoft.azure.cognitiveservices.computervision.implementation.ImageDescriptionInner
    href: com.microsoft.azure.cognitiveservices.computervision.implementation._image_description_inner.yml
  - name: '>'
    fullName: '>'
- uid: fc480ba2com.microsoft.azure.cognitiveservices.computervision.implementation._image_description_innere7daa122
  spec.java:
  - name: Observable<ServiceResponse<
    fullName: Observable<ServiceResponse<
  - uid: com.microsoft.azure.cognitiveservices.computervision.implementation._image_description_inner
    name: ImageDescriptionInner
    fullName: com.microsoft.azure.cognitiveservices.computervision.implementation.ImageDescriptionInner
    href: com.microsoft.azure.cognitiveservices.computervision.implementation._image_description_inner.yml
  - name: '>>'
    fullName: '>>'
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.describeImageWithServiceResponseAsync*
  name: describeImageWithServiceResponseAsync
  nameWithType: ComputerVisionAPIImpl.describeImageWithServiceResponseAsync
  fullName: Observable<ServiceResponse<ImageDescriptionInner>> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.describeImageWithServiceResponseAsync
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.tagImage*
  name: tagImage
  nameWithType: ComputerVisionAPIImpl.tagImage
  fullName: TagResultInner com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.tagImage
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
- uid: 897eb10acom.microsoft.azure.cognitiveservices.computervision.implementation._tag_result_innera08ddfce
  spec.java:
  - name: final ServiceCallback<
    fullName: final ServiceCallback<
  - uid: com.microsoft.azure.cognitiveservices.computervision.implementation._tag_result_inner
    name: TagResultInner
    fullName: com.microsoft.azure.cognitiveservices.computervision.implementation.TagResultInner
    href: com.microsoft.azure.cognitiveservices.computervision.implementation._tag_result_inner.yml
  - name: '>'
    fullName: '>'
- uid: c522ce07com.microsoft.azure.cognitiveservices.computervision.implementation._tag_result_innera08ddfce
  spec.java:
  - name: ServiceFuture<
    fullName: ServiceFuture<
  - uid: com.microsoft.azure.cognitiveservices.computervision.implementation._tag_result_inner
    name: TagResultInner
    fullName: com.microsoft.azure.cognitiveservices.computervision.implementation.TagResultInner
    href: com.microsoft.azure.cognitiveservices.computervision.implementation._tag_result_inner.yml
  - name: '>'
    fullName: '>'
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.tagImageAsync*
  name: tagImageAsync
  nameWithType: ComputerVisionAPIImpl.tagImageAsync
  fullName: ServiceFuture<TagResultInner> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.tagImageAsync
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
- uid: c2d0e8c6com.microsoft.azure.cognitiveservices.computervision.implementation._tag_result_innera08ddfce
  spec.java:
  - name: Observable<
    fullName: Observable<
  - uid: com.microsoft.azure.cognitiveservices.computervision.implementation._tag_result_inner
    name: TagResultInner
    fullName: com.microsoft.azure.cognitiveservices.computervision.implementation.TagResultInner
    href: com.microsoft.azure.cognitiveservices.computervision.implementation._tag_result_inner.yml
  - name: '>'
    fullName: '>'
- uid: fc480ba2com.microsoft.azure.cognitiveservices.computervision.implementation._tag_result_innere7daa122
  spec.java:
  - name: Observable<ServiceResponse<
    fullName: Observable<ServiceResponse<
  - uid: com.microsoft.azure.cognitiveservices.computervision.implementation._tag_result_inner
    name: TagResultInner
    fullName: com.microsoft.azure.cognitiveservices.computervision.implementation.TagResultInner
    href: com.microsoft.azure.cognitiveservices.computervision.implementation._tag_result_inner.yml
  - name: '>>'
    fullName: '>>'
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.tagImageWithServiceResponseAsync*
  name: tagImageWithServiceResponseAsync
  nameWithType: ComputerVisionAPIImpl.tagImageWithServiceResponseAsync
  fullName: Observable<ServiceResponse<TagResultInner>> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.tagImageWithServiceResponseAsync
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageByDomain*
  name: analyzeImageByDomain
  nameWithType: ComputerVisionAPIImpl.analyzeImageByDomain
  fullName: DomainModelResultsInner com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.analyzeImageByDomain
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
- uid: 897eb10acom.microsoft.azure.cognitiveservices.computervision.implementation._domain_model_results_innera08ddfce
  spec.java:
  - name: final ServiceCallback<
    fullName: final ServiceCallback<
  - uid: com.microsoft.azure.cognitiveservices.computervision.implementation._domain_model_results_inner
    name: DomainModelResultsInner
    fullName: com.microsoft.azure.cognitiveservices.computervision.implementation.DomainModelResultsInner
    href: com.microsoft.azure.cognitiveservices.computervision.implementation._domain_model_results_inner.yml
  - name: '>'
    fullName: '>'
- uid: c522ce07com.microsoft.azure.cognitiveservices.computervision.implementation._domain_model_results_innera08ddfce
  spec.java:
  - name: ServiceFuture<
    fullName: ServiceFuture<
  - uid: com.microsoft.azure.cognitiveservices.computervision.implementation._domain_model_results_inner
    name: DomainModelResultsInner
    fullName: com.microsoft.azure.cognitiveservices.computervision.implementation.DomainModelResultsInner
    href: com.microsoft.azure.cognitiveservices.computervision.implementation._domain_model_results_inner.yml
  - name: '>'
    fullName: '>'
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageByDomainAsync*
  name: analyzeImageByDomainAsync
  nameWithType: ComputerVisionAPIImpl.analyzeImageByDomainAsync
  fullName: ServiceFuture<DomainModelResultsInner> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.analyzeImageByDomainAsync
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
- uid: c2d0e8c6com.microsoft.azure.cognitiveservices.computervision.implementation._domain_model_results_innera08ddfce
  spec.java:
  - name: Observable<
    fullName: Observable<
  - uid: com.microsoft.azure.cognitiveservices.computervision.implementation._domain_model_results_inner
    name: DomainModelResultsInner
    fullName: com.microsoft.azure.cognitiveservices.computervision.implementation.DomainModelResultsInner
    href: com.microsoft.azure.cognitiveservices.computervision.implementation._domain_model_results_inner.yml
  - name: '>'
    fullName: '>'
- uid: fc480ba2com.microsoft.azure.cognitiveservices.computervision.implementation._domain_model_results_innere7daa122
  spec.java:
  - name: Observable<ServiceResponse<
    fullName: Observable<ServiceResponse<
  - uid: com.microsoft.azure.cognitiveservices.computervision.implementation._domain_model_results_inner
    name: DomainModelResultsInner
    fullName: com.microsoft.azure.cognitiveservices.computervision.implementation.DomainModelResultsInner
    href: com.microsoft.azure.cognitiveservices.computervision.implementation._domain_model_results_inner.yml
  - name: '>>'
    fullName: '>>'
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageByDomainWithServiceResponseAsync*
  name: analyzeImageByDomainWithServiceResponseAsync
  nameWithType: ComputerVisionAPIImpl.analyzeImageByDomainWithServiceResponseAsync
  fullName: Observable<ServiceResponse<DomainModelResultsInner>> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.analyzeImageByDomainWithServiceResponseAsync
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizeText*
  name: recognizeText
  nameWithType: ComputerVisionAPIImpl.recognizeText
  fullName: void com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.recognizeText
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
- uid: 1c186eb5
  spec.java:
  - name: final ServiceCallback<Void>
    fullName: final ServiceCallback<Void>
- uid: aa81d378
  spec.java:
  - name: ServiceFuture<Void>
    fullName: ServiceFuture<Void>
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizeTextAsync*
  name: recognizeTextAsync
  nameWithType: ComputerVisionAPIImpl.recognizeTextAsync
  fullName: ServiceFuture<Void> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.recognizeTextAsync
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
- uid: dcd884b2
  spec.java:
  - name: Observable<Void>
    fullName: Observable<Void>
- uid: 6738ce59com.microsoft.azure.cognitiveservices.computervision.implementation._recognize_text_headers_innere7daa122
  spec.java:
  - name: 'Observable<ServiceResponseWithHeaders<Void, '
    fullName: 'Observable<ServiceResponseWithHeaders<Void, '
  - uid: com.microsoft.azure.cognitiveservices.computervision.implementation._recognize_text_headers_inner
    name: RecognizeTextHeadersInner
    fullName: com.microsoft.azure.cognitiveservices.computervision.implementation.RecognizeTextHeadersInner
    href: com.microsoft.azure.cognitiveservices.computervision.implementation._recognize_text_headers_inner.yml
  - name: '>>'
    fullName: '>>'
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizeTextWithServiceResponseAsync*
  name: recognizeTextWithServiceResponseAsync
  nameWithType: ComputerVisionAPIImpl.recognizeTextWithServiceResponseAsync
  fullName: Observable<ServiceResponseWithHeaders<Void, RecognizeTextHeadersInner>> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.recognizeTextWithServiceResponseAsync
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.getTextOperationResult*
  name: getTextOperationResult
  nameWithType: ComputerVisionAPIImpl.getTextOperationResult
  fullName: TextOperationResultInner com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.getTextOperationResult
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
- uid: 897eb10acom.microsoft.azure.cognitiveservices.computervision.implementation._text_operation_result_innera08ddfce
  spec.java:
  - name: final ServiceCallback<
    fullName: final ServiceCallback<
  - uid: com.microsoft.azure.cognitiveservices.computervision.implementation._text_operation_result_inner
    name: TextOperationResultInner
    fullName: com.microsoft.azure.cognitiveservices.computervision.implementation.TextOperationResultInner
    href: com.microsoft.azure.cognitiveservices.computervision.implementation._text_operation_result_inner.yml
  - name: '>'
    fullName: '>'
- uid: c522ce07com.microsoft.azure.cognitiveservices.computervision.implementation._text_operation_result_innera08ddfce
  spec.java:
  - name: ServiceFuture<
    fullName: ServiceFuture<
  - uid: com.microsoft.azure.cognitiveservices.computervision.implementation._text_operation_result_inner
    name: TextOperationResultInner
    fullName: com.microsoft.azure.cognitiveservices.computervision.implementation.TextOperationResultInner
    href: com.microsoft.azure.cognitiveservices.computervision.implementation._text_operation_result_inner.yml
  - name: '>'
    fullName: '>'
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.getTextOperationResultAsync*
  name: getTextOperationResultAsync
  nameWithType: ComputerVisionAPIImpl.getTextOperationResultAsync
  fullName: ServiceFuture<TextOperationResultInner> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.getTextOperationResultAsync
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
- uid: c2d0e8c6com.microsoft.azure.cognitiveservices.computervision.implementation._text_operation_result_innera08ddfce
  spec.java:
  - name: Observable<
    fullName: Observable<
  - uid: com.microsoft.azure.cognitiveservices.computervision.implementation._text_operation_result_inner
    name: TextOperationResultInner
    fullName: com.microsoft.azure.cognitiveservices.computervision.implementation.TextOperationResultInner
    href: com.microsoft.azure.cognitiveservices.computervision.implementation._text_operation_result_inner.yml
  - name: '>'
    fullName: '>'
- uid: fc480ba2com.microsoft.azure.cognitiveservices.computervision.implementation._text_operation_result_innere7daa122
  spec.java:
  - name: Observable<ServiceResponse<
    fullName: Observable<ServiceResponse<
  - uid: com.microsoft.azure.cognitiveservices.computervision.implementation._text_operation_result_inner
    name: TextOperationResultInner
    fullName: com.microsoft.azure.cognitiveservices.computervision.implementation.TextOperationResultInner
    href: com.microsoft.azure.cognitiveservices.computervision.implementation._text_operation_result_inner.yml
  - name: '>>'
    fullName: '>>'
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.getTextOperationResultWithServiceResponseAsync*
  name: getTextOperationResultWithServiceResponseAsync
  nameWithType: ComputerVisionAPIImpl.getTextOperationResultWithServiceResponseAsync
  fullName: Observable<ServiceResponse<TextOperationResultInner>> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.getTextOperationResultWithServiceResponseAsync
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
- uid: ccd9418d
  spec.java:
  - name: byte []
    fullName: byte []
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageInStream*
  name: analyzeImageInStream
  nameWithType: ComputerVisionAPIImpl.analyzeImageInStream
  fullName: ImageAnalysisInner com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.analyzeImageInStream
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageInStreamAsync*
  name: analyzeImageInStreamAsync
  nameWithType: ComputerVisionAPIImpl.analyzeImageInStreamAsync
  fullName: ServiceFuture<ImageAnalysisInner> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.analyzeImageInStreamAsync
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageInStreamWithServiceResponseAsync*
  name: analyzeImageInStreamWithServiceResponseAsync
  nameWithType: ComputerVisionAPIImpl.analyzeImageInStreamWithServiceResponseAsync
  fullName: Observable<ServiceResponse<ImageAnalysisInner>> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.analyzeImageInStreamWithServiceResponseAsync
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.generateThumbnailInStream*
  name: generateThumbnailInStream
  nameWithType: ComputerVisionAPIImpl.generateThumbnailInStream
  fullName: InputStream com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.generateThumbnailInStream
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.generateThumbnailInStreamAsync*
  name: generateThumbnailInStreamAsync
  nameWithType: ComputerVisionAPIImpl.generateThumbnailInStreamAsync
  fullName: ServiceFuture<InputStream> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.generateThumbnailInStreamAsync
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.generateThumbnailInStreamWithServiceResponseAsync*
  name: generateThumbnailInStreamWithServiceResponseAsync
  nameWithType: ComputerVisionAPIImpl.generateThumbnailInStreamWithServiceResponseAsync
  fullName: Observable<ServiceResponse<InputStream>> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.generateThumbnailInStreamWithServiceResponseAsync
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizePrintedTextInStream*
  name: recognizePrintedTextInStream
  nameWithType: ComputerVisionAPIImpl.recognizePrintedTextInStream
  fullName: OcrResultInner com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.recognizePrintedTextInStream
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizePrintedTextInStreamAsync*
  name: recognizePrintedTextInStreamAsync
  nameWithType: ComputerVisionAPIImpl.recognizePrintedTextInStreamAsync
  fullName: ServiceFuture<OcrResultInner> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.recognizePrintedTextInStreamAsync
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizePrintedTextInStreamWithServiceResponseAsync*
  name: recognizePrintedTextInStreamWithServiceResponseAsync
  nameWithType: ComputerVisionAPIImpl.recognizePrintedTextInStreamWithServiceResponseAsync
  fullName: Observable<ServiceResponse<OcrResultInner>> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.recognizePrintedTextInStreamWithServiceResponseAsync
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.describeImageInStream*
  name: describeImageInStream
  nameWithType: ComputerVisionAPIImpl.describeImageInStream
  fullName: ImageDescriptionInner com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.describeImageInStream
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.describeImageInStreamAsync*
  name: describeImageInStreamAsync
  nameWithType: ComputerVisionAPIImpl.describeImageInStreamAsync
  fullName: ServiceFuture<ImageDescriptionInner> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.describeImageInStreamAsync
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.describeImageInStreamWithServiceResponseAsync*
  name: describeImageInStreamWithServiceResponseAsync
  nameWithType: ComputerVisionAPIImpl.describeImageInStreamWithServiceResponseAsync
  fullName: Observable<ServiceResponse<ImageDescriptionInner>> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.describeImageInStreamWithServiceResponseAsync
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.tagImageInStream*
  name: tagImageInStream
  nameWithType: ComputerVisionAPIImpl.tagImageInStream
  fullName: TagResultInner com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.tagImageInStream
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.tagImageInStreamAsync*
  name: tagImageInStreamAsync
  nameWithType: ComputerVisionAPIImpl.tagImageInStreamAsync
  fullName: ServiceFuture<TagResultInner> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.tagImageInStreamAsync
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.tagImageInStreamWithServiceResponseAsync*
  name: tagImageInStreamWithServiceResponseAsync
  nameWithType: ComputerVisionAPIImpl.tagImageInStreamWithServiceResponseAsync
  fullName: Observable<ServiceResponse<TagResultInner>> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.tagImageInStreamWithServiceResponseAsync
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageByDomainInStream*
  name: analyzeImageByDomainInStream
  nameWithType: ComputerVisionAPIImpl.analyzeImageByDomainInStream
  fullName: DomainModelResultsInner com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.analyzeImageByDomainInStream
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageByDomainInStreamAsync*
  name: analyzeImageByDomainInStreamAsync
  nameWithType: ComputerVisionAPIImpl.analyzeImageByDomainInStreamAsync
  fullName: ServiceFuture<DomainModelResultsInner> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.analyzeImageByDomainInStreamAsync
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.analyzeImageByDomainInStreamWithServiceResponseAsync*
  name: analyzeImageByDomainInStreamWithServiceResponseAsync
  nameWithType: ComputerVisionAPIImpl.analyzeImageByDomainInStreamWithServiceResponseAsync
  fullName: Observable<ServiceResponse<DomainModelResultsInner>> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.analyzeImageByDomainInStreamWithServiceResponseAsync
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizeTextInStream*
  name: recognizeTextInStream
  nameWithType: ComputerVisionAPIImpl.recognizeTextInStream
  fullName: void com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.recognizeTextInStream
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizeTextInStreamAsync*
  name: recognizeTextInStreamAsync
  nameWithType: ComputerVisionAPIImpl.recognizeTextInStreamAsync
  fullName: ServiceFuture<Void> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.recognizeTextInStreamAsync
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
- uid: 6738ce59com.microsoft.azure.cognitiveservices.computervision.implementation._reco2bb3a00c0d01a8e8a9d04b46d2399ab7e7daa122
  spec.java:
  - name: 'Observable<ServiceResponseWithHeaders<Void, '
    fullName: 'Observable<ServiceResponseWithHeaders<Void, '
  - uid: com.microsoft.azure.cognitiveservices.computervision.implementation._reco2bb3a00c0d01a8e8a9d04b46d2399ab7
    name: RecognizeTextInStreamHeadersInner
    fullName: com.microsoft.azure.cognitiveservices.computervision.implementation.RecognizeTextInStreamHeadersInner
    href: com.microsoft.azure.cognitiveservices.computervision.implementation._reco2bb3a00c0d01a8e8a9d04b46d2399ab7.yml
  - name: '>>'
    fullName: '>>'
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.recognizeTextInStreamWithServiceResponseAsync*
  name: recognizeTextInStreamWithServiceResponseAsync
  nameWithType: ComputerVisionAPIImpl.recognizeTextInStreamWithServiceResponseAsync
  fullName: Observable<ServiceResponseWithHeaders<Void, RecognizeTextInStreamHeadersInner>> com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.recognizeTextInStreamWithServiceResponseAsync
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.initialize*
  name: initialize
  nameWithType: ComputerVisionAPIImpl.initialize
  fullName: void com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl.initialize
  package: com.microsoft.azure.cognitiveservices.computervision.implementation
- uid: com.microsoft.azure.cognitiveservices.computervision._azure_regions
  parent: com.microsoft.azure.cognitiveservices.computervision
  href: com.microsoft.azure.cognitiveservices.computervision._azure_regions.yml
  name: AzureRegions
  nameWithType: AzureRegions
  fullName: com.microsoft.azure.cognitiveservices.computervision.AzureRegions
  type: Enum
  summary: <p>Defines values for <xref uid="com.microsoft.azure.cognitiveservices.computervision._azure_regions" data-throw-if-not-resolved="false">AzureRegions</xref>. </p>
  syntax:
    content: public enum AzureRegions
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl.yml
  name: ComputerVisionAPIImpl
  nameWithType: ComputerVisionAPIImpl
  fullName: com.microsoft.azure.cognitiveservices.computervision.implementation.ComputerVisionAPIImpl
  type: Class
  summary: <p>Initializes a new instance of the <xref uid="com.microsoft.azure.cognitiveservices.computervision.implementation._computer_vision_a_p_i_impl" data-throw-if-not-resolved="false">ComputerVisionAPIImpl</xref> class. </p>
  syntax: *o1
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._list_models_result_inner
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._list_models_result_inner.yml
  name: ListModelsResultInner
  nameWithType: ListModelsResultInner
  fullName: com.microsoft.azure.cognitiveservices.computervision.implementation.ListModelsResultInner
  type: Class
  summary: <p>Result of the List Domain Models operation. </p>
  syntax:
    content: public class ListModelsResultInner
- uid: com.microsoft.azure.cognitiveservices.computervision._computer_vision_error_exception
  parent: com.microsoft.azure.cognitiveservices.computervision
  href: com.microsoft.azure.cognitiveservices.computervision._computer_vision_error_exception.yml
  name: ComputerVisionErrorException
  nameWithType: ComputerVisionErrorException
  fullName: com.microsoft.azure.cognitiveservices.computervision.ComputerVisionErrorException
  type: Class
  summary: <p>Exception thrown for an invalid response with <xref uid="com.microsoft.azure.cognitiveservices.computervision._computer_vision_error" data-throw-if-not-resolved="false">ComputerVisionError</xref> information. </p>
  syntax:
    content: public class ComputerVisionErrorException
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._image_analysis_inner
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._image_analysis_inner.yml
  name: ImageAnalysisInner
  nameWithType: ImageAnalysisInner
  fullName: com.microsoft.azure.cognitiveservices.computervision.implementation.ImageAnalysisInner
  type: Class
  summary: <p>Result of AnalyzeImage operation. </p>
  syntax:
    content: public class ImageAnalysisInner
- uid: com.microsoft.azure.cognitiveservices.computervision._visual_feature_types
  parent: com.microsoft.azure.cognitiveservices.computervision
  href: com.microsoft.azure.cognitiveservices.computervision._visual_feature_types.yml
  name: VisualFeatureTypes
  nameWithType: VisualFeatureTypes
  fullName: com.microsoft.azure.cognitiveservices.computervision.VisualFeatureTypes
  type: Enum
  summary: <p>Defines values for <xref uid="com.microsoft.azure.cognitiveservices.computervision._visual_feature_types" data-throw-if-not-resolved="false">VisualFeatureTypes</xref>. </p>
  syntax:
    content: public enum VisualFeatureTypes
- uid: com.microsoft.azure.cognitiveservices.computervision._details
  parent: com.microsoft.azure.cognitiveservices.computervision
  href: com.microsoft.azure.cognitiveservices.computervision._details.yml
  name: Details
  nameWithType: Details
  fullName: com.microsoft.azure.cognitiveservices.computervision.Details
  type: Enum
  summary: <p>Defines values for <xref uid="com.microsoft.azure.cognitiveservices.computervision._details" data-throw-if-not-resolved="false">Details</xref>. </p>
  syntax:
    content: public enum Details
- uid: com.microsoft.azure.cognitiveservices.computervision._language1
  parent: com.microsoft.azure.cognitiveservices.computervision
  href: com.microsoft.azure.cognitiveservices.computervision._language1.yml
  name: Language1
  nameWithType: Language1
  fullName: com.microsoft.azure.cognitiveservices.computervision.Language1
  type: Enum
  summary: <p>Defines values for <xref uid="com.microsoft.azure.cognitiveservices.computervision._language1" data-throw-if-not-resolved="false">Language1</xref>. </p>
  syntax:
    content: public enum Language1
- uid: com.microsoft.azure.cognitiveservices.computervision._image_type
  parent: com.microsoft.azure.cognitiveservices.computervision
  href: com.microsoft.azure.cognitiveservices.computervision._image_type.yml
  name: ImageType
  nameWithType: ImageType
  fullName: com.microsoft.azure.cognitiveservices.computervision.ImageType
  type: Class
  summary: <p>An object providing possible image types and matching confidence levels. </p>
  syntax:
    content: public class ImageType
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._ocr_result_inner
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._ocr_result_inner.yml
  name: OcrResultInner
  nameWithType: OcrResultInner
  fullName: com.microsoft.azure.cognitiveservices.computervision.implementation.OcrResultInner
  type: Class
  summary: <p>The <xref uid="com.microsoft.azure.cognitiveservices.computervision.implementation._ocr_result_inner" data-throw-if-not-resolved="false">OcrResultInner</xref> model. </p>
  syntax:
    content: public class OcrResultInner
- uid: com.microsoft.azure.cognitiveservices.computervision._ocr_languages
  parent: com.microsoft.azure.cognitiveservices.computervision
  href: com.microsoft.azure.cognitiveservices.computervision._ocr_languages.yml
  name: OcrLanguages
  nameWithType: OcrLanguages
  fullName: com.microsoft.azure.cognitiveservices.computervision.OcrLanguages
  type: Enum
  summary: <p>Defines values for <xref uid="com.microsoft.azure.cognitiveservices.computervision._ocr_languages" data-throw-if-not-resolved="false">OcrLanguages</xref>. </p>
  syntax:
    content: public enum OcrLanguages
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._image_description_inner
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._image_description_inner.yml
  name: ImageDescriptionInner
  nameWithType: ImageDescriptionInner
  fullName: com.microsoft.azure.cognitiveservices.computervision.implementation.ImageDescriptionInner
  type: Class
  summary: <p>A collection of content tags, along with a list of captions sorted by confidence level, and image metadata. </p>
  syntax:
    content: public class ImageDescriptionInner
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._tag_result_inner
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._tag_result_inner.yml
  name: TagResultInner
  nameWithType: TagResultInner
  fullName: com.microsoft.azure.cognitiveservices.computervision.implementation.TagResultInner
  type: Class
  summary: <p>The results of a image tag operation, including any tags and image metadata. </p>
  syntax:
    content: public class TagResultInner
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._domain_model_results_inner
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._domain_model_results_inner.yml
  name: DomainModelResultsInner
  nameWithType: DomainModelResultsInner
  fullName: com.microsoft.azure.cognitiveservices.computervision.implementation.DomainModelResultsInner
  type: Class
  summary: <p>Result of image analysis using a specific domain model including additional metadata. </p>
  syntax:
    content: public class DomainModelResultsInner
- uid: com.microsoft.azure.cognitiveservices.computervision._domain_models
  parent: com.microsoft.azure.cognitiveservices.computervision
  href: com.microsoft.azure.cognitiveservices.computervision._domain_models.yml
  name: DomainModels
  nameWithType: DomainModels
  fullName: com.microsoft.azure.cognitiveservices.computervision.DomainModels
  type: Enum
  summary: <p>Defines values for <xref uid="com.microsoft.azure.cognitiveservices.computervision._domain_models" data-throw-if-not-resolved="false">DomainModels</xref>. </p>
  syntax:
    content: public enum DomainModels
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._recognize_text_headers_inner
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._recognize_text_headers_inner.yml
  name: RecognizeTextHeadersInner
  nameWithType: RecognizeTextHeadersInner
  fullName: com.microsoft.azure.cognitiveservices.computervision.implementation.RecognizeTextHeadersInner
  type: Class
  summary: <p>Defines headers for RecognizeText operation. </p>
  syntax:
    content: public class RecognizeTextHeadersInner
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._text_operation_result_inner
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._text_operation_result_inner.yml
  name: TextOperationResultInner
  nameWithType: TextOperationResultInner
  fullName: com.microsoft.azure.cognitiveservices.computervision.implementation.TextOperationResultInner
  type: Class
  summary: <p>The <xref uid="com.microsoft.azure.cognitiveservices.computervision.implementation._text_operation_result_inner" data-throw-if-not-resolved="false">TextOperationResultInner</xref> model. </p>
  syntax:
    content: public class TextOperationResultInner
- uid: com.microsoft.azure.cognitiveservices.computervision.implementation._reco2bb3a00c0d01a8e8a9d04b46d2399ab7
  parent: com.microsoft.azure.cognitiveservices.computervision.implementation
  href: com.microsoft.azure.cognitiveservices.computervision.implementation._reco2bb3a00c0d01a8e8a9d04b46d2399ab7.yml
  name: RecognizeTextInStreamHeadersInner
  nameWithType: RecognizeTextInStreamHeadersInner
  fullName: com.microsoft.azure.cognitiveservices.computervision.implementation.RecognizeTextInStreamHeadersInner
  type: Class
  summary: <p>Defines headers for RecognizeTextInStream operation. </p>
  syntax:
    content: public class RecognizeTextInStreamHeadersInner
